{
  "uuid": "c1be4004-3e5b-4790-a5d5-2757f0a6437e",
  "name": "Modular Design and Code Optimization for Binomial MATLAB Code",
  "summary": "",
  "created_at": "2025-05-08T09:06:27.072641+00:00",
  "updated_at": "2025-05-08T10:13:20.215759+00:00",
  "settings": {
    "enabled_web_search": true,
    "paprika_mode": "extended",
    "preview_feature_uses_artifacts": true
  },
  "is_starred": false,
  "current_leaf_message_uuid": "72ad818b-e2ef-47e3-bd5c-c8ce86ea188e",
  "chat_messages": [
    {
      "uuid": "3a0c7d3e-bceb-43e4-80da-eada71bb8b9a",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T09:06:29.877046+00:00",
          "stop_timestamp": "2025-05-08T09:06:29.877046+00:00",
          "type": "text",
          "text": "1. **模块化设计** 将`Binomial`拆分为多个子函数,每个函数专注于单一任务(如数据加载、预处理等),提高代码可维护性。2. **模块化设计** 将功能拆分为独立模块,便于复用和扩展。代码已部分模块化,但仍有一些功能(如可视化)嵌入在主流程中。 * **提取重复逻辑** * **进一步分解功能** * 某些函数(如 `save_enhanced_results` 及其辅助的表格创建函数,`create_enhanced_summary_report`)非常长。虽然它们在逻辑上相关,但可以考虑将报告生成的部分拆分成更小的、专注于特定报告片段的函数,以提高可读性。3. **现状**:代码无单元测试。4. **面向对象编程** 使用类封装数据和方法,提升复用性。5. **规范命名** 使用更具描述性的变量名6. **并行同步** 使用MATLAB并行计算工具箱的同步机制,确保数据一致性。已经有效地使用了 `parfor` (例如在 `prepare_variables`, `bootstrap_sampling`, `select_variables`, `train_and_evaluate_models_with_groups`, `get_model_parameters` 中) 和 `parfeval` (用于并行执行不同的变量选择方法)。这是利用多核CPU的关键。7. **参数化配置** 将关键参数提取到配置文件或函数参数中。**硬编码值:** * `preprocess_data` 中的 `exclude_rows = [6, 10, ..., 339];` 和 `reverse_items = [12, 19, 23];` 以及 `max_score = 5;`。 * `prepare_variables` 中的 `groups = {...};` 和因变量列 `data(:, 29)`。 * **建议:** 如果这些值可能会改变,或者脚本需要应用于不同的数据集,将它们作为函数参数、配置文件中的参数或至少在函数开头的常量中定义,会提高可维护性和灵活性。8. **消除冗余代码** 重构重复逻辑,提升代码复用性。 请按要求优化代码9. **数据清洗** 在预处理阶段添加缺失值填充和异常值检测。10. **增强错误处理 **在关键步骤使用`try-catch`捕获异常,并记录详细日志。代码已有基本的`try-catch`块,但覆盖范围有限。11. **充分利用MATLAB特性** 使用向量化操作和并行计算优化性能。12. **添加详细注释** 为每个函数和关键代码块添加文档字符串,说明功能、输入输出和使用方法。**添加详细帮助文档**: * **添加详细帮助文档**:在每个函数开头添加标准MATLAB文档。 * **内联注释**:在复杂逻辑处添加解释。13. **使用MATLAB Profiler**:在`Binomial`中添加性能分析。\n\n需要优化的代码已上传至GitHub\n\nhttps://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m\n\n优化过后的代码若过长可分类发送给我",
          "citations": []
        }
      ],
      "sender": "human",
      "index": 0,
      "created_at": "2025-05-08T09:06:29.880755+00:00",
      "updated_at": "2025-05-08T09:06:29.880755+00:00",
      "truncated": false,
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "00000000-0000-4000-8000-000000000000"
    },
    {
      "uuid": "928e78a8-786d-4dae-9b40-17b2dbb37cc4",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T09:06:30.753406+00:00",
          "stop_timestamp": "2025-05-08T09:06:33.797214+00:00",
          "type": "thinking",
          "thinking": "用户提到了一系列的代码优化需求，主要包括：\n1. 模块化设计\n2. 提取重复逻辑\n3. 添加单元测试\n4. 面向对象编程\n5. 规范命名\n6. 并行同步\n7. 参数化配置\n8. 消除冗余代码\n9. 数据清洗\n10. 增强错误处理\n11. 充分利用MATLAB特性\n12. 添加详细注释\n13. 性能分析\n\n用户提到已经将代码上传到GitHub，需要我从GitHub获取代码，然后根据这些要求进行优化。优化后的代码如果过长可以分类发送。\n\n我需要先获取GitHub上的代码，看一下具体的内容，然后根据用户的要求进行优化。\n\n首先，我需要使用web_fetch工具获取代码内容。",
          "summaries": [
            {
              "summary": "获取GitHub代码，根据优化需求进行改进"
            },
            {
              "summary": "准备从GitHub获取代码并进行全面优化"
            }
          ],
          "cut_off": false
        },
        {
          "start_timestamp": "2025-05-08T09:06:33.804551+00:00",
          "stop_timestamp": "2025-05-08T09:06:34.376452+00:00",
          "type": "text",
          "text": "我将帮你优化这段MATLAB代码。首先，让我从GitHub获取代码，然后按照你提出的要求进行全面优化。",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:06:34.569756+00:00",
          "stop_timestamp": "2025-05-08T09:06:34.892947+00:00",
          "type": "tool_use",
          "name": "web_fetch",
          "input": {
            "url": "https://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m"
          },
          "message": "Fetching site"
        },
        {
          "type": "tool_result",
          "name": "web_fetch",
          "content": [
            {
              "type": "knowledge",
              "title": "",
              "url": "https://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m",
              "metadata": {
                "type": "webpage_metadata",
                "site_domain": "github.com",
                "favicon_url": "https://www.google.com/s2/favicons?sz=64&domain=github.com",
                "site_name": "github"
              },
              "is_missing": false,
              "text": "function Binomial(filename)\n% 二元逻辑回归模型的完整实现 - 为MacBook Pro 2019 i9-9980HK优化\n% 增强版：增加k折交叉验证、多指标监控、系数稳定性评估、参数置信区间和变量贡献分析\n% 增强版2.0：增加BCa置信区间、箱线图、PR曲线、校准曲线、混淆矩阵、AIC/BIC评价、残差分析、累计方差\n% 版本3.0：优化日志系统，增加日志级别控制，简化图形保存日志\n% 输入:\n%   filename - 包含数据的.mat文件路径\n% 示例:\n%   Binomial('mydata.mat');\n\n% 开始计时\ntic;\n\n% 设置随机数种子以确保结果可重复\nrng(42);\n\n% 设置日志级别\nset_log_level('info'); % 可选值: 'debug', 'info', 'warning', 'error'\n\n% 系统信息收集\nlog_message('info', '系统配置:');\nlog_message('info', sprintf('- CPU: Intel i9-9980HK (8核16线程)'));\nlog_message('info', sprintf('- 内存: 64GB RAM'));\nlog_message('info', sprintf('- GPU: AMD Radeon Pro 5500M 8GB'));\n\n% 工具箱检查\nif ~license('test', 'statistics_toolbox')\n    error('需要安装 Statistics and Machine Learning Toolbox');\nend\n\n% 配置并行池\nif isempty(gcp('nocreate'))\n    % i9-9980HK有8核16线程，专业配置方案\n    numLogicalProcessors = feature('numcores');\n    log_message('info', sprintf('检测到%d个逻辑处理器', numLogicalProcessors));\n    \n    % 创建并配置本地集群对象\n    c = parcluster('local');\n    \n    % 方案2: 平衡配置 - 适合混合计算任务(推荐)\n    c.NumThreads = 2; % 每个worker使用2个线程\n    poolSize = min(8, feature('numcores')); % 限制为物理核心数\n    \n    % 性能优化：设置工作目录到高速存储\n    tmpDir = fullfile('/tmp', ['matlab_parallel_', datestr(now, 'yyyymmdd_HHMMSS')]);\n    if ~exist(tmpDir, 'dir')\n        mkdir(tmpDir);\n    end\n    c.JobStorageLocation = tmpDir;\n    \n    % 保存配置并创建并行池\n    c.saveProfile;\n    parpool(c, poolSize);\n    log_message('info', sprintf('创建并行池，使用%d个worker，每个worker使用%d个线程', poolSize, c.NumThreads));\nelse\n    log_message('info', '使用现有并行池');\nend\n\n% 创建输出文件夹\nif ~exist('results', 'dir')\n    mkdir('results');\nend\n\n% 创建图形文件夹\nfigure_dir = fullfile('results', 'figures');\nif ~exist(figure_dir, 'dir')\n    mkdir(figure_dir);\nend\n\n% 初始化日志\nlog_file = fullfile('results', 'log.txt');\nif exist(log_file, 'file')\n    delete(log_file);\nend\nlog_message('info', '开始执行二元逻辑回归分析...');\n\ntry\n    % 1. 加载数据\n    t_start = toc;\n    [data_raw, success, msg] = load_data(filename);\n    if ~success\n        log_message('error', msg);\n        return;\n    end\n    t_end = toc;\n    log_message('info', sprintf('成功加载数据，样本数：%d，变量数：%d，耗时：%.2f秒', ...\n        size(data_raw, 1), size(data_raw, 2), t_end - t_start));\n    \n    % 2. 数据预处理\n    t_start = toc;\n    [data_processed, valid_rows] = preprocess_data(data_raw);\n    t_end = toc;\n    log_message('info', sprintf('数据预处理完成，有效样本数：%d，耗时：%.2f秒', ...\n        length(valid_rows), t_end - t_start));\n    \n    % 3. 准备因变量和自变量\n    t_start = toc;\n    [X, y, var_names, group_means] = prepare_variables(data_processed);\n    t_end = toc;\n    log_message('info', sprintf('变量准备完成，自变量数：%d，耗时：%.2f秒', ...\n        size(X, 2), t_end - t_start));\n    \n    % 4. 检查多重共线性\n    t_start = toc;\n    [X_final, vif_values, removed_vars] = check_collinearity(X, var_names);\n    t_end = toc;\n    log_message('info', sprintf('多重共线性检查完成，最终自变量数：%d，耗时：%.2f秒', ...\n        size(X_final, 2), t_end - t_start));\n    \n    % 5. 变量分析（增强版，返回PCA结果）\n    t_start = toc;\n    pca_results = analyze_variable_correlations(X_final, var_names(~removed_vars));\n    t_end = toc;\n    log_message('info', sprintf('变量相关性分析完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 6. 使用Bootstrap生成样本\n    t_start = toc;\n    [train_indices, test_indices] = bootstrap_sampling(y, 0.8, 100);\n    t_end = toc;\n    log_message('info', sprintf('Bootstrap抽样完成，生成了%d个训练/测试集，耗时：%.2f秒', ...\n        length(train_indices), t_end - t_start));\n    \n    % 7. 执行K折交叉验证（增强版可视化）\n    t_start = toc;\n    % 设置K的值为10\n    k_value = 10;\n    cv_results = k_fold_cross_validation(X_final, y, k_value, var_names(~removed_vars));\n    create_kfold_performance_visualization(cv_results, figure_dir);\n    t_end = toc;\n    log_message('info', sprintf('K折交叉验证完成(K=%d)，耗时：%.2f秒', k_value, t_end - t_start));\n    \n    % 8. 使用不同方法筛选变量 - 并行处理\n    t_start = toc;\n    methods = {'stepwise', 'lasso', 'ridge', 'elasticnet', 'randomforest'};\n    results = struct();\n    \n    % 创建函数句柄数组\n    futures = cell(length(methods), 1);\n    \n    % 并行启动所有方法\n    for i = 1:length(methods)\n        method = methods{i};\n        log_message('info', sprintf('开始并行使用%s方法筛选变量', method));\n        \n        % 使用parfeval异步执行\n        futures{i} = parfeval(@process_method, 1, X_final, y, train_indices, test_indices, method, var_names(~removed_vars));\n    end\n    \n    % 收集结果\n    for i = 1:length(methods)\n        method = methods{i};\n        [methodResult] = fetchOutputs(futures{i});\n        results.(method) = methodResult;\n        log_message('info', sprintf('%s方法完成', method));\n    end\n    \n    t_end = toc;\n    log_message('info', sprintf('所有变量选择方法完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 9. 监控模型系数稳定性（增强版，包含BCa区间）\n    t_start = toc;\n    coef_stability = monitor_coefficient_stability(results, methods, var_names(~removed_vars));\n    t_end = toc;\n    log_message('info', sprintf('模型系数稳定性监控完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 10. 计算模型参数置信区间和p值（增强版，同时使用BCa和t分布）\n    t_start = toc;\n    param_stats = calculate_parameter_statistics(results, methods, var_names(~removed_vars));\n    t_end = toc;\n    log_message('info', sprintf('模型参数统计分析完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 11. 评估每个变量对模型的贡献\n    t_start = toc;\n    var_contribution = evaluate_variable_contribution(X_final, y, results, methods, var_names(~removed_vars));\n    t_end = toc;\n    log_message('info', sprintf('变量贡献评估完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 12. 执行残差分析\n    t_start = toc;\n    create_residual_analysis(results, methods, figure_dir);\n    t_end = toc;\n    log_message('info', sprintf('残差分析完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 13. 创建所有可视化图表 - 现在使用优化后的图形保存函数，不再单独记录每个图表\n    t_start = toc;\n    \n    create_boxplot_visualization(results, methods, figure_dir);\n    create_pr_curves(results, methods, figure_dir);\n    create_calibration_curves(results, methods, figure_dir);\n    create_confusion_matrices(results, methods, figure_dir);\n    create_roc_curves(results, methods, figure_dir);\n    create_variable_importance_plot(results, methods, var_names(~removed_vars), figure_dir);\n    create_variable_group_plot(results, methods, var_names(~removed_vars), figure_dir);\n    create_coefficient_stability_plot(coef_stability, methods, figure_dir);\n    create_variable_contribution_plot(var_contribution, figure_dir);\n    \n    t_end = toc;\n    log_message('info', sprintf('所有可视化图表创建完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 14. 保存结果\n    t_start = toc;\n    save_enhanced_results(results, var_names(~removed_vars), group_means, cv_results, coef_stability, param_stats, var_contribution);\n    t_end = toc;\n    log_message('info', sprintf('结果保存完成，耗时：%.2f秒', t_end - t_start));\n    \n    % 统计总耗时\n    total_time = toc;\n    log_message('info', sprintf('分析完成！所有结果已保存到results文件夹，总耗时：%.2f秒', total_time));\n    \n    % 如果使用并行池，添加并行性能统计\n    if ~isempty(gcp('nocreate'))\n        try\n            % 获取并行池对象\n            p = gcp('nocreate');\n            numWorkers = p.NumWorkers;\n                    \n            % 记录详细的并行池信息\n            log_message('info', sprintf('并行池性能统计:'));\n            log_message('info', sprintf('- 工作器数量: %d', numWorkers));\n            log_message('info', sprintf('- 每个工作器的线程数: %d', p.NumThreads));\n            log_message('info', sprintf('- 总并行线程: %d', p.NumWorkers * p.NumThreads));\n                    \n        catch ME\n            log_message('warning', sprintf('无法获取详细的并行性能统计: %s', ME.message));\n        end\n    end\n    \ncatch ME\n    log_message('error', sprintf('执行过程中发生错误：%s\\n%s', ME.message, getReport(ME)));\nend\n\n% 关闭并行池\ntry\n    delete(gcp('nocreate'));\n    log_message('info', '关闭并行池');\ncatch\n    % 忽略关闭并行池时的错误\nend\n\nend\n\n%% 辅助函数: 日志记录\nfunction log_message(level, message)\n% 记录日志信息到控制台和文件\n% 输入:\n%   level - 日志级别 ('debug', 'info', 'warning', 'error')\n%   message - 日志消息\n\n    % 设置当前日志级别\n    persistent current_level;\n    if isempty(current_level)\n        current_level = 'info'; % 默认级别\n    end\n    \n    % 定义级别优先级\n    levels = {'debug', 'info', 'warning', 'error'};\n    level_priority = containers.Map(levels, 1:4);\n    \n    % 确保level是有效的\n    if ~ismember(lower(level), levels)\n        level = 'info'; % 如果level无效，默认为'info'\n    end\n    \n    % 获取当前时间\n    timestamp = datestr(now, 'yyyy-mm-dd HH:MM:SS');\n    \n    % 根据级别设置前缀\n    prefix = upper(level);\n    \n    % 构建完整日志消息\n    log_str = sprintf('[%s] [%s] %s', timestamp, prefix, message);\n    \n    % 如果当前级别 >= 设置的级别，则输出到控制台\n    if level_priority(lower(level)) >= level_priority(current_level)\n        fprintf('%s\\n', log_str);\n    end\n    \n    % 写入日志文件（始终写入文件，不受级别限制）\n    log_file = fullfile('results', 'log.txt');\n    fid = fopen(log_file, 'a');\n    if fid ~= -1\n        fprintf(fid, '%s\\n', log_str);\n        fclose(fid);\n    end\nend\n\n% 在日志级别控制函数中添加图形保存专用级别\nfunction set_log_level(level, options)\n    % 设置全局日志级别\n    % 输入:\n    %   level - 日志级别 ('debug', 'info', 'warning', 'error')\n    %   options - 可选配置参数\n\n    persistent current_level figure_save_level;\n    \n    % 默认图形保存日志级别比一般日志级别高一级（减少输出）\n    if nargin >= 2 && isfield(options, 'figure_save_level')\n        figure_save_level = options.figure_save_level;\n    elseif isempty(figure_save_level)\n        % 图形保存默认使用更高级别\n        switch lower(level)\n            case 'debug'\n                figure_save_level = 'info';\n            case 'info'\n                figure_save_level = 'warning';\n            otherwise\n                figure_save_level = level;\n        end\n    end\n    \n    % 默认级别逻辑\n    valid_levels = {'debug', 'info', 'warning', 'error'};\n    \n    % 检查级别是否有效\n    if ismember(lower(level), valid_levels)\n        current_level = lower(level);\n        fprintf('日志级别已设置为: %s (图形保存级别: %s)\\n', upper(current_level), upper(figure_save_level));\n    else\n        fprintf('无效的日志级别: %s, 有效级别: debug, info, warning, error\\n', level);\n    end\nend\n\n% 增加获取图形保存级别的函数\nfunction level = get_figure_save_level()\n    % 获取图形保存日志级别\n    % 输出:\n    %   level - 当前图形保存日志级别\n\n    persistent figure_save_level;\n    if isempty(figure_save_level)\n        figure_save_level = 'info'; % 默认级别\n    end\n    \n    level = figure_save_level;\nend\n\n%获取当前日志级别\nfunction level = get_log_level()\n% 获取当前日志级别\n% 输出:\n%   level - 当前日志级别\n\n    persistent current_level;\n    if isempty(current_level)\n        current_level = 'info'; % 默认级别\n    end\n    \n    level = current_level;\nend\n\n%% 数据加载函数\nfunction [data, success, message] = load_data(filename)\n% 加载数据文件\n% 输入:\n%   filename - 数据文件名\n% 输出:\n%   data - 加载的数据\n%   success - 是否成功加载\n%   message - 成功或错误消息\n\nsuccess = false;\nmessage = '';\ndata = [];\n\ntry\n    % 使用try-catch捕获可能的错误\n    try\n        % 尝试直接加载变量名为'data'的数据\n        s = load(filename);\n        if isfield(s, 'data')\n            data = s.data;\n        else\n            % 如果没有'data'字段，尝试获取第一个字段\n            fn = fieldnames(s);\n            if ~isempty(fn)\n                data = s.(fn{1});\n            else\n                error('数据文件中没有找到有效变量');\n            end\n        end\n    catch ME\n        % 如果上面的方法失败，尝试无变量名加载\n        data = load(filename);\n    end\n    \n    % 检查数据类型并转换\n    if istable(data)\n        data = table2array(data);\n    elseif ~isnumeric(data)\n        message = '数据必须是数值矩阵或表格';\n        return;\n    end\n    \n    % 检查数据有效性\n    if isempty(data)\n        message = '加载的数据为空';\n        return;\n    end\n    \n    % 数据成功加载\n    success = true;\n    message = '数据加载成功';\ncatch ME\n    message = sprintf('数据文件 %s 加载失败，请检查文件路径或内容！错误信息：%s', filename, ME.message);\nend\nend\n\n%% GPU支持函数 - 优化版\nfunction data_gpu = toGPU(data)\n% 将数据转移到GPU(如果支持) - 为AMD 5500M GPU优化\n% 输入:\n%   data - 输入数据\n% 输出:\n%   data_gpu - GPU上的数据或原始数据\n    \npersistent gpuAvailable gpuMemLimit;\n    \n% 只检查一次GPU可用性\nif isempty(gpuAvailable)\n    gpuAvailable = (exist('gpuArray', 'file') == 2) && gpuDeviceCount > 0;\n    \n    if gpuAvailable\n        gpu = gpuDevice();\n        % 为AMD GPU设置更保守的内存限制（总显存的60%）\n        gpuMemLimit = 0.6 * gpu.AvailableMemory;\n        \n        log_message('info', sprintf('GPU可用: %s, 总内存: %.2f GB, 可用内存: %.2f GB', ...\n            gpu.Name, gpu.TotalMemory/1e9, gpu.AvailableMemory/1e9));\n    else\n        gpuMemLimit = 0;\n        log_message('info', 'GPU不可用，使用CPU计算');\n    end\nend\n    \n% 智能决策：根据数据大小和传输开销决定是否使用GPU\nif gpuAvailable\n    try\n        % 计算数据大小(字节)\n        dataSize = numel(data) * 8; % 假设是双精度数据\n        \n        % 最小阈值：太小的数据传输开销大于收益(5MB)\n        minThreshold = 5 * 1024 * 1024;\n        \n        % 如果数据太大或太小，不使用GPU\n        if dataSize > gpuMemLimit || dataSize < minThreshold\n            data_gpu = data;\n            return;\n        end\n        \n        % 使用GPU\n        data_gpu = gpuArray(data);\n    catch ME\n        log_message('warning', sprintf('GPU转换失败: %s，使用CPU计算', ME.message));\n        data_gpu = data;\n    end\nelse\n    data_gpu = data;\nend\nend\n\n%% 数据预处理函数 - 优化版\nfunction [data_processed, valid_rows] = preprocess_data(data)\n% 数据清洗与预处理\n% 输入:\n%   data - 原始数据\n% 输出:\n%   data_processed - 处理后的数据\n%   valid_rows - 有效行索引\n\n% 定义有效行和需要反转的项目\nrows = 1:375;\nexclude_rows = [6, 10, 42, 74, 124, 127, 189, 252, 285, 298, 326, 331, 339];\nvalid_rows = setdiff(rows, exclude_rows);\nreverse_items = [12, 19, 23];\nmax_score = 5;\n\n% 预分配目标数组提高性能\ndata_processed = data;\n\n% 反转指定列\ndata_processed(:, reverse_items) = max_score + 1 - data_processed(:, reverse_items);\n\n% 选择有效行 - 直接索引比使用setdiff每次都计算更高效\ndata_processed = data_processed(valid_rows, :);\n\n% 后处理：检查数据有效性\nif any(isnan(data_processed(:)))\n    % 填充NaN值\n    data_processed = fillmissing(data_processed, 'linear');\n    log_message('warning', '检测到NaN值并使用线性插值填充');\nend\n\n% 如果数据很大且符合GPU处理条件，则尝试GPU加速\nif numel(data_processed) > 1e6\n    data_processed = toGPU(data_processed);\nend\nend\n\n%% 变量准备函数 - 优化版\nfunction [X, y, var_names, group_means] = prepare_variables(data)\n% 准备自变量和因变量\n% 输入:\n%   data - 预处理后的数据\n% 输出:\n%   X - 自变量矩阵\n%   y - 因变量向量\n%   var_names - 变量名称\n%   group_means - 分组均值\n\n% 提取因变量(第29列)\ny = data(:, 29);\n\n% 检查因变量范围\nif any(y < 1 | y > 4)\n    error('因变量中存在异常值，请检查！');\nend\n\n% 将因变量二元化(>2为1，<=2为0)\ny = double(y > 2);\n\n% 定义分组\ngroups = {\n    [1, 2, 3, 4, 5, 6, 12, 19, 23],  % 组1\n    [7, 8, 9],                       % 组2\n    [10, 11],                        % 组3\n    [13, 14],                        % 组4\n    [15, 17, 18, 20, 21],            % 组5\n    [22, 24],                        % 组6\n    [25, 26],                        % 组7\n    [27, 28]                         % 组8\n};\n\n% 标准化并计算各组均值\nX = zeros(size(data, 1), length(groups));\ngroup_means = cell(length(groups), 1);\nvar_names = cell(length(groups), 1);\n\n% 分块计算参数 - 增大分块大小利用64GB内存\nn_samples = size(data, 1);\nBLOCK_SIZE = 10000;  % 更大的块大小\nn_blocks = ceil(n_samples / BLOCK_SIZE);\nuse_blocks = n_samples > BLOCK_SIZE * 3; % 只有超大数据才分块\n\n% 使用parfor并行处理各组\nparfor i = 1:length(groups)\n    % 获取当前组的列\n    group_cols = groups{i};\n    \n    % 提取当前组的数据\n    group_data = data(:, group_cols);\n    \n    % 标准化处理\n    if use_blocks && n_samples > 100000\n        % 先计算整体统计量\n        mu = mean(group_data);\n        sigma = std(group_data);\n        \n        % 初始化标准化后的数据\n        group_data_std = zeros(size(group_data));\n        \n        % 分块标准化 - 仅对超大数据集使用\n        for b = 1:n_blocks\n            start_idx = (b-1)*BLOCK_SIZE + 1;\n            end_idx = min(b*BLOCK_SIZE, n_samples);\n            block_data = group_data(start_idx:end_idx, :);\n            \n            % 标准化\n            group_data_std(start_idx:end_idx, :) = (block_data - mu) ./ sigma;\n        end\n    else\n        % 对于一般大小数据集，直接标准化\n        group_data_std = zscore(group_data);\n    end\n    \n    % 计算标准化后的均值\n    group_mean = mean(group_data_std, 2);\n    \n    % 存储原始均值（未标准化）\n    group_orig_mean = mean(group_data, 2);\n    \n    % 返回结果\n    X(:, i) = group_mean;\n    group_means{i} = group_orig_mean;\n    var_names{i} = sprintf('Group%d', i);\nend\n\n% 将X从GPU移回CPU(如果需要)\nif isa(X, 'gpuArray')\n    X = gather(X);\nend\nif isa(y, 'gpuArray')\n    y = gather(y);\nend\nend\n\n%% 多重共线性检查函数 - 优化版\nfunction [X_cleaned, vif_values, removed_vars] = check_collinearity(X, var_names)\n% 检查并处理多重共线性\n% 输入:\n%   X - 自变量矩阵\n%   var_names - 变量名称\n% 输出:\n%   X_cleaned - 处理后的自变量矩阵\n%   vif_values - VIF值\n%   removed_vars - 被移除的变量标记\n\n% 计算相关矩阵 - 使用更高效的计算\nR = corr(X, 'Type', 'Pearson');\n\n% 检查相关矩阵\nif any(isnan(R(:))) || any(isinf(R(:)))\n    error('相关矩阵 R 包含 NaN 或 Inf，请检查输入数据！');\nend\n\n% 初始化输出变量\nremoved_vars = false(size(X, 2), 1);\nvif_values = zeros(size(X, 2), 1);\n\n% 优化：先检查矩阵的条件数而不是秩\ncond_num = cond(R);\nif cond_num > 30\n    log_message('warning', sprintf('相关矩阵条件数较高(%.2f)，可能存在多重共线性', cond_num));\n    \n    % 使用SVD代替直接求逆计算VIF，更数值稳定\n    [U, S, V] = svd(R);\n    s = diag(S);\n    \n    % 如果最小奇异值小于阈值，认为矩阵接近奇异\n    if min(s) < 1e-10\n        warning('MatrixError:NearSingular', '相关矩阵接近奇异，使用PCA处理多重共线性');\n        \n        % 使用主成分分析处理多重共线性\n        [~, score, ~, ~, explained] = pca(X, 'Algorithm', 'svd');\n        cum_var = cumsum(explained);\n        k = find(cum_var >= 95, 1, 'first'); % 保留解释95%方差的成分，提高保留信息\n        X_cleaned = score(:, 1:k);\n        \n        log_message('warning', sprintf('使用PCA降维，从%d个变量降至%d个主成分', size(X, 2), k));\n        \n        % 所有原始变量都被\"移除\"\n        removed_vars = true(size(X, 2), 1);\n        vif_values = ones(size(X, 2), 1) * Inf;\n        return;\n    else\n        % 使用SVD计算VIF\n        vif_values = zeros(size(X, 2), 1);\n        for i = 1:size(X, 2)\n            % 选择第i列作为因变量\n            y_i = X(:, i);\n            % 选择其他列作为自变量\n            X_i = X(:, setdiff(1:size(X, 2), i));\n            % 计算R²\n            b = X_i \\ y_i;\n            y_hat = X_i * b;\n            SS_total = sum((y_i - mean(y_i)).^2);\n            SS_residual = sum((y_i - y_hat).^2);\n            R_squared = 1 - SS_residual/SS_total;\n            % 计算VIF\n            vif_values(i) = 1 / (1 - R_squared);\n        end\n    end\nelse\n    % 条件良好，直接计算VIF\n    try\n        % 使用更高效的计算方法\n        vif_values = zeros(size(X, 2), 1);\n        for i = 1:size(X, 2)\n            % 使用线性回归而不是直接求逆计算VIF，数值更稳定\n            idx = setdiff(1:size(X, 2), i);\n            mdl = fitlm(X(:, idx), X(:, i));\n            vif_values(i) = 1 / (1 - mdl.Rsquared.Ordinary);\n        end\n    catch ME\n        log_message('warning', sprintf('VIF计算失败，使用SVD方法: %s', ME.message));\n        % 使用SVD方法作为备选\n        vif_values = ones(size(X, 2), 1) ./ diag(pinv(R));\n    end\nend\n\n% 输出VIF值\nlog_message('info', '自变量的VIF值：');\nfor i = 1:length(vif_values)\n    log_message('info', sprintf('%s: %.2f', var_names{i}, vif_values(i)));\nend\n\n% 找出高VIF值的变量 - 使用阈值为10\nhigh_vif = find(vif_values > 10);\nif ~isempty(high_vif)\n    log_message('warning', '移除高VIF变量索引：');\n    for i = 1:length(high_vif)\n        log_message('warning', sprintf('%s (VIF = %.2f)', var_names{high_vif(i)}, vif_values(high_vif(i))));\n    end\n    \n    % 移除高VIF值的变量\n    removed_vars(high_vif) = true;\n    X_cleaned = X(:, ~removed_vars);\n    \n    % 递归检查剩余变量的VIF\n    if sum(~removed_vars) > 1\n        log_message('info', '递归检查剩余变量的VIF值');\n        [X_cleaned_rec, vif_values_rec, removed_vars_rec] = check_collinearity(X_cleaned, var_names(~removed_vars));\n        \n        % 更新removed_vars以反映递归结果\n        still_removed = false(size(X, 2), 1);\n        still_removed(~removed_vars) = removed_vars_rec;\n        removed_vars = removed_vars | still_removed;\n        \n        X_cleaned = X_cleaned_rec;\n    end\nelse\n    X_cleaned = X;\nend\nend\n\n%% 变量相关性分析函数 - 优化版\nfunction [pca_results] = analyze_variable_correlations(X, var_names)\n% 分析变量之间的相关性\n% 输入:\n%   X - 自变量矩阵\n%   var_names - 变量名称\n% 输出:\n%   pca_results - PCA分析结果\n\n% 计算变量之间的相关性\nR = corr(X);\n\n% 创建更高分辨率的热图\nfig = figure('Name', '变量相关性矩阵', 'Position', [100, 100, 1000, 900]);\n\n% 使用更美观的热图\nh = heatmap(R, 'XDisplayLabels', var_names, 'YDisplayLabels', var_names);\nh.Title = '变量相关性矩阵';\nh.FontSize = 10;\nh.Colormap = parula;\n\n% 调整colorbar\ncaxis([-1, 1]);\ncolorbar;\n\n% 保存矢量图\nsave_figure(fig, 'results', 'variable_correlation', 'Formats', {'svg'});\nclose(fig);\n\n% 识别高度相关的变量对\n[rows, cols] = find(triu(abs(R) > 0.8, 1));\nif ~isempty(rows)\n    log_message('warning', '发现高度相关的变量对 (|r| > 0.8):');\n    for i = 1:length(rows)\n        log_message('warning', sprintf('%s 与 %s: r = %.2f', var_names{rows(i)}, var_names{cols(i)}, R(rows(i), cols(i))));\n    end\nelse\n    log_message('info', '未发现高度相关的变量对 (|r| > 0.8)');\nend\n\n% 增加主成分分析可视化 - 仅在变量较多时使用\npca_results = struct(); % 初始化PCA结果结构\n\nif length(var_names) > 3\n    try\n        % 执行PCA\n        [coeff, score, ~, ~, explained, mu] = pca(X);\n        \n        % 存储PCA结果\n        pca_results.coeff = coeff;\n        pca_results.score = score;\n        pca_results.explained = explained;\n        pca_results.mu = mu;\n        pca_results.cum_explained = cumsum(explained);\n        \n        % 创建PCA双线图\n        fig2 = figure('Name', '主成分分析', 'Position', [100, 100, 1200, 900]);\n        \n        % 绘制变量在前两个主成分上的投影\n        subplot(2, 2, 1);\n        biplot(coeff(:,1:2), 'Scores', score(:,1:2), 'VarLabels', var_names);\n        title('变量在主成分1-2上的投影');\n        grid on;\n        \n        % 绘制解释方差比例\n        subplot(2, 2, 2);\n        bar(explained);\n        xlabel('主成分');\n        ylabel('解释方差百分比');\n        title('各主成分解释方差比例');\n        grid on;\n        \n        % 绘制累积解释方差\n        subplot(2, 2, 3);\n        plot(cumsum(explained), 'o-', 'LineWidth', 2);\n        xlabel('主成分数量');\n        ylabel('累积解释方差百分比');\n        title('累积解释方差');\n        grid on;\n        \n        % 增加百分比标注\n        cum_explained = cumsum(explained);\n        hold on;\n        \n        % 选取几个关键点标注\n        key_components = [1, min(3, length(cum_explained)), min(5, length(cum_explained))];\n        for i = 1:length(key_components)\n            idx = key_components(i);\n            plot(idx, cum_explained(idx), 'ro', 'MarkerSize', 8, 'MarkerFaceColor', 'r');\n            text(idx, cum_explained(idx) + 2, sprintf('%.1f%%', cum_explained(idx)), ...\n                'HorizontalAlignment', 'center', 'FontSize', 9);\n        end\n        \n        % 绘制95%方差的线\n        idx_95 = find(cum_explained >= 95, 1, 'first');\n        if ~isempty(idx_95)\n            plot([0, idx_95, idx_95], [95, 95, 0], 'k--');\n            text(idx_95-0.5, 96, sprintf('95%%方差需要%d个主成分', idx_95), ...\n                'HorizontalAlignment', 'right', 'FontSize', 9);\n        end\n        \n        % 绘制变量对主成分的贡献\n        subplot(2, 2, 4);\n        imagesc(abs(coeff(:, 1:min(5, size(coeff, 2)))));\n        colorbar;\n        xlabel('主成分');\n        set(gca, 'YTick', 1:length(var_names), 'YTickLabel', var_names);\n        title('变量对前5个主成分的贡献(绝对值)');\n        \n        % 保存PCA图\n        save_figure(fig2, 'results', 'pca_analysis', 'Formats', {'svg'});\n        close(fig2);\n        \n        % 创建主成分累计方差表\n        cum_var_table = table((1:length(explained))', explained, cum_explained, ...\n            'VariableNames', {'Component', 'ExplainedVariance', 'CumulativeVariance'});\n        \n        % 输出累计方差\n        log_message('info', '主成分累计方差:');\n        key_idx = [1, 2, 3, min(5, length(cum_explained)), min(10, length(cum_explained))];\n        key_idx = unique(key_idx);\n        for i = 1:length(key_idx)\n            idx = key_idx(i);\n            log_message('info', sprintf('  前%d个主成分解释了%.2f%%的总方差', idx, cum_explained(idx)));\n        end\n        \n        % 创建新的累计方差图\n        fig3 = figure('Name', '主成分累计方差', 'Position', [100, 100, 900, 600]);\n        \n        % 绘制阶梯图\n        stairs(cum_explained, 'LineWidth', 2);\n        hold on;\n        \n        % 标记95%方差\n        if ~isempty(idx_95)\n            plot([0, idx_95], [95, 95], 'r--');\n            plot([idx_95, idx_95], [0, 95], 'r--');\n            text(idx_95 + 0.1, 60, sprintf('95%%方差需要%d个主成分', idx_95), ...\n                'FontSize', 10, 'Color', 'r');\n        end\n        \n        % 标记80%方差\n        idx_80 = find(cum_explained >= 80, 1, 'first');\n        if ~isempty(idx_80)\n            plot([0, idx_80], [80, 80], 'g--');\n            plot([idx_80, idx_80], [0, 80], 'g--');\n            text(idx_80 + 0.1, 40, sprintf('80%%方差需要%d个主成分', idx_80), ...\n                'FontSize', 10, 'Color', 'g');\n        end\n        \n        % 设置图形属性\n        xlabel('主成分数量', 'FontSize', 12, 'FontWeight', 'bold');\n        ylabel('累计解释方差百分比', 'FontSize', 12, 'FontWeight', 'bold');\n        title('主成分分析累计解释方差', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        xlim([0, min(15, length(explained))]);\n        ylim([0, 100]);\n        \n        % 保存图形\n        save_figure(fig3, 'results', 'cumulative_variance', 'Formats', {'svg'});\n        close(fig3);\n        \n        % 创建主成分载荷可视化\n        fig4 = figure('Name', '主成分载荷', 'Position', [100, 100, 1200, 600]);\n        \n        % 显示前3个主成分的载荷\n        num_pc = min(3, size(coeff, 2));\n        for i = 1:num_pc\n            subplot(1, num_pc, i);\n            bar(coeff(:, i));\n            xlabel('变量');\n            ylabel('载荷系数');\n            title(sprintf('主成分%d载荷', i));\n            set(gca, 'XTick', 1:length(var_names), 'XTickLabel', var_names, 'XTickLabelRotation', 45);\n            grid on;\n        end\n        \n        % 保存图形\n        save_figure(fig4, 'results', 'principal_component_loadings', 'Formats', {'svg'});\n        close(fig4);\n    catch ME\n        log_message('warning', sprintf('PCA可视化失败: %s', ME.message));\n    end\nend\nend\n\n%% Bootstrap抽样函数 - 优化版\nfunction [train_indices, test_indices] = bootstrap_sampling(y, train_ratio, n_samples)\n% 使用Bootstrap进行分层抽样\n% 输入:\n%   y - 因变量\n%   train_ratio - 训练集比例\n%   n_samples - 样本数量\n% 输出:\n%   train_indices - 训练集索引\n%   test_indices - 测试集索引\n\n% 找出各类别的索引\nclass_0_idx = find(y == 0);\nclass_1_idx = find(y == 1);\n\n% 预计算常量避免在parfor中重复计算\nn0 = length(class_0_idx);\nn1 = length(class_1_idx);\nn0_train = round(train_ratio * n0);\nn1_train = round(train_ratio * n1);\ntotal_samples = length(y);\n\n% 预分配结果数组\ntrain_indices = cell(n_samples, 1);\ntest_indices = cell(n_samples, 1);\n\n% 预分配随机种子数组确保并行迭代随机性\nrng_seeds = randi(1000000, n_samples, 1);\n\n% 创建逻辑索引数组提高效率\ntotal_mask = false(total_samples, n_samples);\n\n% 使用parfor并行处理\nparfor i = 1:n_samples\n    % 设置当前迭代的随机种子\n    rng(rng_seeds(i));\n    \n    % 对每个类别进行分层抽样\n    train_idx_0 = class_0_idx(randsample(n0, n0_train));\n    train_idx_1 = class_1_idx(randsample(n1, n1_train));\n    \n    % 合并训练集索引\n    train_idx = [train_idx_0; train_idx_1];\n    \n    % 使用逻辑索引代替setdiff提高性能\n    mask = false(total_samples, 1);\n    mask(train_idx) = true;\n    \n    % 存储训练集和测试集\n    train_indices{i} = train_idx;\n    test_indices{i} = find(~mask);\n    \n    % 存储total_mask\n    total_mask(:, i) = mask;\nend\n\n% 输出Bootstrap样本的统计信息\ntrain_sizes = cellfun(@length, train_indices);\ntest_sizes = cellfun(@length, test_indices);\nlog_message('info', sprintf('Bootstrap样本统计: 平均训练集大小=%.1f, 平均测试集大小=%.1f', ...\n    mean(train_sizes), mean(test_sizes)));\n\n% 计算样本覆盖率\ncoverage = mean(sum(total_mask, 2) > 0);\nlog_message('info', sprintf('数据覆盖率: %.2f%%', coverage * 100));\nend\n\n%% K折交叉验证函数 - 新增\nfunction results = k_fold_cross_validation(X, y, k, var_names)\n% 执行K折交叉验证来评估模型稳定性\n% 输入:\n%   X - 自变量矩阵\n%   y - 因变量\n%   k - 折数\n%   var_names - 变量名称（新增）\n% 输出:\n%   results - 交叉验证结果\n\n% 确认K值有效\nif k < 2\n    error('K值必须大于等于2');\nend\n\n% 获取总样本数\nn = length(y);\n\n% 如果K大于样本数，调整K\nif k > n\n    log_message('warning', sprintf('K值(%d)大于样本数(%d)，调整为%d', k, n, n));\n    k = n;\nend\n\n% 创建交叉验证分组\ncv = cvpartition(y, 'KFold', k);\n\n% 初始化性能指标结果\nresults = struct();\nresults.accuracy = zeros(k, 1);\nresults.precision = zeros(k, 1);\nresults.recall = zeros(k, 1);\nresults.specificity = zeros(k, 1);\nresults.f1_score = zeros(k, 1);\nresults.auc = zeros(k, 1);\nresults.aic = zeros(k, 1);     % 新增\nresults.bic = zeros(k, 1);     % 新增\nresults.coefs = cell(k, 1);\nresults.fold_indices = cell(k, 1);\nresults.y_pred = cell(k, 1);       % 新增\nresults.y_test = cell(k, 1);       % 新增\nresults.y_pred_prob = cell(k, 1);  % 新增\n\n% 记录每个模型的变量系数分布\nn_vars = size(X, 2);\nall_coefs = zeros(k, n_vars+1); % +1是因为有截距项\n\n% 对每个折执行训练和评估\nfor i = 1:k\n    % 获取当前折的训练集和测试集\n    train_idx = cv.training(i);\n    test_idx = cv.test(i);\n    \n    % 存储当前折的索引\n    results.fold_indices{i} = struct('train', find(train_idx), 'test', find(test_idx));\n    \n    % 使用训练集训练逻辑回归模型\n    try\n        % 使用更强大的fitglm函数\n        mdl = fitglm(X(train_idx, :), y(train_idx), 'Distribution', 'binomial', 'Link', 'logit');\n        \n        % 存储模型系数\n        coefs = mdl.Coefficients.Estimate;\n        results.coefs{i} = coefs;\n        all_coefs(i, :) = coefs';\n        \n        % 使用测试集预测\n        y_pred_prob = predict(mdl, X(test_idx, :));\n        y_pred = y_pred_prob > 0.5;\n        \n        % 保存预测结果\n        results.y_pred{i} = y_pred;\n        results.y_test{i} = y(test_idx);\n        results.y_pred_prob{i} = y_pred_prob;\n        \n        % 计算评估指标\n        y_test = y(test_idx);\n        \n        % 准确率\n        results.accuracy(i) = sum(y_pred == y_test) / length(y_test);\n        \n        % 计算混淆矩阵\n        TP = sum(y_pred == 1 & y_test == 1);\n        TN = sum(y_pred == 0 & y_test == 0);\n        FP = sum(y_pred == 1 & y_test == 0);\n        FN = sum(y_pred == 0 & y_test == 1);\n        \n        % 精确率\n        if (TP + FP) > 0\n            results.precision(i) = TP / (TP + FP);\n        else\n            results.precision(i) = 0;\n        end\n        \n        % 召回率/敏感性\n        if (TP + FN) > 0\n            results.recall(i) = TP / (TP + FN);\n        else\n            results.recall(i) = 0;\n        end\n        \n        % 特异性\n        if (TN + FP) > 0\n            results.specificity(i) = TN / (TN + FP);\n        else\n            results.specificity(i) = 0;\n        end\n        \n        % F1分数\n        if (results.precision(i) + results.recall(i)) > 0\n            results.f1_score(i) = 2 * (results.precision(i) * results.recall(i)) / (results.precision(i) + results.recall(i));\n        else\n            results.f1_score(i) = 0;\n        end\n        \n        % AUC\n        if length(unique(y_test)) > 1 % 确保正负样本都有\n            [~, ~, ~, auc] = perfcurve(y_test, y_pred_prob, 1);\n            results.auc(i) = auc;\n        else\n            results.auc(i) = NaN;\n        end\n        \n        % 计算AIC和BIC - 新增\n        deviance = mdl.Deviance;\n        n_params = length(coefs);\n        n_samples = sum(train_idx);\n        \n        results.aic(i) = deviance + 2 * n_params;\n        results.bic(i) = deviance + log(n_samples) * n_params;\n        \n    catch ME\n        log_message('warning', sprintf('第%d折交叉验证失败: %s', i, ME.message));\n        results.accuracy(i) = NaN;\n        results.precision(i) = NaN;\n        results.recall(i) = NaN;\n        results.specificity(i) = NaN;\n        results.f1_score(i) = NaN;\n        results.auc(i) = NaN;\n        results.aic(i) = NaN;\n        results.bic(i) = NaN;\n        results.coefs{i} = NaN(n_vars+1, 1);\n        all_coefs(i, :) = NaN(1, n_vars+1);\n    end\nend\n\n% 计算每个指标的平均值和标准差\n% 计算每个指标的平均值和标准差\nfields = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc', 'aic', 'bic'};\nfor j = 1:length(fields)\n    field = fields{j};\n    results.(['avg_' field]) = mean(results.(field), 'omitnan');\n    results.(['std_' field]) = std(results.(field), 'omitnan');\n    results.(['cv_' field]) = results.(['std_' field]) / results.(['avg_' field]); % 新增：变异系数\nend\n\n% 系数稳定性分析\nresults.coef_mean = mean(all_coefs, 'omitnan');\nresults.coef_std = std(all_coefs, 'omitnan');\nresults.coef_cv = abs(results.coef_std ./ results.coef_mean); % 变异系数\nresults.all_coefs = all_coefs;\n\n% 添加变量名字段\nresults.variables = cell(n_vars + 1, 1); % +1是因为有截距项\nresults.variables{1} = 'Intercept';\nfor i = 1:n_vars\n    if nargin > 3 && i <= length(var_names) % 检查是否传入了变量名\n        results.variables{i+1} = var_names{i};\n    else\n        results.variables{i+1} = sprintf('Var%d', i);\n    end\nend\n\n% 记录K折验证的整体情况\nlog_message('info', sprintf('K折交叉验证指标: 准确率=%.3f(±%.3f), 精确率=%.3f(±%.3f), 召回率=%.3f(±%.3f), F1=%.3f(±%.3f), AUC=%.3f(±%.3f), AIC=%.1f(±%.1f), BIC=%.1f(±%.1f)', ...\n    results.avg_accuracy, results.std_accuracy, ...\n    results.avg_precision, results.std_precision, ...\n    results.avg_recall, results.std_recall, ...\n    results.avg_f1_score, results.std_f1_score, ...\n    results.avg_auc, results.std_auc, ...\n    results.avg_aic, results.std_aic, ...\n    results.avg_bic, results.std_bic));\n\n% 创建K折交叉验证可视化\ncreate_kfold_visualization(results, k);\n\nend\n\n% 辅助函数：创建K折交叉验证可视化\nfunction create_kfold_visualization(results, k)\n% 创建K折交叉验证可视化\n% 输入:\n%   results - 交叉验证结果\n%   k - 折数\n\n% 创建图形\nfig = figure('Name', 'K-Fold Cross-Validation Results', 'Position', [100, 100, 1200, 900]);\n\n% 准备数据\nmetrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\nmetric_labels = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\ncolors = lines(length(metrics));\n\n% 创建子图1：各折对比\nsubplot(2, 2, 1);\nhold on;\n\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    values = results.(metric);\n    \n    % 绘制折线\n    plot(1:k, values, 'o-', 'LineWidth', 1.5, 'Color', colors(i,:), 'DisplayName', metric_labels{i});\n    \n    % 绘制均值线\n    mean_val = results.(['avg_' metric]);\n    plot([0.5, k+0.5], [mean_val, mean_val], '--', 'Color', colors(i,:), 'LineWidth', 1, 'HandleVisibility', 'off');\nend\n\n% 设置图形属性\nxlabel('折数', 'FontSize', 12);\nylabel('性能值', 'FontSize', 12);\ntitle('K折交叉验证各折性能', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\nlegend('Location', 'best', 'FontSize', 9);\nxlim([0.5, k+0.5]);\nylim([0, 1.05]);\nset(gca, 'XTick', 1:k);\n\n% 创建子图2：性能指标比较\nsubplot(2, 2, 2);\n\n% 准备数据\nmean_values = zeros(length(metrics), 1);\nstd_values = zeros(length(metrics), 1);\n\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    mean_values(i) = results.(['avg_' metric]);\n    std_values(i) = results.(['std_' metric]);\nend\n\n% 创建条形图\nbar_h = bar(mean_values);\nset(bar_h, 'FaceColor', 'flat');\nfor i = 1:length(metrics)\n    bar_h.CData(i,:) = colors(i,:);\nend\n\n% 添加误差线\nhold on;\nerrorbar(1:length(metrics), mean_values, std_values, '.k');\n\n% 设置图形属性\nset(gca, 'XTick', 1:length(metrics), 'XTickLabel', metric_labels, 'XTickLabelRotation', 45);\nylabel('平均值', 'FontSize', 12);\ntitle('各性能指标均值和标准差', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\nylim([0, 1.05]);\n\n% 添加数值标签\nfor i = 1:length(metrics)\n    text(i, mean_values(i) + std_values(i) + 0.03, sprintf('%.3f±%.3f', mean_values(i), std_values(i)), ...\n        'HorizontalAlignment', 'center', 'FontSize', 9);\nend\n\n% 创建子图3：参数统计\nsubplot(2, 2, 3);\n\n% 准备AIC和BIC数据\naic_values = results.aic;\nbic_values = results.bic;\n\n% 创建箱线图\nboxplot([aic_values, bic_values], 'Labels', {'AIC', 'BIC'}, 'Notch', 'on');\nylabel('值', 'FontSize', 12);\ntitle('AIC和BIC分布', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\n\n% 添加均值和标准差\ntext(1, max(aic_values) + 0.1 * range(aic_values), sprintf('均值: %.1f\\n标准差: %.1f', results.avg_aic, results.std_aic), ...\n    'HorizontalAlignment', 'center', 'FontSize', 9);\ntext(2, max(bic_values) + 0.1 * range(bic_values), sprintf('均值: %.1f\\n标准差: %.1f', results.avg_bic, results.std_bic), ...\n    'HorizontalAlignment', 'center', 'FontSize', 9);\n\n% 创建子图4：系数稳定性\nsubplot(2, 2, 4);\n\n% 排除截距，只分析变量系数\ncoef_cv = results.coef_cv(2:end);\nvar_names = results.variables(2:end);\n\n% 按变异系数排序\n[sorted_cv, idx] = sort(coef_cv, 'descend');\nsorted_vars = var_names(idx);\n\n% 限制显示的变量数量\nmax_vars = min(10, length(sorted_vars));\nsorted_cv = sorted_cv(1:max_vars);\nsorted_vars = sorted_vars(1:max_vars);\n\n% 创建条形图\nbar_h = barh(sorted_cv);\nset(bar_h, 'FaceColor', [0.3, 0.6, 0.8]);\n\n% 设置图形属性\nset(gca, 'YTick', 1:max_vars, 'YTickLabel', sorted_vars);\nxlabel('变异系数 (CV)', 'FontSize', 12);\ntitle('系数稳定性分析 (CV)', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\n\n% 添加阈值线\nhold on;\nplot([0.5, 0.5], [0, max_vars+1], 'r--', 'LineWidth', 1.5);\ntext(0.52, 1, '不稳定阈值 (CV>0.5)', 'Color', 'r', 'FontSize', 9, 'VerticalAlignment', 'bottom');\n\n% 保存图形\nsgtitle(sprintf('K折交叉验证分析 (K=%d)', k), 'FontSize', 16, 'FontWeight', 'bold');\nset(gcf, 'Color', 'white');\n\n% 保存为图像\n    save_figure(fig, 'results', 'kfold_visualization', 'Formats', {'svg'});\nclose(fig);\nend\n\n%% 变量选择函数 - 优化版\nfunction [selected_vars, var_freq, var_combinations] = select_variables(X, y, train_indices, method)\n% 使用不同方法进行变量选择，并保存每次选择的变量组合\n% 输入:\n%   X - 自变量矩阵\n%   y - 因变量\n%   train_indices - 训练集索引\n%   method - 方法名称\n% 输出:\n%   selected_vars - 总体选中的变量\n%   var_freq - 变量选择频率\n%   var_combinations - 每次迭代选择的变量组合\n\nn_samples = length(train_indices);\nn_vars = size(X, 2);\n\n% 初始化变量选择频率计数\nvar_selection_count = zeros(n_vars, 1);\n\n% 初始化变量组合存储\nvar_combinations = cell(n_samples, 1);\n\n% 优化并行设置 - 适合i9处理器\nUseParallel = true;\nopts = statset('UseParallel', UseParallel, 'Display', 'off');\n\n% 更密集的lambda范围提高模型质量\nlambda_range = logspace(-5, 1, 50);  \n\n% 使用parfor并行处理\nparfor i = 1:n_samples\n    % 获取当前训练集\n    X_train = X(train_indices{i}, :);\n    y_train = y(train_indices{i});\n    \n    % 根据方法选择变量\n    selected = false(1, n_vars);\n    \n    switch lower(method)\n        case 'stepwise'\n            % 逐步回归 - 优化P值阈值\n            [~, ~, ~, inmodel] = stepwisefit(X_train, y_train, 'PEnter', 0.15, 'PRemove', 0.20, 'Display', 'off');\n            selected = inmodel;\n            \n        case 'lasso'\n            % LASSO回归 - 增加交叉验证折数\n            [B, FitInfo] = lasso(X_train, y_train, 'CV', 10, ...\n                                'Options', opts, 'Alpha', 1, 'Lambda', lambda_range);\n            lambda_min = FitInfo.LambdaMinMSE;\n            coef = B(:, FitInfo.Lambda == lambda_min);\n            selected = abs(coef) > 0;\n            \n        case 'ridge'\n            % Ridge回归 - 针对i9优化alpha值\n            [~, FitInfo] = lasso(X_train, y_train, 'CV', 10, 'Alpha', 0.001, 'Lambda', lambda_range, 'Options', opts);\n            lambda_min = FitInfo.LambdaMinMSE;\n            B = ridge(y_train, X_train, lambda_min, 0);\n            % 使用自适应阈值\n            threshold = max(0.05, std(B(2:end)) * 0.1);\n            selected = abs(B(2:end)) > threshold;\n            \n        case 'elasticnet'\n            % Elastic Net - 使用中等alpha值\n            [B, FitInfo] = lasso(X_train, y_train, 'CV', 10, ...\n                                'Options', opts, 'Alpha', 0.5, 'Lambda', lambda_range);\n            lambda_min = FitInfo.LambdaMinMSE;\n            coef = B(:, FitInfo.Lambda == lambda_min);\n            selected = abs(coef) > 0;\n            \n        case 'randomforest'\n            % Random Forest - 增加并行控制参数和性能优化\n            if exist('TreeBagger', 'file')\n                % 创建高级并行选项 - 移除 CompileOptions 参数\n                parallelOptions = statset('UseParallel', true, 'UseSubstreams', true);\n                \n                % 使用更多树和更高效的参数配置\n                mdl = TreeBagger(200, X_train, y_train, 'Method', 'classification', ...\n                    'OOBPrediction', 'on', 'OOBPredictorImportance', 'on', ...\n                    'MinLeafSize', max(1, floor(size(X_train,1)/50)), ...\n                    'NumPredictorsToSample', max(1, floor(sqrt(size(X_train,2)))), ...\n                    'Options', parallelOptions, ...\n                    'PredictorSelection', 'curvature', ...  % 添加曲率测试提高变量选择效率\n                    'MaxNumSplits', 1e4, ... % 限制分裂数量提高速度\n                    'Surrogate', 'off'); % 关闭替代分裂以提高速度\n                    \n                imp = mdl.OOBPermutedPredictorDeltaError;\n                selected = imp > mean(imp);\n                \n                % 使用后立即清除大对象\n                mdl = [];\n            else\n                % 如果没有TreeBagger，使用简单的相关系数筛选\n                [~, pval] = corr(X_train, y_train);\n                selected = pval < 0.05;\n            end\n\n            \n        otherwise\n            error('不支持的变量选择方法: %s', method);\n    end\n    \n    % 保存当前迭代选择的变量组合\n    var_combinations{i} = find(selected);\n    \n    % 如果没有变量被选中，选择相关性最高的3个变量\n    if isempty(var_combinations{i})\n        [~, idx] = sort(abs(corr(X_train, y_train)), 'descend');\n        var_combinations{i} = idx(1:min(3, length(idx)));\n    end\nend\n\n% 统计选择频率\nfor i = 1:n_samples\n    selected = false(n_vars, 1);\n    selected(var_combinations{i}) = true;\n    var_selection_count = var_selection_count + selected;\nend\n\n% 计算变量选择频率\nvar_freq = var_selection_count / n_samples;\n\n% 确保var_freq的长度与n_vars一致\nif length(var_freq) ~= n_vars\n    log_message('warning', sprintf('变量频率长度(%d)与变量数量(%d)不匹配，进行调整', length(var_freq), n_vars));\n    if length(var_freq) < n_vars\n        tmp = zeros(n_vars, 1);\n        tmp(1:length(var_freq)) = var_freq;\n        var_freq = tmp;\n    else\n        var_freq = var_freq(1:n_vars);\n    end\nend\n\n% 将变量组合转换为字符串表示，以便统计频率\ncombo_strings = cellfun(@(x) sprintf('%d,', sort(x)), var_combinations, 'UniformOutput', false);\n[unique_combos, ~, ic] = unique(combo_strings);\ncombo_counts = accumarray(ic, 1);\n\n% 找出出现频率最高的变量组合\n[~, max_idx] = max(combo_counts);\nmost_frequent_combo = unique_combos{max_idx};\n\n% 从字符串中提取变量索引\ncombo_indices = str2num(['[' most_frequent_combo(1:end-1) ']']);\n\n% 使用最频繁的变量组合作为总体选择的变量\nselected_vars = false(n_vars, 1);\nselected_vars(combo_indices) = true;\n\n% 记录最频繁的变量组合\nlog_message('info', sprintf('使用出现频率最高的变量组合作为总体变量 (出现%d次，占比%.2f%%)', ...\n    combo_counts(max_idx), 100*combo_counts(max_idx)/n_samples));\nlog_message('info', sprintf('选择的变量索引: %s', mat2str(combo_indices)));\n\n% 删除重复的变量组合并统计每种组合的出现次数\n[unique_combinations, ~, ic] = unique(cellfun(@(x) sprintf('%d,', sort(x)), var_combinations, 'UniformOutput', false));\ncombination_counts = accumarray(ic, 1);\n\n% 按出现次数排序\n[sorted_counts, idx] = sort(combination_counts, 'descend');\nsorted_combinations = unique_combinations(idx);\n\n% 打印前5个最常见的变量组合\nlog_message('info', sprintf('前%d个最常见的变量组合:', min(5, length(sorted_combinations))));\nfor i = 1:min(5, length(sorted_combinations))\n    log_message('info', sprintf('组合 #%d (出现%d次): %s', i, sorted_counts(i), sorted_combinations{i}));\nend\nend\n\n%% 模型训练和评估函数 - 修改版，增加更多评估指标\nfunction [models, overall_performance, group_performance] = train_and_evaluate_models_with_groups(X, y, train_indices, test_indices, var_combinations, method, var_names)\n    n_samples = length(train_indices);\n\n    % 初始化结果\n    models = cell(n_samples, 1);\n    perf_template = struct(...\n        'accuracy', 0, ...\n        'sensitivity', 0, ...\n        'specificity', 0, ...\n        'precision', 0, ...\n        'f1_score', 0, ...\n        'auc', 0, ...\n        'aic', 0, ...\n        'bic', 0, ...\n        'count', 0, ...\n        'variables', {{}});\n\n    % 初始化性能指标数组\n    accuracy_values = zeros(n_samples, 1);\n    sensitivity_values = zeros(n_samples, 1);\n    specificity_values = zeros(n_samples, 1);\n    precision_values = zeros(n_samples, 1);\n    f1_score_values = zeros(n_samples, 1);\n    auc_values = zeros(n_samples, 1);\n    aic_values = zeros(n_samples, 1);\n    bic_values = zeros(n_samples, 1);\n\n    % 初始化预测结果存储\n    y_pred_all = cell(n_samples, 1);\n    y_test_all = cell(n_samples, 1);\n    y_pred_prob_all = cell(n_samples, 1);\n\n    % 预分配数组以存储组合键和性能\n    combo_keys = cell(n_samples, 1);\n    perf_structs = cell(n_samples, 1);\n    all_coefs = cell(n_samples, 1);\n\n    % 使用parfor并行处理\n    parfor i = 1:n_samples\n        % 初始化临时变量，避免警告\n        y_pred_prob = [];\n        y_pred = [];\n        coefs = [];\n        aic = NaN;  % 初始化为NaN\n        bic = NaN;  % 初始化为NaN\n\n        % 获取当前训练集和测试集\n        train_idx = train_indices{i};\n        test_idx = test_indices{i};\n\n        % 获取当前迭代的变量组合\n        selected_vars = var_combinations{i};\n        X_selected = X(:, selected_vars);\n\n        % 训练模型\n        local_mdl = [];\n        switch lower(method)\n            case {'stepwise', 'lasso', 'ridge', 'elasticnet'}\n                local_mdl = fitglm(X_selected(train_idx, :), y(train_idx), ...\n                    'Distribution', 'binomial', 'Link', 'logit', ...\n                    'Intercept', true, 'PredictorVars', 1:size(X_selected, 2));\n                \n                coefs = local_mdl.Coefficients.Estimate;\n                y_pred_prob = predict(local_mdl, X_selected(test_idx, :));\n                y_pred = y_pred_prob > 0.5;\n                \n                deviance = local_mdl.Deviance;\n                n_params = length(coefs);\n                n_samples_iter = length(train_idx);\n                aic = deviance + 2 * n_params;\n                bic = deviance + log(n_samples_iter) * n_params;\n\n            case 'randomforest'\n                parallelOptions = statset('UseParallel', true);\n                \n                if exist('TreeBagger', 'file')\n                    local_mdl = TreeBagger(250, X_selected(train_idx, :), y(train_idx), ...\n                        'Method', 'classification', ...\n                        'OOBPrediction', 'on', ...\n                        'OOBPredictorImportance', 'on', ...\n                        'MinLeafSize', max(1, floor(length(train_idx)/50)), ...\n                        'NumPredictorsToSample', max(1, floor(sqrt(size(X_selected, 2)))), ...\n                        'Options', parallelOptions, ...\n                        'PredictorSelection', 'curvature', ...\n                        'SplitCriterion', 'gdi', ...\n                        'MaxNumSplits', 1e4, ...\n                        'Surrogate', 'off');\n                    \n                    coefs = local_mdl.OOBPermutedPredictorDeltaError;\n                    [y_pred_class, y_pred_scores] = predict(local_mdl, X_selected(test_idx, :));\n                    y_pred = str2double(y_pred_class) > 0.5;\n                    y_pred_prob = y_pred_scores(:, 2);\n                    \n                    % 修改点：使用oobError方法计算OOB误差\n                    oob_err_vec = oobError(local_mdl);\n                    oob_error = oob_err_vec(end);\n                    n_trees = local_mdl.NumTrees;\n                    n_predictors = size(X_selected, 2);\n                    \n                    aic = oob_error * length(train_idx) + 2 * (n_trees + n_predictors);\n                    bic = oob_error * length(train_idx) + log(length(train_idx)) * (n_trees + n_predictors);\n                else\n                    local_mdl = fitglm(X_selected(train_idx, :), y(train_idx), 'Distribution', 'binomial', 'Link', 'logit');\n                    coefs = local_mdl.Coefficients.Estimate;\n                    y_pred_prob = predict(local_mdl, X_selected(test_idx, :));\n                    y_pred = y_pred_prob > 0.5;\n                    \n                    deviance = local_mdl.Deviance;\n                    n_params = length(coefs);\n                    n_samples_iter = length(train_idx);\n                    aic = deviance + 2 * n_params;\n                    bic = deviance + log(n_samples_iter) * n_params;\n                end\n        end\n\n        % 存储模型和系数\n        models{i} = local_mdl;\n        all_coefs{i} = coefs;\n\n        % 存储预测结果\n        y_pred_all{i} = y_pred;\n        y_test_all{i} = y(test_idx);\n        y_pred_prob_all{i} = y_pred_prob;\n\n        % 计算性能指标\n        y_test = y(test_idx);\n        accuracy = sum(y_pred == y_test) / length(y_test);\n        \n        TP = sum(y_pred == 1 & y_test == 1);\n        TN = sum(y_pred == 0 & y_test == 0);\n        FP = sum(y_pred == 1 & y_test == 0);\n        FN = sum(y_pred == 0 & y_test == 1);\n        \n        sensitivity = TP / max(1, (TP + FN));\n        specificity = TN / max(1, (TN + FP));\n        precision = TP / max(1, (TP + FP));\n        f1_score = 2 * (precision * sensitivity) / max(1, (precision + sensitivity));\n        \n        auc = 0.5;\n        if length(unique(y_test)) > 1\n            try\n                [~, ~, ~, auc] = perfcurve(y_test, y_pred_prob, 1);\n            catch\n                auc = 0.5;\n            end\n        end\n\n        % 存储性能指标\n        accuracy_values(i) = accuracy;\n        sensitivity_values(i) = sensitivity;\n        specificity_values(i) = specificity;\n        precision_values(i) = precision;\n        f1_score_values(i) = f1_score;\n        auc_values(i) = auc;\n        aic_values(i) = aic;\n        bic_values(i) = bic;\n\n        % 创建变量组合的唯一标识符\n        combo_key = sprintf('%s', mat2str(sort(selected_vars)));\n        combo_keys{i} = combo_key;\n\n        % 创建性能结构\n        perf = perf_template;\n        perf.accuracy = accuracy;\n        perf.sensitivity = sensitivity;\n        perf.specificity = specificity;\n        perf.precision = precision;\n        perf.f1_score = f1_score;\n        perf.auc = auc;\n        perf.aic = aic;\n        perf.bic = bic;\n        perf.count = 1;\n        perf.variables = var_names(selected_vars);\n        perf_structs{i} = perf;\n    end\n\n    % 构建整体性能结构\n    overall_performance = struct();\n    overall_performance.accuracy = accuracy_values;\n    overall_performance.sensitivity = sensitivity_values;\n    overall_performance.specificity = specificity_values;\n    overall_performance.precision = precision_values;\n    overall_performance.f1_score = f1_score_values;\n    overall_performance.auc = auc_values;\n    overall_performance.aic = aic_values;\n    overall_performance.bic = bic_values;\n    overall_performance.avg_accuracy = mean(accuracy_values);\n    overall_performance.avg_sensitivity = mean(sensitivity_values);\n    overall_performance.avg_specificity = mean(specificity_values);\n    overall_performance.avg_precision = mean(precision_values);\n    overall_performance.avg_f1_score = mean(f1_score_values);\n    overall_performance.avg_auc = nanmean(auc_values);\n    overall_performance.avg_aic = nanmean(aic_values);\n    overall_performance.avg_bic = nanmean(bic_values);\n    overall_performance.std_accuracy = std(accuracy_values);\n    overall_performance.std_sensitivity = std(sensitivity_values);\n    overall_performance.std_specificity = std(specificity_values);\n    overall_performance.std_precision = std(precision_values);\n    overall_performance.std_f1_score = std(f1_score_values);\n    overall_performance.std_auc = nanstd(auc_values);\n    overall_performance.std_aic = nanstd(aic_values);\n    overall_performance.std_bic = nanstd(bic_values);\n    overall_performance.all_coefs = all_coefs;\n    overall_performance.y_pred = y_pred_all;\n    overall_performance.y_test = y_test_all;\n    overall_performance.y_pred_prob = y_pred_prob_all;\n\n    % 合并组合性能\n    [unique_keys, ~, ic] = unique(combo_keys);\n    n_unique_combos = length(unique_keys);\n    group_performance = repmat(perf_template, n_unique_combos, 1);\n\n    for i = 1:n_unique_combos\n        combo_indices = find(ic == i);\n        first_idx = combo_indices(1);\n        group_performance(i).variables = perf_structs{first_idx}.variables;\n        group_performance(i).count = length(combo_indices);\n        \n        acc_sum = 0; sens_sum = 0; spec_sum = 0; prec_sum = 0; f1_sum = 0; auc_sum = 0; aic_sum = 0; bic_sum = 0;\n        for j = 1:length(combo_indices)\n            idx = combo_indices(j);\n            acc_sum = acc_sum + perf_structs{idx}.accuracy;\n            sens_sum = sens_sum + perf_structs{idx}.sensitivity;\n            spec_sum = spec_sum + perf_structs{idx}.specificity;\n            prec_sum = prec_sum + perf_structs{idx}.precision;\n            f1_sum = f1_sum + perf_structs{idx}.f1_score;\n            auc_sum = auc_sum + perf_structs{idx}.auc;\n            aic_sum = aic_sum + perf_structs{idx}.aic;\n            bic_sum = bic_sum + perf_structs{idx}.bic;\n        end\n        \n        group_performance(i).accuracy = acc_sum / length(combo_indices);\n        group_performance(i).sensitivity = sens_sum / length(combo_indices);\n        group_performance(i).specificity = spec_sum / length(combo_indices);\n        group_performance(i).precision = prec_sum / length(combo_indices);\n        group_performance(i).f1_score = f1_sum / length(combo_indices);\n        group_performance(i).auc = auc_sum / length(combo_indices);\n        group_performance(i).aic = aic_sum / length(combo_indices);\n        group_performance(i).bic = bic_sum / length(combo_indices);\n    end\n\n    % 按出现次数排序\n    [~, idx] = sort([group_performance.count], 'descend');\n    group_performance = group_performance(idx);\n\n    % 记录最常见的变量组合\n    top_n = min(5, length(group_performance));\n    log_message('info', sprintf('前%d个最常见的变量组合的性能:', top_n));\n    for i = 1:top_n\n        combo = group_performance(i);\n        var_str = strjoin(cellfun(@(x) x, combo.variables, 'UniformOutput', false), ', ');\n        log_message('info', sprintf('组合 #%d (出现%d次, AUC=%.3f, F1=%.3f, AIC=%.1f, BIC=%.1f): %s', ...\n            i, combo.count, combo.auc, combo.f1_score, combo.aic, combo.bic, var_str));\n    end\nend\n\n%% 残差分析函数\nfunction create_residual_analysis(results, methods, figure_dir)\n% 创建残差分析和可视化\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   figure_dir - 图形保存目录\n\n% 对每种方法执行残差分析\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    % 检查该方法是否适合残差分析（逻辑回归模型）\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        \n        % 获取预测结果\n        if isfield(results.(method).performance, 'y_pred_prob') && ...\n           isfield(results.(method).performance, 'y_test')\n            \n            y_pred_prob = results.(method).performance.y_pred_prob;\n            y_test = results.(method).performance.y_test;\n            \n            % 合并所有Bootstrap样本的数据\n            all_probs = [];\n            all_labels = [];\n            \n            for j = 1:length(y_pred_prob)\n                if ~isempty(y_pred_prob{j}) && ~isempty(y_test{j})\n                    all_probs = [all_probs; y_pred_prob{j}];\n                    all_labels = [all_labels; y_test{j}];\n                end\n            end\n            \n            if ~isempty(all_probs) && ~isempty(all_labels)\n                % 计算对数几率\n                logodds = log(all_probs ./ (1 - all_probs));\n                \n                % 计算残差（皮尔森残差）\n                residuals = (all_labels - all_probs) ./ sqrt(all_probs .* (1 - all_probs));\n                \n                % 计算Deviance残差\n                deviance_residuals = sign(all_labels - all_probs) .* ...\n                    sqrt(-2 * (all_labels .* log(all_probs) + (1 - all_labels) .* log(1 - all_probs)));\n                \n                % 创建残差分析图\n                fig = figure('Name', sprintf('%s Residual Analysis', method), 'Position', [100, 100, 1200, 900]);\n                \n                % 创建2x3的子图布局，而不是2x2\n                % 创建子图1：皮尔森残差 vs 预测概率\n                subplot(2, 3, 1);\n                scatter(all_probs, residuals, 30, 'filled', 'MarkerFaceAlpha', 0.6);\n                hold on;\n                plot([0, 1], [0, 0], 'k--');\n                xlabel('预测概率', 'FontSize', 10);\n                ylabel('皮尔森残差', 'FontSize', 10);\n                title('皮尔森残差 vs 预测概率', 'FontSize', 12);\n                grid on;\n                \n                % 添加平滑曲线\n                try\n                    [xData, yData] = prepareCurveData(all_probs, residuals);\n                    smoothed = smooth(xData, yData, 0.2, 'loess');\n                    plot(xData, smoothed, 'r-', 'LineWidth', 2);\n                catch\n                    % 如果平滑失败，忽略\n                end\n                % 创建子图2：Deviance残差 vs 预测概率\n                subplot(2, 3, 2);\n                scatter(all_probs, deviance_residuals, 30, 'filled', 'MarkerFaceAlpha', 0.6);\n                hold on;\n                plot([0, 1], [0, 0], 'k--');\n                xlabel('预测概率', 'FontSize', 10);\n                ylabel('Deviance残差', 'FontSize', 10);\n                title('Deviance残差 vs 预测概率', 'FontSize', 12);\n                grid on;\n                \n                % 添加平滑曲线\n                try\n                    [xData, yData] = prepareCurveData(all_probs, deviance_residuals);\n                    smoothed = smooth(xData, yData, 0.2, 'loess');\n                    plot(xData, smoothed, 'r-', 'LineWidth', 2);\n                catch\n                    % 如果平滑失败，忽略\n                end\n                \n                % 创建子图3：皮尔森残差箱线图\n                subplot(2, 3, 3);\n                boxplot(residuals, all_labels, 'Labels', {'0', '1'});\n                ylabel('皮尔森残差', 'FontSize', 10);\n                title('按实际类别分组的皮尔森残差', 'FontSize', 12);\n                grid on;\n                \n                % 创建子图4：Deviance残差箱线图 (新增)\n                subplot(2, 3, 4);\n                boxplot(deviance_residuals, all_labels, 'Labels', {'0', '1'});\n                ylabel('Deviance残差', 'FontSize', 10);\n                title('按实际类别分组的Deviance残差', 'FontSize', 12);\n                grid on;\n                \n                % 创建子图5：皮尔森残差QQ图\n                subplot(2, 3, 5);\n                qqplot(residuals);\n                title('皮尔森残差QQ图', 'FontSize', 12);\n                grid on;\n                \n                % 创建子图6：Deviance残差QQ图 (新增)\n                subplot(2, 3, 6);\n                qqplot(deviance_residuals);\n                title('Deviance残差QQ图', 'FontSize', 12);\n                grid on;\n                % 添加总标题\n                sgtitle(sprintf('%s方法的残差分析', method), 'FontSize', 14, 'FontWeight', 'bold');\n                \n                % 保存图形\n                save_figure(fig, figure_dir, sprintf('%s_residual_analysis', method), 'Formats', {'svg'});\n                close(fig);\n                \n                % 创建残差汇总统计表\n                stats = struct();\n                stats.method = method;\n                stats.pearson_mean = mean(residuals);\n                stats.pearson_std = std(residuals);\n                stats.pearson_min = min(residuals);\n                stats.pearson_max = max(residuals);\n                stats.pearson_skewness = skewness(residuals);\n                stats.pearson_kurtosis = kurtosis(residuals);\n                stats.deviance_mean = mean(deviance_residuals);\n                stats.deviance_std = std(deviance_residuals);\n                stats.deviance_min = min(deviance_residuals);  % 新增\n                stats.deviance_max = max(deviance_residuals);  % 新增\n                stats.deviance_skewness = skewness(deviance_residuals);  % 新增\n                stats.deviance_kurtosis = kurtosis(deviance_residuals);  % 新增\n                \n                % 输出残差统计信息\n                log_message('info', sprintf('%s方法残差统计:', method));\n                log_message('info', sprintf('皮尔森残差: 均值=%.3f, 标准差=%.3f, 偏度=%.3f, 峰度=%.3f', ...\n                    stats.pearson_mean, stats.pearson_std, stats.pearson_skewness, stats.pearson_kurtosis));\n                log_message('info', sprintf('Deviance残差: 均值=%.3f, 标准差=%.3f, 偏度=%.3f, 峰度=%.3f', ...\n                    stats.deviance_mean, stats.deviance_std, stats.deviance_skewness, stats.deviance_kurtosis));\n                \n                % 检测潜在的异常点\n                pearson_outliers = abs(residuals) > 2.5;\n                deviance_outliers = abs(deviance_residuals) > 2.5;\n                \n                if any(pearson_outliers)\n                    log_message('info', sprintf('%s方法检测到%d个皮尔森残差异常点(|残差|>2.5)', ...\n                        method, sum(pearson_outliers)));\n                end\n                \n                if any(deviance_outliers)\n                    log_message('info', sprintf('%s方法检测到%d个Deviance残差异常点(|残差|>2.5)', ...\n                        method, sum(deviance_outliers)));\n                end\n                else\n                log_message('warning', sprintf('%s方法没有足够的预测数据进行残差分析', method));\n            end\n        else\n            log_message('warning', sprintf('%s方法缺少预测概率或真实标签数据，无法进行残差分析', method));\n        end\n    else\n        log_message('info', sprintf('%s方法不适用于传统残差分析', method));\n    end\nend\n\n% 创建所有方法的残差比较图\ntry\n    % 收集所有方法的残差数据\n    methods_with_residuals = {};\n    all_pearson_residuals = {};\n    all_deviance_residuals = {};  % 新增\n    \n    for i = 1:length(methods)\n        method = methods{i};\n        \n        % 检查该方法是否适合残差分析（逻辑回归模型）\n        if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n            \n            % 获取预测结果\n            if isfield(results.(method).performance, 'y_pred_prob') && ...\n               isfield(results.(method).performance, 'y_test')\n                \n                y_pred_prob = results.(method).performance.y_pred_prob;\n                y_test = results.(method).performance.y_test;\n                \n                % 合并所有Bootstrap样本的数据\n                all_probs = [];\n                all_labels = [];\n                \n                for j = 1:length(y_pred_prob)\n                    if ~isempty(y_pred_prob{j}) && ~isempty(y_test{j})\n                        all_probs = [all_probs; y_pred_prob{j}];\n                        all_labels = [all_labels; y_test{j}];\n                    end\n                end\n                \n                if ~isempty(all_probs) && ~isempty(all_labels)\n                    % 计算皮尔森残差\n                    pearson_residuals = (all_labels - all_probs) ./ sqrt(all_probs .* (1 - all_probs));\n                    \n                    % 计算Deviance残差\n                    deviance_residuals = sign(all_labels - all_probs) .* ...\n                        sqrt(-2 * (all_labels .* log(all_probs) + (1 - all_labels) .* log(1 - all_probs)));\n                    \n                    % 保存方法名和残差\n                    methods_with_residuals{end+1} = method;\n                    all_pearson_residuals{end+1} = pearson_residuals;\n                    all_deviance_residuals{end+1} = deviance_residuals;  % 新增\n                end\n            end\n        end\n    end\n    if length(methods_with_residuals) >= 2\n        % 创建残差比较图 - 皮尔森残差\n        fig1 = figure('Name', 'Pearson Residuals Comparison', 'Position', [100, 100, 1000, 600]);\n        \n        % 创建箱线图比较\n        boxplot(cell2mat(all_pearson_residuals), repelem(1:length(methods_with_residuals), cellfun(@length, all_pearson_residuals)), ...\n            'Labels', methods_with_residuals, 'Notch', 'on');\n        \n        % 设置图形属性\n        ylabel('皮尔森残差', 'FontSize', 12, 'FontWeight', 'bold');\n        title('各方法皮尔森残差分布比较', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加零线\n        hold on;\n        plot(xlim, [0 0], 'k--');\n        \n        % 保存图形\n        save_figure(fig1, figure_dir, 'pearson_residuals_comparison', 'Formats', {'svg'});\n        close(fig1);\n        \n        % 创建残差比较图 - Deviance残差 (新增)\n        fig2 = figure('Name', 'Deviance Residuals Comparison', 'Position', [100, 100, 1000, 600]);\n        \n        % 创建箱线图比较\n        boxplot(cell2mat(all_deviance_residuals), repelem(1:length(methods_with_residuals), cellfun(@length, all_deviance_residuals)), ...\n            'Labels', methods_with_residuals, 'Notch', 'on');\n        \n        % 设置图形属性\n        ylabel('Deviance残差', 'FontSize', 12, 'FontWeight', 'bold');\n        title('各方法Deviance残差分布比较', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加零线\n        hold on;\n        plot(xlim, [0 0], 'k--');\n        \n        % 保存图形\n        save_figure(fig2, figure_dir, 'deviance_residuals_comparison', 'Formats', {'svg'});\n        close(fig2);\n    end\ncatch ME\n    log_message('warning', sprintf('创建残差比较图失败: %s', ME.message));\nend\nend\n\n%% 修改4：改进系数维度与变量组合维度不匹配的处理\nfunction coef_stability = monitor_coefficient_stability(results, methods, var_names)\n% 监控模型系数的稳定性\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   var_names - 变量名称\n% 输出:\n%   coef_stability - 系数稳定性分析结果\n\ncoef_stability = struct();\n\nfor m = 1:length(methods)\n    method = methods{m};\n    \n    % 只针对回归类模型进行系数稳定性分析\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        % 获取该方法的所有模型系数\n        all_coefs = results.(method).performance.all_coefs;\n        n_models = length(all_coefs);\n        \n        % 确定最常见的变量组合\n        var_combinations = results.(method).var_combinations;\n        combo_strings = cellfun(@(x) sprintf('%d,', sort(x)), var_combinations, 'UniformOutput', false);\n        [unique_combos, ~, ic] = unique(combo_strings);\n        combo_counts = accumarray(ic, 1);\n        [~, max_idx] = max(combo_counts);\n        most_frequent_combo = unique_combos{max_idx};\n        combo_indices = str2num(['[' most_frequent_combo(1:end-1) ']']);\n        \n        % 找出使用了最常见组合的模型索引\n        common_combo_indices = find(ic == max_idx);\n        \n        % 降低模型数量要求\n        if length(common_combo_indices) >= 5\n            % 提取这些模型的系数\n            % 确保common_coefs是一个有效的数值矩阵\n            common_coefs = [];\n            valid_coefs_count = 0;\n            \n            for cidx = 1:length(common_combo_indices)\n                model_idx = common_combo_indices(cidx);\n                coef = all_coefs{model_idx};\n                \n                % 检查coef是有效的数值向量\n                if isnumeric(coef) && ~isempty(coef) && ~any(isnan(coef))\n                    if isempty(common_coefs)\n                        common_coefs = coef';  % 转置为行向量\n                        valid_coefs_count = 1;\n                    else\n                        % 确保长度匹配\n                        if length(coef) == size(common_coefs, 2)\n                            common_coefs = [common_coefs; coef'];\n                            valid_coefs_count = valid_coefs_count + 1;\n                        end\n                    end\n                end\n            end\n            \n            % 如果没有有效系数，则跳过\n            if valid_coefs_count < 2\n                log_message('warning', sprintf('%s方法没有足够的有效系数，跳过系数稳定性分析', method));\n                coef_stability.(method) = struct('status', 'insufficient_valid_data');\n                continue;\n            end\n            \n            % 检查系数维度是否与变量组合匹配\n            expected_dim = length(combo_indices) + 1; % +1是截距项\n            actual_dim = size(common_coefs, 2);\n            \n            log_message('info', sprintf('%s方法的系数维度=%d，变量组合维度=%d', ...\n                method, actual_dim, expected_dim));\n                \n            % 如果维度不匹配，尝试调整\n            if actual_dim ~= expected_dim\n                log_message('warning', sprintf('%s方法的系数维度(%d)与变量组合维度(%d)不匹配，尝试调整', ...\n                    method, actual_dim, expected_dim));\n                \n                % 根据实际情况调整\n                if actual_dim > expected_dim\n                    % 如果系数数量多于变量数量，取前面的部分（截距项和选择的变量）\n                    log_message('info', sprintf('截取系数维度从%d到%d', actual_dim, expected_dim));\n                    common_coefs = common_coefs(:, 1:expected_dim);\n                elseif actual_dim < expected_dim && actual_dim > 0\n                    % 如果系数数量少于变量数量但不为零，使用可用的系数（可能会导致变量名不匹配）\n                    log_message('warning', sprintf('系数数量不足，统计可用的%d个系数', actual_dim));\n                    expected_dim = actual_dim;\n                else\n                    % 极端情况：没有有效系数\n                    log_message('warning', sprintf('%s方法没有有效系数', method));\n                    coef_stability.(method) = struct('status', 'no_valid_coefficients');\n                    continue;\n                end\n            end\n            \n            % 计算系数统计量\n            coef_mean = mean(common_coefs, 1);\n            coef_std = std(common_coefs, 0, 1);\n            \n            % 变异系数计算时需要处理零和接近零的值\n            coef_cv = zeros(size(coef_mean));\n            for i = 1:length(coef_mean)\n                if abs(coef_mean(i)) > 1e-6  % 避免除以接近零的值\n                    coef_cv(i) = abs(coef_std(i) / coef_mean(i));\n                else\n                    if coef_std(i) > 1e-6  % 均值接近零但标准差不小\n                        coef_cv(i) = 999;  % 表示高变异性\n                    else  % 均值和标准差都接近零\n                        coef_cv(i) = 0;    % 表示稳定（都是零）\n                    end\n                end\n            end\n            \n            % 创建变量列表（包括截距）\n            if expected_dim <= 1\n                var_list = {'Intercept'};\n            else\n                if length(combo_indices) >= expected_dim - 1\n                    var_list = ['Intercept'; var_names(combo_indices(1:expected_dim-1))];\n                else\n                    % 如果变量组合索引不足，使用通用变量名\n                    var_list = cell(expected_dim, 1);\n                    var_list{1} = 'Intercept';\n                    for i = 2:expected_dim\n                        if i-1 <= length(combo_indices)\n                            var_list{i} = var_names{combo_indices(i-1)};\n                        else\n                            var_list{i} = sprintf('Var%d', i-1);\n                        end\n                    end\n                end\n            end\n            \n            % 确保所有变量长度一致\n            min_len = min([length(var_list), length(coef_mean), length(coef_std), length(coef_cv)]);\n            \n            % 截取所有数组到相同长度\n            var_list = var_list(1:min_len);\n            coef_mean = coef_mean(1:min_len);\n            coef_std = coef_std(1:min_len);\n            coef_cv = coef_cv(1:min_len);\n            \n            % 创建系数稳定性表\n            % 使用cell数组处理不同类型数据\n            table_data_cell = cell(length(var_list), 4);\n            for i = 1:length(var_list)\n                table_data_cell{i, 1} = var_list{i};\n                table_data_cell{i, 2} = coef_mean(i);\n                table_data_cell{i, 3} = coef_std(i);\n                table_data_cell{i, 4} = coef_cv(i);\n            end\n            \n            % 创建表格\n            table_data = cell2table(table_data_cell, 'VariableNames', {'Variable', 'Mean', 'StdDev', 'CV'});\n            \n            % 存储系数稳定性结果\n            coef_stability.(method).mean = coef_mean;\n            coef_stability.(method).std = coef_std;\n            coef_stability.(method).cv = coef_cv;\n            coef_stability.(method).variables = var_list;\n            coef_stability.(method).table = table_data;\n            coef_stability.(method).all_coefs = common_coefs;\n            \n            % 记录系数稳定性情况\n            log_message('info', sprintf('%s方法的系数稳定性分析完成，分析了%d个模型', method, length(common_combo_indices)));\n            \n            % 识别不稳定的系数 (CV > 0.5)\n            unstable_idx = find(coef_cv > 0.5);\n            if ~isempty(unstable_idx)\n                unstable_vars = var_list(unstable_idx);\n                log_message('warning', sprintf('%s方法中检测到不稳定系数：', method));\n                for i = 1:length(unstable_idx)\n                    log_message('warning', sprintf('  %s: CV=%.2f', unstable_vars{i}, coef_cv(unstable_idx(i))));\n                end\n            else\n                log_message('info', sprintf('%s方法的所有系数都表现稳定 (CV <= 0.5)', method));\n            end\n        else\n            log_message('warning', sprintf('%s方法没有足够的模型使用最常见变量组合(只有%d个，需要至少2个)，跳过系数稳定性分析', ...\n                method, length(common_combo_indices)));\n            coef_stability.(method) = struct('status', 'insufficient_data');\n        end\n    else\n        % 对于非回归类模型\n        log_message('info', sprintf('%s方法不适用于传统系数稳定性分析', method));\n        coef_stability.(method) = struct('status', 'not_applicable');\n    end\nend\nend\n\n%% 修改5：修复calculate_parameter_statistics函数中的维度处理问题\nfunction param_stats = calculate_parameter_statistics(results, methods, var_names)\n% 计算模型参数的置信区间和p值（同时基于BCa和t分布）\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   var_names - 变量名称\n% 输出:\n%   param_stats - 参数统计结果\n\nparam_stats = struct();\n\n% 对每种方法计算参数统计量\nfor m = 1:length(methods)\n    method = methods{m};\n    \n    % 只针对回归类模型进行参数统计分析\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        % 获取该方法的所有模型系数\n        all_coefs = results.(method).performance.all_coefs;\n        n_models = length(all_coefs);\n        \n        % 确定最常见的变量组合\n        var_combinations = results.(method).var_combinations;\n        combo_strings = cellfun(@(x) sprintf('%d,', sort(x)), var_combinations, 'UniformOutput', false);\n        [unique_combos, ~, ic] = unique(combo_strings);\n        combo_counts = accumarray(ic, 1);\n        [~, max_idx] = max(combo_counts);\n        most_frequent_combo = unique_combos{max_idx};\n        combo_indices = str2num(['[' most_frequent_combo(1:end-1) ']']);\n        \n        % 找出使用了最常见组合的模型索引\n        common_combo_indices = find(ic == max_idx);\n        \n        % 降低模型数量要求\n        if length(common_combo_indices) >= 2\n            % 提取这些模型的系数\n            common_coefs = [];\n            valid_coefs_count = 0;\n            \n            for cidx = 1:length(common_combo_indices)\n                model_idx = common_combo_indices(cidx);\n                coef = all_coefs{model_idx};\n                \n                % 检查coef是有效的数值向量\n                if isnumeric(coef) && ~isempty(coef) && ~any(isnan(coef))\n                    if isempty(common_coefs)\n                        common_coefs = coef';  % 转置为行向量\n                        valid_coefs_count = 1;\n                    else\n                        % 确保长度匹配\n                        if length(coef) == size(common_coefs, 2)\n                            common_coefs = [common_coefs; coef'];\n                            valid_coefs_count = valid_coefs_count + 1;\n                        end\n                    end\n                end\n            end\n            \n            % 如果没有有效系数，则跳过\n            if valid_coefs_count < 2\n                log_message('warning', sprintf('%s方法没有足够的有效系数，跳过参数统计分析', method));\n                param_stats.(method) = struct('status', 'insufficient_valid_data');\n                continue;\n            end\n            \n            % 检查维度是否匹配\n            expected_dim = length(combo_indices) + 1;  % +1是截距项\n            actual_dim = size(common_coefs, 2);\n            \n            % 调整维度（如果需要）\n            if actual_dim ~= expected_dim\n                log_message('warning', sprintf('%s方法的系数维度(%d)与变量组合维度(%d)不匹配，尝试调整', ...\n                    method, actual_dim, expected_dim));\n                \n                if actual_dim > expected_dim\n                    common_coefs = common_coefs(:, 1:expected_dim);\n                elseif actual_dim < expected_dim && actual_dim > 0\n                    expected_dim = actual_dim;\n                else\n                    param_stats.(method) = struct('status', 'no_valid_coefficients');\n                    continue;\n                end\n            end\n            \n            % 创建变量列表\n            if expected_dim <= 1\n                var_list = {'Intercept'};\n            else\n                if length(combo_indices) >= expected_dim - 1\n                    var_list = ['Intercept'; var_names(combo_indices(1:expected_dim-1))];\n                else\n                    var_list = cell(expected_dim, 1);\n                    var_list{1} = 'Intercept';\n                    for i = 2:expected_dim\n                        if i-1 <= length(combo_indices)\n                            var_list{i} = var_names{combo_indices(i-1)};\n                        else\n                            var_list{i} = sprintf('Var%d', i-1);\n                        end\n                    end\n                end\n            end\n            \n            % 确保所有变量长度一致\n            min_len = min([length(var_list), size(common_coefs, 2)]);\n            var_list = var_list(1:min_len);\n            \n            % 1. 基于t分布计算\n            % 计算系数统计量\n            coef_mean = mean(common_coefs, 1);\n            coef_std = std(common_coefs, 0, 1);\n            \n            % 样本数量\n            n_samples = size(common_coefs, 1);\n            \n            % 计算95%置信区间\n            t_critical = tinv(0.975, n_samples - 1); % 双侧95%置信度的t值\n            margin_error = t_critical * coef_std / sqrt(n_samples);\n            t_ci_lower = coef_mean - margin_error;\n            t_ci_upper = coef_mean + margin_error;\n            \n            % 计算p值 (双侧t检验，H0：系数=0)\n            t_stat = coef_mean ./ (coef_std / sqrt(n_samples));\n            t_p_values = 2 * (1 - tcdf(abs(t_stat), n_samples - 1));\n            \n            % 2. 基于BCa方法计算Bootstrap置信区间\n            bca_ci_lower = zeros(1, min_len);\n            bca_ci_upper = zeros(1, min_len);\n            \n            try\n                for i = 1:min_len\n                    % 提取当前参数的所有Bootstrap样本值\n                    theta_boot = common_coefs(:, i);\n                    \n                    % 计算BCa置信区间\n                    [bca_ci_lower(i), bca_ci_upper(i)] = calculate_bca_ci(theta_boot, 0.05);\n                end\n            catch ME\n                log_message('warning', sprintf('BCa置信区间计算失败: %s，使用基本Bootstrap置信区间', ME.message));\n                % 使用基本Bootstrap置信区间作为备选\n                alpha = 0.05;\n                lower_percentile = 100 * alpha / 2;\n                upper_percentile = 100 * (1 - alpha / 2);\n                for i = 1:min_len\n                    theta_boot = common_coefs(:, i);\n                    bca_ci_lower(i) = prctile(theta_boot, lower_percentile);\n                    bca_ci_upper(i) = prctile(theta_boot, upper_percentile);\n                end\n            end\n            \n            % 显著性标记\n            significance = cell(size(t_p_values));\n            for i = 1:length(t_p_values)\n                if t_p_values(i) < 0.001\n                    significance{i} = '***';\n                elseif t_p_values(i) < 0.01\n                    significance{i} = '**';\n                elseif t_p_values(i) < 0.05\n                    significance{i} = '*';\n                elseif t_p_values(i) < 0.1\n                    significance{i} = '.';\n                else\n                    significance{i} = '';\n                end\n            end\n            \n            % 创建参数统计表\n            table_data_cell = cell(length(var_list), 9);\n            for i = 1:length(var_list)\n                table_data_cell{i, 1} = var_list{i};\n                table_data_cell{i, 2} = coef_mean(i);\n                table_data_cell{i, 3} = coef_std(i);\n                table_data_cell{i, 4} = t_ci_lower(i);\n                table_data_cell{i, 5} = t_ci_upper(i);\n                table_data_cell{i, 6} = bca_ci_lower(i);\n                table_data_cell{i, 7} = bca_ci_upper(i);\n                table_data_cell{i, 8} = t_p_values(i);\n                table_data_cell{i, 9} = significance{i};\n            end\n            \n            % 创建表格\n            table_data = cell2table(table_data_cell, 'VariableNames', {'Variable', 'Estimate', 'StdError', ...\n                'CI_Lower_t', 'CI_Upper_t', 'CI_Lower_BCa', 'CI_Upper_BCa', 'p_value', 'Significance'});\n            \n            % 存储参数统计结果\n            param_stats.(method).mean = coef_mean;\n            param_stats.(method).std = coef_std;\n            param_stats.(method).t_ci_lower = t_ci_lower;\n            param_stats.(method).t_ci_upper = t_ci_upper;\n            param_stats.(method).bca_ci_lower = bca_ci_lower;\n            param_stats.(method).bca_ci_upper = bca_ci_upper;\n            param_stats.(method).p_values = t_p_values;\n            param_stats.(method).significance = significance;\n            param_stats.(method).variables = var_list;\n            param_stats.(method).table = table_data;\n            param_stats.(method).n_samples = n_samples;\n            \n            % 记录参数统计情况\n            log_message('info', sprintf('%s方法的参数统计分析完成，分析了%d个模型', method, n_samples));\n            \n            % 输出显著的参数\n            sig_idx = find(t_p_values < 0.05);\n            if ~isempty(sig_idx)\n                log_message('info', sprintf('%s方法中检测到显著参数 (p < 0.05)：', method));\n                for i = 1:length(sig_idx)\n                    log_message('info', sprintf('  %s: 估计值=%.4f, t-CI=[%.4f,%.4f], BCa-CI=[%.4f,%.4f], p=%.4f %s', ...\n                        var_list{sig_idx(i)}, coef_mean(sig_idx(i)), ...\n                        t_ci_lower(sig_idx(i)), t_ci_upper(sig_idx(i)), ...\n                        bca_ci_lower(sig_idx(i)), bca_ci_upper(sig_idx(i)), ...\n                        t_p_values(sig_idx(i)), significance{sig_idx(i)}));\n                end\n            else\n                log_message('warning', sprintf('%s方法没有检测到显著参数 (p < 0.05)', method));\n            end\n        else\n            log_message('warning', sprintf('%s方法没有足够的模型使用最常见变量组合(只有%d个，需要至少2个)，跳过参数统计分析', ...\n                method, length(common_combo_indices)));\n            param_stats.(method) = struct('status', 'insufficient_data');\n        end\n    else\n        % 对于非回归类模型\n        log_message('info', sprintf('%s方法不适用于传统参数统计分析', method));\n        param_stats.(method) = struct('status', 'not_applicable');\n    end\nend\nend\n\n% 辅助函数：计算BCa置信区间\nfunction [lower, upper] = calculate_bca_ci(theta_boot, alpha)\n% 计算BCa (偏差校正加速) Bootstrap置信区间\n% 输入:\n%   theta_boot - Bootstrap样本\n%   alpha - 显著性水平 (默认0.05)\n% 输出:\n%   lower - 下界\n%   upper - 上界\n\nn = length(theta_boot);\ntheta_mean = mean(theta_boot);\n\n% 计算偏差校正因子z0\nn_less = sum(theta_boot < theta_mean);\nz0 = norminv(n_less / n);\n\n% 计算加速因子a (使用jackknife方法)\ntheta_jack = zeros(n, 1);\nfor i = 1:n\n    theta_jack(i) = mean(theta_boot([1:i-1, i+1:n]));\nend\ntheta_jack_mean = mean(theta_jack);\nnum = sum((theta_jack_mean - theta_jack).^3);\nden = 6 * (sum((theta_jack_mean - theta_jack).^2)).^(3/2);\nif den == 0\n    a = 0;\nelse\n    a = num / den;\nend\n\n% 计算BCa置信区间\nz_alpha_lo = norminv(alpha/2);\nz_alpha_hi = norminv(1-alpha/2);\n\n% 计算BCa调整后的alpha\nalpha_1_adj = normcdf(z0 + (z0 + z_alpha_lo) / (1 - a * (z0 + z_alpha_lo)));\nalpha_2_adj = normcdf(z0 + (z0 + z_alpha_hi) / (1 - a * (z0 + z_alpha_hi)));\n\n% 根据调整后的alpha找出置信区间\nlower = prctile(theta_boot, 100 * alpha_1_adj);\nupper = prctile(theta_boot, 100 * alpha_2_adj);\nend\n\n%% 评估变量贡献函数 - 新增\nfunction var_contribution = evaluate_variable_contribution(X, y, results, methods, var_names)\n% 评估每个变量对模型的贡献\n% 输入:\n%   X - 自变量矩阵\n%   y - 因变量\n%   results - 结果结构\n%   methods - 方法名称\n%   var_names - 变量名称\n% 输出:\n%   var_contribution - 变量贡献分析结果\n\nvar_contribution = struct();\nn_vars = length(var_names);\n\n% 1. 全局变量重要性分析 - 使用全数据集\nlog_message('info', '开始全局变量重要性分析...');\n\n% 1.1 基于相关性的分析\ntry\n    % 计算相关系数和p值\n    [corr_coef, corr_pval] = corr(X, y, 'Type', 'Pearson');\n    \n    % 计算偏相关系数\n    partial_corr = zeros(n_vars, 1);\n    partial_pval = zeros(n_vars, 1);\n    \n    % 计算每个变量的偏相关系数\n    for i = 1:n_vars\n        other_vars = setdiff(1:n_vars, i);\n        if ~isempty(other_vars)\n            % 残差化\n            mdl_x = fitlm(X(:, other_vars), X(:, i));\n            mdl_y = fitlm(X(:, other_vars), y);\n            \n            x_resid = mdl_x.Residuals.Raw;\n            y_resid = mdl_y.Residuals.Raw;\n            \n            % 计算残差间的相关性\n            [r, p] = corr(x_resid, y_resid);\n            partial_corr(i) = r;\n            partial_pval(i) = p;\n        else\n            % 如果只有一个变量，偏相关等于普通相关\n            partial_corr(i) = corr_coef(i);\n            partial_pval(i) = corr_pval(i);\n        end\n    end\n    \n    % 保存结果\n    var_contribution.correlation = table(var_names, corr_coef, corr_pval, partial_corr, partial_pval, ...\n        'VariableNames', {'Variable', 'Correlation', 'Corr_pvalue', 'PartialCorr', 'Partial_pvalue'});\n    \n    log_message('info', '相关性分析完成');\ncatch ME\n    log_message('warning', sprintf('相关性分析失败: %s', ME.message));\nend\n\n% 1.2 基于模型的重要性分析\n% 尝试使用逻辑回归和随机森林两种方法\n\n% 1.2.1 逻辑回归模型\ntry\n    mdl_logistic = fitglm(X, y, 'Distribution', 'binomial', 'Link', 'logit');\n    coefs = mdl_logistic.Coefficients.Estimate(2:end); % 排除截距\n    pvals = mdl_logistic.Coefficients.pValue(2:end);\n    \n    % 标准化系数 (使用标准差缩放)\n    std_X = std(X);\n    std_coefs = coefs .* std_X';\n    \n    % 基于Wald统计量的重要性\n    wald_stats = (coefs ./ mdl_logistic.Coefficients.SE(2:end)).^2;\n    \n    % 保存结果\n    var_contribution.logistic = table(var_names, coefs, pvals, std_coefs, wald_stats, ...\n        'VariableNames', {'Variable', 'Coefficient', 'p_value', 'Std_Coefficient', 'Wald_Statistic'});\n    \n    log_message('info', '逻辑回归变量重要性分析完成');\ncatch ME\n    log_message('warning', sprintf('逻辑回归变量重要性分析失败: %s', ME.message));\nend\n\n% 1.2.2 随机森林模型\ntry\n    if exist('TreeBagger', 'file')\n        % 移除可能导致问题的并行控制选项\n        % 修改前: parallelOptions = statset('UseParallel', true, 'UseSubstreams', true);\n        % 修改后:\n        parallelOptions = statset('UseParallel', true); % 移除UseSubstreams选项\n        \n        forest = TreeBagger(100, X, y, 'Method', 'classification', ...\n            'OOBPredictorImportance', 'on', ...\n            'MinLeafSize', max(1, floor(size(X,1)/50)), ...\n            'Options', parallelOptions);\n        \n        rf_importance = forest.OOBPermutedPredictorDeltaError;\n        \n        % 标准化重要性分数\n        norm_importance = rf_importance / sum(rf_importance);\n        \n        % 保存结果\n        var_contribution.randomforest = table(var_names, rf_importance', norm_importance', ...\n            'VariableNames', {'Variable', 'Importance', 'Normalized_Importance'});\n        \n        log_message('info', '随机森林变量重要性分析完成');\n    else\n        log_message('warning', 'TreeBagger不可用，跳过随机森林变量重要性分析');\n    end\ncatch ME\n    log_message('warning', sprintf('随机森林变量重要性分析失败: %s', ME.message));\nend\n\n% 2. 方法特定变量贡献分析\nlog_message('info', '开始方法特定变量贡献分析...');\n\nfor m = 1:length(methods)\n    method = methods{m};\n    var_contribution.methods.(method) = struct();\n    \n    % 获取该方法选择的变量\n    selected_vars = find(results.(method).selected_vars);\n    selected_names = var_names(selected_vars);\n    var_contribution.methods.(method).selected_vars = selected_vars;\n    var_contribution.methods.(method).selected_names = selected_names;\n    \n    % 变量选择频率\n    var_contribution.methods.(method).var_freq = results.(method).var_freq;\n    \n    % 对于回归类方法，计算系数贡献\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        try\n            % 构建贡献表\n            method_mdl = fitglm(X(:, selected_vars), y, 'Distribution', 'binomial', 'Link', 'logit');\n            \n            % 模型参数\n            coefs = method_mdl.Coefficients.Estimate(2:end); % 排除截距\n            pvals = method_mdl.Coefficients.pValue(2:end);\n            \n            % 标准化系数\n            std_X_sel = std(X(:, selected_vars));\n            std_coefs = coefs .* std_X_sel';\n            \n            % 计算相对贡献 (基于系数绝对值)\n            abs_coefs = abs(std_coefs);\n            rel_contrib = abs_coefs / sum(abs_coefs) * 100;\n            \n            % 系数符号\n            coef_sign = sign(coefs);\n            effect_dir = cell(length(coef_sign), 1);\n            for i = 1:length(coef_sign)\n                if coef_sign(i) > 0\n                    effect_dir{i} = '正向';\n                elseif coef_sign(i) < 0\n                    effect_dir{i} = '负向';\n                else\n                    effect_dir{i} = '无';\n                end\n            end\n            \n            % 显著性标记\n            sig_marks = cell(length(pvals), 1);\n            for i = 1:length(pvals)\n                if pvals(i) < 0.001\n                    sig_marks{i} = '***';\n                elseif pvals(i) < 0.01\n                    sig_marks{i} = '**';\n                elseif pvals(i) < 0.05\n                    sig_marks{i} = '*';\n                elseif pvals(i) < 0.1\n                    sig_marks{i} = '.';\n                else\n                    sig_marks{i} = '';\n                end\n            end\n            \n            % 创建贡献表\n            contrib_table = table(selected_names, coefs, pvals, std_coefs, rel_contrib, effect_dir, sig_marks, ...\n                'VariableNames', {'Variable', 'Coefficient', 'p_value', 'Std_Coefficient', ...\n                'Relative_Contribution', 'Effect_Direction', 'Significance'});\n            \n            % 按相对贡献排序\n            contrib_table = sortrows(contrib_table, 'Relative_Contribution', 'descend');\n            \n            % 保存结果\n            var_contribution.methods.(method).contribution_table = contrib_table;\n            \n            log_message('info', sprintf('%s方法的变量贡献分析完成', method));\n        catch ME\n            log_message('warning', sprintf('%s方法的变量贡献分析失败: %s', method, ME.message));\n        end\n    elseif strcmpi(method, 'randomforest')\n        % 对于随机森林，使用变量重要性\n        try\n            if exist('TreeBagger', 'file') && ~isempty(selected_vars)\n                % 只使用选定的变量训练森林\n                forest = TreeBagger(100, X(:, selected_vars), y, 'Method', 'classification', ...\n                    'OOBPredictorImportance', 'on');\n                \n                rf_importance = forest.OOBPermutedPredictorDeltaError;\n                \n                % 标准化重要性分数\n                norm_importance = rf_importance / sum(rf_importance) * 100;\n                \n                % 创建贡献表\n                contrib_table = table(selected_names, rf_importance', norm_importance', ...\n                    'VariableNames', {'Variable', 'Importance', 'Relative_Contribution'});\n                \n                % 按相对贡献排序\n                contrib_table = sortrows(contrib_table, 'Relative_Contribution', 'descend');\n                \n                % 保存结果\n                var_contribution.methods.(method).contribution_table = contrib_table;\n                \n                log_message('info', sprintf('%s方法的变量贡献分析完成', method));\n            else\n                log_message('warning', sprintf('%s方法的变量贡献分析失败：TreeBagger不可用或无选定变量', method));\n            end\n        catch ME\n            log_message('warning', sprintf('%s方法的变量贡献分析失败: %s', method, ME.message));\n        end\n    end\nend\n\n% 3. 综合变量重要性排名\nlog_message('info', '计算综合变量重要性排名...');\ntry\n    % 收集所有方法的变量选择频率\n    all_freqs = zeros(n_vars, length(methods));\n    for m = 1:length(methods)\n        method = methods{m};\n        all_freqs(:, m) = results.(method).var_freq;\n    end\n    \n    % 计算平均选择频率\n    avg_freq = mean(all_freqs, 2);\n    \n    % 计算基于选择频率的变量重要性排名\n    [~, freq_rank] = sort(avg_freq, 'descend');\n    freq_rank_score = n_vars + 1 - (1:n_vars)';\n    freq_rank_score = freq_rank_score(freq_rank);\n    \n    % 如果有相关性分析结果，合并它\n    if isfield(var_contribution, 'correlation')\n        corr_abs = abs(var_contribution.correlation.Correlation);\n        [~, corr_rank] = sort(corr_abs, 'descend');\n        corr_rank_score = n_vars + 1 - (1:n_vars)';\n        corr_rank_score = corr_rank_score(corr_rank);\n    else\n        corr_rank_score = zeros(n_vars, 1);\n    end\n    \n    % 如果有逻辑回归分析结果，合并它\n    if isfield(var_contribution, 'logistic')\n        log_abs = abs(var_contribution.logistic.Std_Coefficient);\n        [~, log_rank] = sort(log_abs, 'descend');\n        log_rank_score = n_vars + 1 - (1:n_vars)';\n        log_rank_score = log_rank_score(log_rank);\n    else\n        log_rank_score = zeros(n_vars, 1);\n    end\n    \n    % 如果有随机森林分析结果，合并它\n    if isfield(var_contribution, 'randomforest')\n        rf_imp = var_contribution.randomforest.Importance;\n        [~, rf_rank] = sort(rf_imp, 'descend');\n        rf_rank_score = n_vars + 1 - (1:n_vars)';\n        rf_rank_score = rf_rank_score(rf_rank);\n    else\n        rf_rank_score = zeros(n_vars, 1);\n    end\n    \n    % 计算综合分数 - 使用加权平均\n    combined_score = 0.4 * freq_rank_score + 0.2 * corr_rank_score + 0.2 * log_rank_score + 0.2 * rf_rank_score;\n    \n    % 创建综合重要性表\n    [sorted_score, score_idx] = sort(combined_score, 'descend');\n    sorted_vars = var_names(score_idx);\n    \n    % 计算归一化重要性\n    norm_score = sorted_score / sum(sorted_score) * 100;\n    \n    % 创建表格\n    overall_importance = table(sorted_vars, sorted_score, norm_score, ...\n        'VariableNames', {'Variable', 'Overall_Score', 'Normalized_Importance'});\n    \n    % 保存结果\n    var_contribution.overall_importance = overall_importance;\n    \n    log_message('info', '综合变量重要性排名计算完成');\n    \n    % 输出前5个最重要的变量\n    top_n = min(5, n_vars);\n    log_message('info', '前5个最重要的变量:');\n    for i = 1:top_n\n        log_message('info', sprintf('  %d. %s (重要性: %.2f%%)', i, overall_importance.Variable{i}, overall_importance.Normalized_Importance(i)));\n    end\ncatch ME\n    log_message('warning', sprintf('计算综合变量重要性排名失败: %s', ME.message));\nend\n\nend\n\n%% 并行方法处理函数\nfunction result = process_method(X_final, y, train_indices, test_indices, method, var_names)\n% 处理单个变量选择方法\n% 输入:\n%   X_final - 自变量矩阵\n%   y - 因变量\n%   train_indices - 训练集索引\n%   test_indices - 测试集索引\n%   method - 方法名称\n%   var_names - 变量名称\n% 输出:\n%   result - 方法结果结构\n\n% 变量筛选\nlog_message('info', sprintf('%s: 开始变量筛选', method));\n[selected_vars, var_freq, var_combinations] = select_variables(X_final, y, train_indices, method);\nlog_message('info', sprintf('%s: 变量筛选完成', method));\n\n% 训练和评估模型\nlog_message('info', sprintf('%s: 开始模型训练与评估', method));\n[models, performance, group_performance] = train_and_evaluate_models_with_groups(X_final, y, train_indices, test_indices, var_combinations, method, var_names);\nlog_message('info', sprintf('%s: 模型训练与评估完成', method));\n\n% 获取模型参数\nlog_message('info', sprintf('%s: 提取模型参数', method));\nparams = get_model_parameters(models, var_names);\nlog_message('info', sprintf('%s: 参数提取完成', method));\n\n% 组织结果\nresult = struct();\nresult.selected_vars = selected_vars;\nresult.var_freq = var_freq;\nresult.var_combinations = var_combinations;\nresult.models = models;\nresult.performance = performance;\nresult.group_performance = group_performance;\nresult.params = params;\nend\n\n%% 模型参数函数 - 优化版\nfunction params = get_model_parameters(models, var_names)\n% 获取模型参数\n% 输入:\n%   models - 模型\n%   var_names - 变量名称\n% 输出:\n%   params - 模型参数\n\nn_models = length(models);\n\n% 预分配并行处理数组\ncoef_cell = cell(n_models, 1);\npval_cell = cell(n_models, 1);\nvar_cell = cell(n_models, 1);\n\n% 并行处理模型参数\nparfor i = 1:n_models\n    mdl = models{i};\n    \n    if isa(mdl, 'TreeBagger')\n        % 对于 Random Forest，使用变量重要性作为\"系数\"\n        local_imp = mdl.OOBPermutedPredictorDeltaError;\n        local_coef = local_imp;\n        local_pval = nan(size(local_imp));\n        local_vars = cellstr(mdl.PredictorNames);\n    else\n        % 对于广义线性模型\n        try\n            % 尝试获取系数表\n            coef_table = mdl.Coefficients;\n            local_coef = coef_table.Estimate';\n            local_pval = coef_table.pValue';\n            local_vars = coef_table.Row';\n        catch\n            % 如果上面的方法失败，使用备选方法\n            local_coef = mdl.Coefficients{:, 'Estimate'}';\n            local_pval = mdl.Coefficients{:, 'pValue'}';\n            local_vars = mdl.Coefficients.Properties.RowNames';\n        end\n    end\n    \n    % 存储结果\n    coef_cell{i} = local_coef;\n    pval_cell{i} = local_pval;\n    var_cell{i} = local_vars;\nend\n\n% 构建参数结构\nparams = struct();\nparams.coef_cell = coef_cell;\nparams.pval_cell = pval_cell;\nparams.var_cell = var_cell;\nend\n\n%% 保存增强结果函数 - 新增\nfunction save_enhanced_results(results, var_names, group_means, cv_results, coef_stability, param_stats, var_contribution)\n% 保存分析结果，包括变量组合信息、交叉验证结果、系数稳定性、参数统计和变量贡献\n% 输入:\n%   results - 结果结构\n%   var_names - 变量名称\n%   group_means - 分组均值\n%   cv_results - 交叉验证结果\n%   coef_stability - 系数稳定性\n%   param_stats - 参数统计\n%   var_contribution - 变量贡献\n\n% 从results结构中获取方法名称\nmethods = fieldnames(results);\n\n% 创建高级结果目录\nresult_dir = fullfile('results');\nif ~exist(result_dir, 'dir')\n    mkdir(result_dir);\nend\n\n% 保存时间戳\ntimestamp = datestr(now, 'yyyymmdd_HHMMSS');\nresult_mat = fullfile(result_dir, sprintf('enhanced_analysis_%s.mat', timestamp));\n\n% 保存原始结果 - 使用-v7.3支持大文件\nsave(result_mat, 'results', 'var_names', 'group_means', 'cv_results', ...\n     'coef_stability', 'param_stats', 'var_contribution', '-v7.3');\nlog_message('info', sprintf('增强分析结果已保存至 %s', result_mat));\n\n% 创建CSV结果目录\ncsv_dir = fullfile(result_dir, 'csv');\nif ~exist(csv_dir, 'dir')\n    mkdir(csv_dir);\nend\n\n% 创建图形结果目录\nfigure_dir = fullfile(result_dir, 'figures');\nif ~exist(figure_dir, 'dir')\n    mkdir(figure_dir);\nend\n\n% 创建报告目录\nreport_dir = fullfile(result_dir, 'reports');\nif ~exist(report_dir, 'dir')\n    mkdir(report_dir);\nend\n\n% 创建AIC和BIC比较表\ntry\n    aic_bic_table = create_aic_bic_table(results, methods);\n    writetable(aic_bic_table, fullfile(csv_dir, 'aic_bic_comparison.csv'));\n    log_message('info', 'AIC和BIC比较表已保存');\ncatch ME\n    log_message('error', sprintf('创建AIC和BIC比较表时出错: %s', ME.message));\nend\n\n% 创建变量选择频率表\ntry\n    var_freq_table = create_var_freq_table(results, methods, var_names);\n    writetable(var_freq_table, fullfile(csv_dir, 'variable_selection_frequency.csv'));\n    log_message('info', '变量选择频率表已保存');\ncatch ME\n    log_message('error', sprintf('创建变量选择频率表时出错: %s', ME.message));\nend\n\n% 创建模型性能表（增强版，包括均值和标准差）\ntry\n    perf_detail_table = create_performance_detail_table(results, methods);\n    writetable(perf_detail_table, fullfile(csv_dir, 'model_performance_detailed.csv'));\n    log_message('info', '详细模型性能表已保存');\ncatch ME\n    log_message('error', sprintf('创建详细模型性能表时出错: %s', ME.message));\nend\n% 创建变量组合性能表\ntry\n    var_group_table = create_variable_group_table(results, methods);\n    writetable(var_group_table, fullfile(csv_dir, 'variable_group_performance.csv'));\n    log_message('info', '变量组合性能表已保存');\ncatch ME\n    log_message('error', sprintf('创建变量组合性能表时出错: %s', ME.message));\nend\n\n% 创建K折交叉验证结果表\ntry\n    cv_table = create_cv_results_table(cv_results);\n    writetable(cv_table, fullfile(csv_dir, 'cv_results.csv'));\n    log_message('info', 'K折交叉验证结果表已保存');\ncatch ME\n    log_message('error', sprintf('创建K折交叉验证结果表时出错: %s', ME.message));\nend\n\n% 创建系数稳定性表\ntry\n    for m = 1:length(methods)\n        method = methods{m};\n        if isfield(coef_stability, method) && isfield(coef_stability.(method), 'table')\n            writetable(coef_stability.(method).table, fullfile(csv_dir, sprintf('%s_coefficient_stability.csv', method)));\n            log_message('info', sprintf('%s方法的系数稳定性表已保存', method));\n        end\n    end\ncatch ME\n    log_message('error', sprintf('创建系数稳定性表时出错: %s', ME.message));\nend\n\n% 创建参数统计表\ntry\n    for m = 1:length(methods)\n        method = methods{m};\n        if isfield(param_stats, method) && isfield(param_stats.(method), 'table')\n            writetable(param_stats.(method).table, fullfile(csv_dir, sprintf('%s_parameter_statistics.csv', method)));\n            log_message('info', sprintf('%s方法的参数统计表已保存', method));\n        end\n    end\ncatch ME\n    log_message('error', sprintf('创建参数统计表时出错: %s', ME.message));\nend\n\n% 创建变量贡献表\ntry\n    % 保存全局重要性表\n    if isfield(var_contribution, 'correlation')\n        writetable(var_contribution.correlation, fullfile(csv_dir, 'correlation_importance.csv'));\n    end\n    \n    if isfield(var_contribution, 'logistic')\n        writetable(var_contribution.logistic, fullfile(csv_dir, 'logistic_importance.csv'));\n    end\n    \n    if isfield(var_contribution, 'randomforest')\n        writetable(var_contribution.randomforest, fullfile(csv_dir, 'randomforest_importance.csv'));\n    end\n    \n    if isfield(var_contribution, 'overall_importance')\n        writetable(var_contribution.overall_importance, fullfile(csv_dir, 'overall_importance.csv'));\n    end\n    \n    % 保存方法特定贡献表\n    for m = 1:length(methods)\n        method = methods{m};\n        if isfield(var_contribution, 'methods') && isfield(var_contribution.methods, method) && ...\n           isfield(var_contribution.methods.(method), 'contribution_table')\n            writetable(var_contribution.methods.(method).contribution_table, ...\n                fullfile(csv_dir, sprintf('%s_variable_contribution.csv', method)));\n            log_message('info', sprintf('%s方法的变量贡献表已保存', method));\n        end\n    end\n    \n    log_message('info', '变量贡献表已保存');\ncatch ME\n    log_message('error', sprintf('创建变量贡献表时出错: %s', ME.message));\nend\n\n% 创建模型参数表\ntry\n    param_table = create_parameter_table(results, methods);\n    writetable(param_table, fullfile(csv_dir, 'model_parameters.csv'));\n    log_message('info', '模型参数表已保存');\ncatch ME\n    log_message('error', sprintf('创建模型参数表时出错: %s', ME.message));\nend\n\n% 创建可视化图表\ntry\n    % ROC曲线图\n    create_roc_curves(results, methods, figure_dir);\n    log_message('info', 'ROC曲线图已保存');\n    \n    % 变量重要性图\n    create_variable_importance_plot(results, methods, var_names, figure_dir);\n    log_message('info', '变量重要性图已保存');\n    \n    % 变量组合可视化图\n    create_variable_group_plot(results, methods, var_names, figure_dir);\n    log_message('info', '变量组合可视化图已保存');\n    \n    % K折交叉验证性能图（新增）\n    create_cv_performance_plot(cv_results, figure_dir);\n    log_message('info', 'K折交叉验证性能图已保存');\n    \n    % 系数稳定性图（新增）\n    create_coefficient_stability_plot(coef_stability, methods, figure_dir);\n    log_message('info', '系数稳定性图已保存');\n    \n    % 变量贡献图（新增）\n    create_variable_contribution_plot(var_contribution, figure_dir);\n    log_message('info', '变量贡献图已保存');\ncatch ME\n    log_message('error', sprintf('创建可视化图表时出错: %s', ME.message));\nend\n\n% 创建综合比较报告\ntry\n    create_enhanced_summary_report(results, methods, var_names, cv_results, ...\n        coef_stability, param_stats, var_contribution, report_dir);\n    log_message('info', '增强综合比较报告已保存');\ncatch ME\n    log_message('error', sprintf('创建增强综合比较报告时出错: %s', ME.message));\nend\n\nend\n\n% 辅助函数：创建AIC和BIC比较表\nfunction aic_bic_table = create_aic_bic_table(results, methods)\n% 创建AIC和BIC比较表\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n% 输出:\n%   aic_bic_table - AIC和BIC比较表\n\n% 初始化变量\nmethods_cell = cell(length(methods), 1);\naic_values = zeros(length(methods), 1);\naic_std_values = zeros(length(methods), 1);\nbic_values = zeros(length(methods), 1);\nbic_std_values = zeros(length(methods), 1);\nn_params = zeros(length(methods), 1);\n\n% 提取每种方法的AIC和BIC\nfor i = 1:length(methods)\n    method = methods{i};\n    methods_cell{i} = method;\n    \n    % 检查该方法是否有AIC和BIC值\n    if isfield(results.(method).performance, 'avg_aic') && ...\n       isfield(results.(method).performance, 'avg_bic')\n        aic_values(i) = results.(method).performance.avg_aic;\n        aic_std_values(i) = results.(method).performance.std_aic;\n        bic_values(i) = results.(method).performance.avg_bic;\n        bic_std_values(i) = results.(method).performance.std_bic;\n        \n        % 获取参数数量（基于最常见的变量组合）\n        selected_vars = find(results.(method).selected_vars);\n        n_params(i) = length(selected_vars) + 1; % +1是因为有截距项\n    else\n        aic_values(i) = NaN;\n        aic_std_values(i) = NaN;\n        bic_values(i) = NaN;\n        bic_std_values(i) = NaN;\n        n_params(i) = 0;\n    end\nend\n\n% 创建表格\naic_bic_table = table(methods_cell, n_params, aic_values, aic_std_values, bic_values, bic_std_values, ...\n    'VariableNames', {'Method', 'NumParams', 'AIC', 'AIC_StdDev', 'BIC', 'BIC_StdDev'});\n\n% 按AIC排序\naic_bic_table = sortrows(aic_bic_table, 'AIC', 'ascend');\nend\n\n% 辅助函数：创建详细性能表\nfunction perf_detail_table = create_performance_detail_table(results, methods)\n% 创建详细模型性能表，包括均值和标准差\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n% 输出:\n%   perf_detail_table - 详细性能表\n\n% 初始化变量\nmethods_cell = cell(length(methods), 1);\nmetrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\nmetric_names = {'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1_Score', 'AUC'};\n\n% 初始化数组\nmean_values = zeros(length(methods), length(metrics));\nstd_values = zeros(length(methods), length(metrics));\ncv_values = zeros(length(methods), length(metrics));\n\n% 提取每种方法的性能指标\nfor i = 1:length(methods)\n    method = methods{i};\n    methods_cell{i} = method;\n    \n    for j = 1:length(metrics)\n        metric = metrics{j};\n        \n        % 均值\n        if isfield(results.(method).performance, ['avg_' metric])\n            mean_values(i, j) = results.(method).performance.(['avg_' metric]);\n        else\n            mean_values(i, j) = NaN;\n        end\n        \n        % 标准差\n        if isfield(results.(method).performance, ['std_' metric])\n            std_values(i, j) = results.(method).performance.(['std_' metric]);\n        else\n            std_values(i, j) = NaN;\n        end\n        \n        % 变异系数\n        if mean_values(i, j) > 0\n            cv_values(i, j) = std_values(i, j) / mean_values(i, j);\n        else\n            cv_values(i, j) = NaN;\n        end\n    end\nend\n\n% 创建表格\ntable_vars = {'Method'};\ndata_vars = {methods_cell};\n\n% 添加各指标的均值、标准差和变异系数\nfor j = 1:length(metrics)\n    table_vars{end+1} = [metric_names{j} '_Mean'];\n    data_vars{end+1} = mean_values(:, j);\n    \n    table_vars{end+1} = [metric_names{j} '_StdDev'];\n    data_vars{end+1} = std_values(:, j);\n    \n    table_vars{end+1} = [metric_names{j} '_CV'];\n    data_vars{end+1} = cv_values(:, j);\nend\n\n% 创建表格\nperf_detail_table = table(data_vars{:}, 'VariableNames', table_vars);\n\n% 按F1分数均值排序\nf1_col = find(strcmp(table_vars, 'F1_Score_Mean'));\nperf_detail_table = sortrows(perf_detail_table, f1_col, 'descend');\nend\n\n%% 创建变量频率表 - 修复版\nfunction var_freq_table = create_var_freq_table(results, methods, var_names)\n% 创建变量选择频率表\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   var_names - 变量名称\n% 输出:\n%   var_freq_table - 变量频率表\n\n% 初始化变量名称列\nvar_names_cell = cell(length(var_names), 1);\nfor i = 1:length(var_names)\n    var_names_cell{i} = var_names{i};\nend\n\n% 初始化表格\nvar_freq_table = table(var_names_cell, 'VariableNames', {'VariableName'});\n\n% 添加各方法的频率\nfor i = 1:length(methods)\n    method = methods{i};\n    var_freq = results.(method).var_freq;\n    \n    % 确保长度一致\n    if length(var_freq) ~= length(var_names)\n        log_message('warning', sprintf('%s方法的变量频率长度(%d)与变量名长度(%d)不匹配，进行调整', method, length(var_freq), length(var_names)));\n        \n        % 如果var_freq较短，扩展它\n        if length(var_freq) < length(var_names)\n            var_freq_extended = zeros(length(var_names), 1);\n            var_freq_extended(1:length(var_freq)) = var_freq;\n            var_freq = var_freq_extended;\n        % 如果var_freq较长，截断它\n        else\n            var_freq = var_freq(1:length(var_names));\n        end\n    end\n    \n    % 确保var_freq是列向量\n    if size(var_freq, 2) > 1\n        var_freq = var_freq';\n    end\n    \n    % 添加到表格中\n    var_freq_table.(method) = var_freq;\nend\n\n% 添加平均频率\navg_vals = zeros(height(var_freq_table), 1);\nfor i = 1:length(methods)\n    method = methods{i};\n    avg_vals = avg_vals + var_freq_table.(method);\nend\navg_vals = avg_vals / length(methods);\nvar_freq_table.Average = avg_vals;\n\n% 对表格进行排序\nvar_freq_table = sortrows(var_freq_table, 'Average', 'descend');\nend\n\n%% 创建增强性能表 - 新增\nfunction perf_table = create_enhanced_performance_table(results, methods)\n% 创建增强模型性能表，包含更多评估指标\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n% 输出:\n%   perf_table - 性能表\n\n% 确保methods是列向量cell数组\nif ~iscell(methods)\n    methods = cellstr(methods);\nend\nmethods_cell = cell(length(methods), 1);\nfor i = 1:length(methods)\n    methods_cell{i} = methods{i};\nend\n\n% 初始化表格\nperf_table = table(methods_cell, 'VariableNames', {'Method'});\n\n% 添加各性能指标（增强版）\nmetrics = {'avg_accuracy', 'avg_sensitivity', 'avg_specificity', 'avg_precision', 'avg_f1_score', 'avg_auc'};\nmetric_names = {'Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1_Score', 'AUC'};\n\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    metric_name = metric_names{i};\n    \n    values = zeros(length(methods), 1);\n    for j = 1:length(methods)\n        values(j) = results.(methods{j}).performance.(metric);\n    end\n    \n    perf_table.(metric_name) = values;\nend\n\n% 对表格进行排序\nperf_table = sortrows(perf_table, 'F1_Score', 'descend');\nend\n\n%% 创建交叉验证结果表 - 新增\nfunction cv_table = create_cv_results_table(cv_results)\n% 创建K折交叉验证结果表\n% 输入:\n%   cv_results - 交叉验证结果\n% 输出:\n%   cv_table - 交叉验证结果表\n\n% 提取每个折的性能\nn_folds = length(cv_results.accuracy);\nfold_numbers = (1:n_folds)';\n\n% 初始化表格\ncv_table = table(fold_numbers, 'VariableNames', {'Fold'});\n\n% 添加各性能指标\ncv_table.Accuracy = cv_results.accuracy;\ncv_table.Precision = cv_results.precision;\ncv_table.Recall = cv_results.recall;\ncv_table.Specificity = cv_results.specificity;\ncv_table.F1_Score = cv_results.f1_score;\ncv_table.AUC = cv_results.auc;\n\n% 添加均值和标准差行\nmean_row = table('Size', [1 size(cv_table,2)], 'VariableTypes', repmat({'double'}, 1, size(cv_table,2)), 'VariableNames', cv_table.Properties.VariableNames);\nstd_row = mean_row;\n\nmean_row.Fold = 0; % 用0表示均值行\nstd_row.Fold = -1; % 用-1表示标准差行\n\n% 填充数据\nmetrics = {'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1_Score', 'AUC'};\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    mean_row.(metric) = mean(cv_table.(metric), 'omitnan');\n    std_row.(metric) = std(cv_table.(metric), 'omitnan');\nend\n\n% 合并表格\ncv_table = [cv_table; mean_row; std_row];\n\nend\n\n%% K折表现的可视化函数\nfunction create_kfold_performance_visualization(cv_results, figure_dir)\n% 创建K折交叉验证各折性能可视化\n% 输入:\n%   cv_results - 交叉验证结果\n%   figure_dir - 图形保存目录\n\n% 获取折数\nk = length(cv_results.accuracy);\n\n% 创建图形\nfig = figure('Name', 'K-Fold Performance by Fold', 'Position', [100, 100, 1200, 800]);\n\n% 准备数据\nmetrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\nmetric_labels = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\nn_metrics = length(metrics);\n\n% 创建子图布局\nrows = 2;\ncols = 3;\n\n% 绘制每个指标的折线图\nfor i = 1:n_metrics\n    metric = metrics{i};\n    metric_label = metric_labels{i};\n    \n    % 创建子图\n    subplot(rows, cols, i);\n    \n    % 获取数据\n    values = cv_results.(metric);\n    mean_val = cv_results.(['avg_' metric]);\n    std_val = cv_results.(['std_' metric]);\n    \n    % 绘制折线图\n    plot(1:k, values, 'o-', 'LineWidth', 1.5, 'Color', [0.3, 0.6, 0.8], 'MarkerFaceColor', [0.3, 0.6, 0.8]);\n    hold on;\n    \n    % 绘制均值线\n    plot([0.5, k+0.5], [mean_val, mean_val], 'r--', 'LineWidth', 1.5);\n    \n    % 绘制标准差区间\n    fill([1:k, fliplr(1:k)], [mean_val + std_val * ones(1, k), fliplr(mean_val - std_val * ones(1, k))], ...\n        [0.8, 0.8, 0.8], 'EdgeColor', 'none', 'FaceAlpha', 0.3);\n    \n    % 设置图形属性\n    xlabel('折数', 'FontSize', 10);\n    ylabel(metric_label, 'FontSize', 10);\n    title(sprintf('%s (均值=%.3f, 标准差=%.3f)', metric_label, mean_val, std_val), 'FontSize', 12);\n    grid on;\n    xlim([0.5, k+0.5]);\n    \n    % 调整Y轴范围\n    if strcmp(metric, 'auc') || strcmp(metric, 'f1_score')\n        ylim([0.5, 1]);\n    else\n        ylim([0, 1]);\n    end\n    \n    % 添加数据点标签\n    for j = 1:k\n        text(j, values(j) + 0.02, sprintf('%.3f', values(j)), ...\n            'HorizontalAlignment', 'center', 'FontSize', 7);\n    end\n    \n    % 添加图例\n    legend({'各折值', '均值', '标准差区间'}, 'Location', 'best', 'FontSize', 8);\nend\n\n% 添加总标题\nsgtitle(sprintf('K折交叉验证各折性能指标 (K=%d)', k), 'FontSize', 16, 'FontWeight', 'bold');\nset(gcf, 'Color', 'white');\n\n% 保存图形\nsave_figure(fig, figure_dir, 'kfold_performance_by_fold', 'Formats', {'svg'});\nclose(fig);\nend\n\n%% 创建变量组合性能表 - 修复版\nfunction var_group_table = create_variable_group_table(results, methods)\n% 创建变量组合性能表\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n% 输出:\n%   var_group_table - 变量组合性能表\n\n% 初始化表格行\nrows = [];\n\nfor i = 1:length(methods)\n    method = methods{i};\n    group_perf = results.(method).group_performance;\n    \n    % 对于每个变量组合创建一行\n    for j = 1:length(group_perf)\n        combo = group_perf(j);\n        var_str = strjoin(cellfun(@(x) x, combo.variables, 'UniformOutput', false), ', ');\n        row = {method, var_str, combo.count, combo.accuracy, combo.sensitivity, combo.specificity, combo.precision, combo.f1_score, combo.auc};\n        rows = [rows; row];\n    end\nend\n\n% 创建表格 - 将\"Variables\"改为\"VarCombination\"并增加新指标\nvar_group_table = cell2table(rows, 'VariableNames', {'Method', 'VarCombination', 'Count', 'Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1_Score', 'AUC'});\n\n% 对表格进行排序（先按方法，再按F1分数）\nvar_group_table = sortrows(var_group_table, {'Method', 'F1_Score'}, {'ascend', 'descend'});\nend\n\n%% 创建参数表\nfunction param_table = create_parameter_table(results, methods)\n% 创建模型参数表\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n% 输出:\n%   param_table - 参数表\n\n% 初始化表格行\nrows = [];\n\nfor i = 1:length(methods)\n    method = methods{i};\n    params = results.(method).params;\n    \n    % 对于每个模型\n    for j = 1:length(params.coef_cell)\n        coef = params.coef_cell{j};\n        pval = params.pval_cell{j};\n        vars = params.var_cell{j};\n        \n        % 对于每个变量\n        for k = 1:length(coef)\n            if k <= length(vars)\n                var_name = vars{k};\n                row = {method, j, var_name, coef(k), pval(k)};\n                rows = [rows; row];\n            end\n        end\n    end\nend\n\n% 创建表格\nparam_table = cell2table(rows, 'VariableNames', {'Method', 'Model_Index', 'Variable', 'Coefficient', 'P_Value'});\nend\n\n%% 创建K折交叉验证性能图 - 新增\nfunction create_cv_performance_plot(cv_results, figure_dir)\n% 创建K折交叉验证性能图\n% 输入:\n%   cv_results - 交叉验证结果\n%   figure_dir - 图形保存目录\n\n\n% 创建图形\nfig = figure('Name', 'Cross-Validation Performance', 'Position', [100, 100, 1200, 800]);\n\n% 获取折数\nk = length(cv_results.accuracy);\n\n% 准备数据\nmetrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\nmetric_labels = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\nmetric_colors = lines(length(metrics));\n\n% 创建子图1：各折性能\nsubplot(2, 2, 1);\nhold on;\n\n% 为每个指标绘制折线\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    values = cv_results.(metric);\n    \n    % 绘制折线\n    plot(1:k, values, 'o-', 'LineWidth', 1.5, 'Color', metric_colors(i,:), 'DisplayName', metric_labels{i});\nend\n\n% 设置图形属性\nxlabel('折数', 'FontSize', 12);\nylabel('性能值', 'FontSize', 12);\ntitle('K折交叉验证中各折的性能表现', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\nlegend('Location', 'best');\nxlim([0.5, k+0.5]);\nylim([0, 1.05]);\nset(gca, 'XTick', 1:k);\n\n% 创建子图2：各指标均值和标准差\nsubplot(2, 2, 2);\n\n% 计算均值和标准差\nmetric_means = zeros(length(metrics), 1);\nmetric_stds = zeros(length(metrics), 1);\n\nfor i = 1:length(metrics)\n    metric = metrics{i};\n    metric_means(i) = mean(cv_results.(metric), 'omitnan');\n    metric_stds(i) = std(cv_results.(metric), 'omitnan');\nend\n\n% 创建条形图\nbar_h = bar(metric_means);\nset(bar_h, 'FaceColor', 'flat');\nfor i = 1:length(metrics)\n    bar_h.CData(i,:) = metric_colors(i,:);\nend\n\n% 添加误差线\nhold on;\nerrorbar(1:length(metrics), metric_means, metric_stds, '.k');\n\n% 设置图形属性\nset(gca, 'XTick', 1:length(metrics), 'XTickLabel', metric_labels);\nylabel('平均性能', 'FontSize', 12);\ntitle('各评估指标的均值和标准差', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\nylim([0, 1.05]);\n\n% 添加数值标签\nfor i = 1:length(metrics)\n    text(i, metric_means(i) + 0.03, sprintf('%.3f±%.3f', metric_means(i), metric_stds(i)), ...\n        'HorizontalAlignment', 'center', 'FontSize', 9);\nend\n\n% 创建子图3：系数稳定性\nsubplot(2, 2, 3);\n\n% 提取系数变异系数\ncoef_cv = cv_results.coef_cv;\nvar_list = ['Intercept'; cv_results.variables(2:end)]; % 排除截距\n\n% 创建条形图\nbar_h = barh(coef_cv);\nset(bar_h, 'FaceColor', [0.3, 0.6, 0.8]);\n\n% 设置图形属性\nset(gca, 'YTick', 1:length(coef_cv), 'YTickLabel', var_list);\nxlabel('变异系数 (CV)', 'FontSize', 12);\ntitle('模型系数稳定性 (变异系数)', 'FontSize', 14, 'FontWeight', 'bold');\ngrid on;\n\n% 创建子图4：学习曲线或ROC曲线\nsubplot(2, 2, 4);\n\ntry\n    % 计算平均ROC曲线（如果可能）\n    x_points = linspace(0, 1, 100);\n    y_points = zeros(length(x_points), 1);\n    \n    % 绘制ROC曲线\n    plot([0, 1], [0, 1], 'k--', 'LineWidth', 1.5); % 对角线\n    hold on;\n    \n    for i = 1:k\n        if ~isnan(cv_results.auc(i)) && cv_results.auc(i) > 0.5\n            % 绘制简化的ROC曲线\n            x0 = 0;\n            y0 = 0;\n            x1 = 1 - cv_results.specificity(i);\n            y1 = cv_results.recall(i);\n            x2 = 1;\n            y2 = 1;\n            \n            % 绘制折线\n            plot([x0, x1, x2], [y0, y1, y2], '-', 'Color', [0.7, 0.7, 0.7, 0.3], 'LineWidth', 0.5);\n            \n            % 计算近似曲线下面积\n            for j = 1:length(x_points)\n                x = x_points(j);\n                if x <= x1\n                    y = y1 * x / x1;\n                else\n                    y = y1 + (y2 - y1) * (x - x1) / (x2 - x1);\n                end\n                y_points(j) = y_points(j) + y / k;\n            end\n        end\n    end\n    \n    % 绘制平均ROC曲线\n    plot(x_points, y_points, '-', 'LineWidth', 2, 'Color', [0.8, 0.2, 0.2], 'DisplayName', '平均ROC曲线');\n    \n    % 添加AUC值\n    mean_auc = mean(cv_results.auc, 'omitnan');\n    text(0.6, 0.2, sprintf('平均AUC = %.3f ± %.3f', mean_auc, std(cv_results.auc, 'omitnan')), ...\n        'FontSize', 10, 'FontWeight', 'bold');\n    \n    % 设置图形属性\n    xlabel('1 - 特异性', 'FontSize', 12);\n    ylabel('敏感性', 'FontSize', 12);\n    title('平均ROC曲线', 'FontSize', 14, 'FontWeight', 'bold');\n    grid on;\n    legend('无信息线', '平均ROC曲线', 'Location', 'southeast');\n    \ncatch ME\n    % 如果ROC曲线绘制失败，显示错误消息\n    text(0.5, 0.5, '无法生成ROC曲线', 'HorizontalAlignment', 'center', 'FontSize', 12);\n    log_message('warning', sprintf('绘制ROC曲线失败: %s', ME.message));\nend\n\n% 调整整体布局\nsgtitle('K折交叉验证性能分析', 'FontSize', 16, 'FontWeight', 'bold');\nset(gcf, 'Color', 'white');\n\n% 保存矢量图\nsave_figure(fig, figure_dir, 'cv_performance', 'Formats', {'svg'});\n\n% 关闭图形\nclose(fig);\nend\n\n%% 创建系数稳定性图 - 新增\nfunction create_coefficient_stability_plot(coef_stability, methods, figure_dir)\n% 创建系数稳定性图\n% 输入:\n%   coef_stability - 系数稳定性结果\n%   methods - 方法名称\n%   figure_dir - 图形保存目录\n\n% 对每种支持的方法创建图形\nfor m = 1:length(methods)\n    method = methods{m};\n    \n    % 检查该方法是否有系数稳定性结果\n    if isfield(coef_stability, method) && isfield(coef_stability.(method), 'table')\n        \n        % 提取数据\n        table_data = coef_stability.(method).table;\n        var_list = table_data.Variable;\n        coef_mean = table_data.Mean;\n        coef_std = table_data.StdDev;\n        coef_cv = table_data.CV;\n        \n        % 创建图形\n        fig = figure('Name', sprintf('%s Coefficient Stability', method), 'Position', [100, 100, 1200, 800]);\n        \n        % 创建子图1：系数均值和标准差\n        subplot(2, 1, 1);\n        \n        % 创建条形图\n        bar_h = bar(coef_mean);\n        hold on;\n        \n        % 添加误差线\n        errorbar(1:length(coef_mean), coef_mean, coef_std, '.k');\n        \n        % 设置图形属性\n        set(gca, 'XTick', 1:length(var_list), 'XTickLabel', var_list, 'XTickLabelRotation', 45);\n        ylabel('系数值', 'FontSize', 12);\n        title(sprintf('%s方法的系数均值和标准差', method), 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加零线\n        line([0, length(var_list)+1], [0, 0], 'Color', 'k', 'LineStyle', '--', 'LineWidth', 1);\n        \n        % 创建子图2：系数变异系数\n        subplot(2, 1, 2);\n        \n        % 按变异系数大小排序\n        [sorted_cv, idx] = sort(coef_cv, 'descend');\n        sorted_vars = var_list(idx);\n        \n        % 创建条形图\n        bar_h = barh(sorted_cv);\n        set(bar_h, 'FaceColor', [0.3, 0.6, 0.8]);\n        \n        % 设置图形属性\n        set(gca, 'YTick', 1:length(sorted_vars), 'YTickLabel', sorted_vars);\n        xlabel('变异系数 (CV)', 'FontSize', 12);\n        title(sprintf('%s方法的系数稳定性 (变异系数)', method), 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加阈值线\n        line([0.5, 0.5], [0, length(sorted_vars)+1], 'Color', 'r', 'LineStyle', '--', 'LineWidth', 1);\n        text(0.52, length(sorted_vars)-1, '不稳定阈值 (CV > 0.5)', 'Color', 'r', 'FontSize', 10);\n        \n        % 调整整体布局\n        sgtitle(sprintf('%s方法的系数稳定性分析', method), 'FontSize', 16, 'FontWeight', 'bold');\n        set(gcf, 'Color', 'white');\n                \n        % 保存矢量图\n        save_figure(fig, figure_dir, '_coefficient_stability', 'MethodName', method);\n        \n        % 关闭图形\n        close(fig);\n    end\nend\n\n% 创建所有方法的综合比较图\ntry\n    % 收集所有方法的变异系数\n    all_methods = {};\n    all_vars = {};\n    all_cvs = [];\n    \n    for m = 1:length(methods)\n        method = methods{m};\n        if isfield(coef_stability, method) && isfield(coef_stability.(method), 'table')\n            table_data = coef_stability.(method).table;\n            \n            % 只考虑截距项\n            for i = 1:height(table_data)\n                all_methods{end+1} = method;\n                all_vars{end+1} = table_data.Variable{i};\n                all_cvs(end+1) = table_data.CV(i);\n            end\n        end\n    end\n    \n    % 如果有足够的数据，创建比较图\n    if length(all_cvs) >= 3\n        fig = figure('Name', 'Coefficient Stability Comparison', 'Position', [100, 100, 1200, 600]);\n        \n        % 创建散点图\n        scatter(1:length(all_cvs), all_cvs, 50, 'filled', 'MarkerFaceAlpha', 0.7);\n        \n        % 添加方法和变量标签\n        for i = 1:length(all_cvs)\n            text(i, all_cvs(i) + 0.03, sprintf('%s\\n%s', all_methods{i}, all_vars{i}), ...\n                'HorizontalAlignment', 'center', 'FontSize', 8, 'Rotation', 45);\n        end\n        \n        % 设置图形属性\n        set(gca, 'XTick', []);\n        ylabel('变异系数 (CV)', 'FontSize', 12);\n        title('各方法系数稳定性比较', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加阈值线\n        line([0, length(all_cvs)+1], [0.5, 0.5], 'Color', 'r', 'LineStyle', '--', 'LineWidth', 1);\n        text(length(all_cvs)*0.9, 0.52, '不稳定阈值 (CV > 0.5)', 'Color', 'r', 'FontSize', 10);\n        \n        % 调整图形\n        set(gcf, 'Color', 'white');\n                \n        % 保存矢量图\n        save_figure(fig, figure_dir, 'coefficient_stability_comparison', 'Formats', {'svg'});\n        \n        % 关闭图形\n        close(fig);\n    end\ncatch ME\n    log_message('warning', sprintf('创建系数稳定性比较图失败: %s', ME.message));\nend\nend\n\n%% 创建变量贡献图 - 新增\nfunction create_variable_contribution_plot(var_contribution, figure_dir)\n% 创建变量贡献图\n% 输入:\n%   var_contribution - 变量贡献分析结果\n%   figure_dir - 图形保存目录\n\n\n\n% 创建综合变量重要性图\nif isfield(var_contribution, 'overall_importance')\n    try\n        % 提取数据\n        importance_table = var_contribution.overall_importance;\n        vars = importance_table.Variable;\n        importance = importance_table.Normalized_Importance;\n        \n        % 取前10个变量\n        top_n = min(10, length(vars));\n        top_vars = vars(1:top_n);\n        top_importance = importance(1:top_n);\n        \n        % 创建图形\n        fig = figure('Name', 'Overall Variable Importance', 'Position', [100, 100, 1000, 600]);\n        \n        % 创建条形图\n        barh_h = barh(top_importance);\n        set(barh_h, 'FaceColor', [0.3, 0.6, 0.8]);\n        \n        % 设置图形属性\n        set(gca, 'YTick', 1:top_n, 'YTickLabel', top_vars);\n        xlabel('归一化重要性 (%)', 'FontSize', 12);\n        title('综合变量重要性排名 (前10个变量)', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加数值标签\n        for i = 1:top_n\n            text(top_importance(i) + 0.5, i, sprintf('%.2f%%', top_importance(i)), ...\n                'VerticalAlignment', 'middle', 'FontSize', 9);\n        end\n        \n        % 调整图形\n        set(gcf, 'Color', 'white');\n        \n        % 保存矢量图\n        save_figure(fig, figure_dir, 'overall_variable_importance', 'Formats', {'svg'});\n        \n        % 关闭图形\n        close(fig);\n    catch ME\n        log_message('warning', sprintf('创建综合变量重要性图失败: %s', ME.message));\n    end\nend\n\n% 创建相关性分析图\nif isfield(var_contribution, 'correlation')\n    try\n        % 提取数据\n        corr_table = var_contribution.correlation;\n        vars = corr_table.Variable;\n        corr_values = corr_table.Correlation;\n        partial_corr = corr_table.PartialCorr;\n        \n        % 按偏相关系数绝对值排序\n        [~, idx] = sort(abs(partial_corr), 'descend');\n        sorted_vars = vars(idx);\n        sorted_corr = corr_values(idx);\n        sorted_partial = partial_corr(idx);\n        \n        % 取前10个变量\n        top_n = min(10, length(sorted_vars));\n        top_vars = sorted_vars(1:top_n);\n        top_corr = sorted_corr(1:top_n);\n        top_partial = sorted_partial(1:top_n);\n        \n        % 创建图形\n        fig = figure('Name', 'Correlation Analysis', 'Position', [100, 100, 1000, 600]);\n        \n        % 创建分组条形图\n        bar_data = [top_corr, top_partial];\n        bar_h = barh(bar_data);\n        set(bar_h(1), 'FaceColor', [0.3, 0.6, 0.8]);\n        set(bar_h(2), 'FaceColor', [0.8, 0.3, 0.3]);\n        \n        % 设置图形属性\n        set(gca, 'YTick', 1:top_n, 'YTickLabel', top_vars);\n        xlabel('相关系数', 'FontSize', 12);\n        title('变量相关性分析 (前10个变量)', 'FontSize', 14, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加图例\n        legend({'普通相关', '偏相关'}, 'Location', 'southeast');\n        \n        % 添加参考线\n        line([0, 0], [0, top_n+1], 'Color', 'k', 'LineStyle', '--', 'LineWidth', 1);\n        \n        % 调整图形\n        set(gcf, 'Color', 'white');\n                \n        % 保存矢量图\n        save_figure(fig, figure_dir, 'correlation_analysis', 'Formats', {'svg'});\n\n        % 关闭图形\n        close(fig);\n    catch ME\n        log_message('warning', sprintf('创建相关性分析图失败: %s', ME.message));\n    end\nend\n\n% 为各个方法创建变量贡献图\nif isfield(var_contribution, 'methods')\n    method_names = fieldnames(var_contribution.methods);\n    \n    for m = 1:length(method_names)\n        method = method_names{m};\n        \n        % 检查该方法是否有贡献表\n        if isfield(var_contribution.methods.(method), 'contribution_table')\n            try\n                % 提取数据\n                contrib_table = var_contribution.methods.(method).contribution_table;\n                \n                % 创建图形\n                fig = figure('Name', sprintf('%s Variable Contribution', method), 'Position', [100, 100, 1000, 600]);\n                \n                % 提取变量和贡献\n                vars = contrib_table.Variable;\n                rel_contrib = contrib_table.Relative_Contribution;\n                \n                % 取前10个变量\n                top_n = min(10, height(contrib_table));\n                top_vars = vars(1:top_n);\n                top_contrib = rel_contrib(1:top_n);\n                \n                % 为不同方法设置不同的表现形式\n                if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n                    % 回归类方法显示系数和相对贡献\n                    \n                    % 提取系数和方向\n                    coeffs = contrib_table.Std_Coefficient(1:top_n);\n                    directions = contrib_table.Effect_Direction(1:top_n);\n                    \n                    % 创建颜色映射\n                    colors = zeros(top_n, 3);\n                    for i = 1:top_n\n                        if strcmp(directions{i}, '正向')\n                            colors(i,:) = [0.2, 0.6, 0.8]; % 蓝色表示正向影响\n                        else\n                            colors(i,:) = [0.8, 0.3, 0.3]; % 红色表示负向影响\n                        end\n                    end\n                    \n                    % 创建水平条形图\n                    bar_h = barh(top_contrib);\n                    set(bar_h, 'FaceColor', 'flat');\n                    bar_h.CData = colors;\n                    \n                    % 设置图形属性\n                    set(gca, 'YTick', 1:top_n, 'YTickLabel', top_vars);\n                    xlabel('相对贡献 (%)', 'FontSize', 12);\n                    title(sprintf('%s方法的变量贡献分析 (前%d个变量)', method, top_n), 'FontSize', 14, 'FontWeight', 'bold');\n                    grid on;\n                    \n                    % 添加方向指示\n                    for i = 1:top_n\n                        if strcmp(directions{i}, '正向')\n                            text(top_contrib(i) + 0.5, i, '(+)', 'VerticalAlignment', 'middle', 'FontSize', 9, 'Color', [0, 0.5, 0]);\n                        else\n                            text(top_contrib(i) + 0.5, i, '(-)', 'VerticalAlignment', 'middle', 'FontSize', 9, 'Color', [0.8, 0, 0]);\n                        end\n                    end\n                    \n                else\n                    % 非回归类方法只显示重要性\n                    bar_h = barh(top_contrib);\n                    set(bar_h, 'FaceColor', [0.3, 0.6, 0.8]);\n                    \n                    % 设置图形属性\n                    set(gca, 'YTick', 1:top_n, 'YTickLabel', top_vars);\n                    xlabel('相对贡献 (%)', 'FontSize', 12);\n                    title(sprintf('%s方法的变量重要性 (前%d个变量)', method, top_n), 'FontSize', 14, 'FontWeight', 'bold');\n                    grid on;\n                end\n                \n                % 添加数值标签\n                for i = 1:top_n\n                    text(top_contrib(i) + 0.5, i, sprintf('%.2f%%', top_contrib(i)), ...\n                        'VerticalAlignment', 'middle', 'FontSize', 9);\n                end\n                \n                % 调整图形\n                set(gcf, 'Color', 'white');\n                                \n                % 保存矢量图\n                save_figure(fig, figure_dir, [method, '_variable_contribution'], 'Formats', {'svg'});\n                \n                % 关闭图形\n                close(fig);\n            catch ME\n                log_message('warning', sprintf('创建%s方法的变量贡献图失败: %s', method, ME.message));\n            end\n        end\n    end\nend\nend\n\n%% 箱线图可视化函数\nfunction create_boxplot_visualization(results, methods, figure_dir)\n    % 创建箱线图可视化\n    % 输入:\n    %   results - 结果结构\n    %   methods - 方法名称\n    %   figure_dir - 图形保存目录\n\n    % 定义性能指标名称\n    metric_names = {'Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1_Score', 'AUC'};\n    n_metrics = length(metric_names);\n    n_methods = length(methods);\n\n    % 初始化数据矩阵\n    data = cell(n_methods, n_metrics);\n    for i = 1:n_methods\n        method = methods{i};\n        if isfield(results, method) && isfield(results.(method), 'performance')\n            perf = results.(method).performance;\n            \n            % 检查并填充每个指标的数据\n            data{i, 1} = check_data(perf, 'accuracy', method, 'Accuracy');\n            data{i, 2} = check_data(perf, 'sensitivity', method, 'Sensitivity');\n            data{i, 3} = check_data(perf, 'specificity', method, 'Specificity');\n            data{i, 4} = check_data(perf, 'precision', method, 'Precision');\n            data{i, 5} = check_data(perf, 'f1_score', method, 'F1_Score');\n            data{i, 6} = check_data(perf, 'auc', method, 'AUC');\n        else\n            % 如果方法或性能数据缺失，填充 NaN\n            log_message('warning', sprintf('Method %s is missing in results or performance data', method));\n            for j = 1:n_metrics\n                data{i, j} = NaN;\n            end\n        end\n    end\n\n    % 为每个指标创建箱线图\n    for i = 1:n_metrics\n        metric = metric_names{i};\n        \n        % 提取当前指标的数据\n        metric_data_cell = data(:, i);\n        \n        % 确定最大数据长度并填充 NaN\n        max_len = 0;\n        for j = 1:n_methods\n            if ~isempty(metric_data_cell{j}) && ~all(isnan(metric_data_cell{j}))\n                max_len = max(max_len, length(metric_data_cell{j}));\n            end\n        end\n        \n        % 如果没有有效数据，跳过\n        if max_len == 0\n            log_message('warning', sprintf('No valid data available for metric %s', metric));\n            continue;\n        end\n        \n        % 创建矩阵，填充 NaN 以对齐维度\n        metric_data = NaN(max_len, n_methods);\n        for j = 1:n_methods\n            current_data = metric_data_cell{j};\n            if ~isempty(current_data) && ~all(isnan(current_data))\n                len = length(current_data);\n                metric_data(1:len, j) = current_data;\n            end\n        end\n        \n        % 验证列数与方法数一致\n        if size(metric_data, 2) ~= n_methods\n            log_message('error', sprintf('metric_data has %d columns, but there are %d methods for %s', ...\n                size(metric_data, 2), n_methods, metric));\n            continue;\n        end\n        \n        % 创建图形\n        fig = figure('Name', sprintf('%s Boxplot', metric), 'Position', [100, 100, 1000, 600]);\n        \n        % 创建箱线图\n        boxplot(metric_data, 'Labels', methods, 'Notch', 'on', 'Symbol', 'r+');\n        \n        % 设置图形属性\n        title(sprintf('%s分布箱线图 - 各方法比较', metric), 'FontSize', 14, 'FontWeight', 'bold');\n        ylabel(metric, 'FontSize', 12, 'FontWeight', 'bold');\n        grid on;\n        \n        % 添加均值点\n        hold on;\n        means = nanmean(metric_data);\n        scatter(1:n_methods, means, 100, 'filled', 'MarkerFaceColor', 'r', 'MarkerEdgeColor', 'k');\n        \n        % 添加均值和标准差标签\n        for j = 1:n_methods\n            method_data = metric_data(:, j);\n            mean_val = nanmean(method_data);\n            std_val = nanstd(method_data);\n            text(j, max(method_data, [], 'omitnan') + 0.02, sprintf('均值: %.3f\\n标准差: %.3f', mean_val, std_val), ...\n                'HorizontalAlignment', 'center', 'FontSize', 9);\n        end\n        \n        % 添加整体均值线\n        overall_mean = nanmean(metric_data(:));\n        plot([0.5, n_methods+0.5], [overall_mean, overall_mean], 'k--', 'LineWidth', 1.5);\n        text(n_methods+0.5, overall_mean, sprintf(' 总体均值: %.3f', overall_mean), ...\n            'VerticalAlignment', 'middle', 'FontSize', 9);\n        \n        % 调整 Y 轴范围\n        ylim_current = ylim;\n        ylim([ylim_current(1), ylim_current(2) + 0.1]);\n        \n        % 保存图形\n        save_figure(fig, figure_dir, sprintf('boxplot_%s', lower(metric)), 'Formats', {'svg'});\n        close(fig);\n    end\nend\n\n% 辅助函数：检查和处理数据\nfunction data_out = check_data(perf, field, method, metric_name)\n    if isfield(perf, field) && ~isempty(perf.(field))\n        data_out = perf.(field);\n    else\n        log_message('warning', sprintf('Method %s has missing or empty %s data', method, metric_name));\n        data_out = NaN;\n    end\nend\n\n%% 平均Precision-Recall曲线函数\nfunction create_pr_curves(results, methods, figure_dir)\n% 创建精确率-召回率曲线图\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   figure_dir - 图形保存目录\n\nfig = figure('Name', 'Precision-Recall Curves', 'Position', [100, 100, 1000, 800]);\n\ncolors = lines(length(methods));\nmarkers = {'o', 's', 'd', '^', 'v', '>', '<', 'p', 'h'};\nhold on;\n\nlegend_entries = cell(length(methods), 1);\n\n% 创建标准PR曲线点\nstd_recall = linspace(0, 1, 100)';\navg_precision = zeros(100, length(methods));\n\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    % 计算平均精确率-召回率曲线\n    all_recall = [];\n    all_precision = [];\n    \n    % 如果存在性能结构中的预测概率，使用它们绘制PR曲线\n    if isfield(results.(method).performance, 'y_pred_prob') && ...\n       isfield(results.(method).performance, 'y_test')\n        \n        y_pred_prob = results.(method).performance.y_pred_prob;\n        y_test = results.(method).performance.y_test;\n        \n        % 对每个Bootstrap样本计算PR曲线\n        for j = 1:length(y_pred_prob)\n            if ~isempty(y_pred_prob{j}) && ~isempty(y_test{j})\n                [precision, recall, ~] = precision_recall_curve(y_test{j}, y_pred_prob{j});\n                \n                % 存储所有召回率和精确率值\n                all_recall = [all_recall; recall];\n                all_precision = [all_precision; precision];\n            end\n        end\n        \n        % 如果收集到足够的点，绘制平均PR曲线\n        if ~isempty(all_recall) && ~isempty(all_precision)\n            % 对所有样本的召回率进行排序\n            [sorted_recall, idx] = sort(all_recall);\n            sorted_precision = all_precision(idx);\n            \n            % 在标准召回率点计算平均精确率\n            for k = 1:length(std_recall)\n                r = std_recall(k);\n                % 找出大于或等于r的最接近点\n                idx = find(sorted_recall >= r, 1, 'first');\n                if isempty(idx)\n                    avg_precision(k, i) = 0;\n                else\n                    avg_precision(k, i) = sorted_precision(idx);\n                end\n            end\n            \n            % 计算平均精确率 (AP)\n            ap = trapz(std_recall, avg_precision(:, i));\n            \n            % 绘制PR曲线\n            color_idx = mod(i-1, size(colors, 1)) + 1;\n            plot(std_recall, avg_precision(:, i), '-', 'Color', colors(color_idx,:), 'LineWidth', 2);\n            \n            % 在曲线上标记数据点\n            marker_idx = mod(i-1, length(markers)) + 1;\n            num_points = 10; % 均匀分布的点数\n            point_idx = round(linspace(1, length(std_recall), num_points));\n            plot(std_recall(point_idx), avg_precision(point_idx, i), markers{marker_idx}, ...\n                'Color', colors(color_idx,:), 'MarkerSize', 8, 'MarkerFaceColor', colors(color_idx,:));\n            \n            legend_entries{i} = sprintf('%s (AP=%.3f)', method, ap);\n        else\n            % 如果没有足够的数据点，使用性能指标中的平均值绘制单个点\n            recall = results.(method).performance.avg_sensitivity;\n            precision = results.(method).performance.avg_precision;\n            \n            color_idx = mod(i-1, size(colors, 1)) + 1;\n            marker_idx = mod(i-1, length(markers)) + 1;\n            \n            plot(recall, precision, markers{marker_idx}, 'Color', colors(color_idx,:), ...\n                'MarkerSize', 12, 'LineWidth', 2, 'MarkerFaceColor', colors(color_idx,:));\n            \n            legend_entries{i} = sprintf('%s (单点)', method);\n        end\n    else\n        % 使用单点性能指标\n        recall = results.(method).performance.avg_sensitivity;\n        precision = results.(method).performance.avg_precision;\n        \n        color_idx = mod(i-1, size(colors, 1)) + 1;\n        marker_idx = mod(i-1, length(markers)) + 1;\n        \n        plot(recall, precision, markers{marker_idx}, 'Color', colors(color_idx,:), ...\n            'MarkerSize', 12, 'LineWidth', 2, 'MarkerFaceColor', colors(color_idx,:));\n        \n        legend_entries{i} = sprintf('%s (单点)', method);\n    end\nend\n\n% 添加随机分类器的基准线\nrandom_precision = sum([results.(methods{1}).performance.avg_sensitivity]) / length(methods);\nplot([0, 1], [random_precision, random_precision], 'k--', 'LineWidth', 1.5);\nlegend_entries{end+1} = sprintf('随机 (Precision=%.3f)', random_precision);\n\n% 设置图形属性\nxlim([0, 1]);\nylim([0, 1]);\nxlabel('召回率 (Recall)', 'FontSize', 12, 'FontWeight', 'bold');\nylabel('精确率 (Precision)', 'FontSize', 12, 'FontWeight', 'bold');\ntitle('不同变量选择方法的精确率-召回率曲线比较', 'FontSize', 14, 'FontWeight', 'bold');\nlegend(legend_entries, 'Location', 'southwest', 'FontSize', 10);\ngrid on;\nset(gca, 'FontSize', 11);\nbox on;\n\n% 保存图形\nsave_figure(fig, figure_dir, 'precision_recall_curves', 'Formats', {'svg'});\nclose(fig);\nend\n\n% 辅助函数：计算精确率-召回率曲线\nfunction [precision, recall, thresholds] = precision_recall_curve(y_true, y_score)\n% 计算精确率-召回率曲线\n% 输入:\n%   y_true - 真实标签\n%   y_score - 预测分数或概率\n% 输出:\n%   precision - 精确率\n%   recall - 召回率\n%   thresholds - 阈值\n\n% 获取唯一的阈值，以降序排列\nthresholds = sort(unique(y_score), 'descend');\n\n% 添加0作为最后一个阈值\nthresholds = [thresholds; -Inf];\n\nn_thresholds = length(thresholds);\nprecision = zeros(n_thresholds, 1);\nrecall = zeros(n_thresholds, 1);\n\nfor i = 1:n_thresholds\n    threshold = thresholds(i);\n    \n    % 在当前阈值下的预测\n    y_pred = y_score >= threshold;\n    \n    % 计算混淆矩阵元素\n    TP = sum(y_pred == 1 & y_true == 1);\n    FP = sum(y_pred == 1 & y_true == 0);\n    FN = sum(y_pred == 0 & y_true == 1);\n    \n    % 计算精确率和召回率\n    if TP + FP == 0\n        precision(i) = 1;  % 如果没有阳性预测，精确率为1\n    else\n        precision(i) = TP / (TP + FP);\n    end\n    \n    if TP + FN == 0\n        recall(i) = 0;  % 如果没有真阳性，召回率为0\n    else\n        recall(i) = TP / (TP + FN);\n    end\nend\n\n% 确保精确率-召回率曲线是单调递减的\nfor i = n_thresholds-1:-1:1\n    precision(i) = max(precision(i), precision(i+1));\nend\nend\n\n%% 校准曲线图函数\nfunction create_calibration_curves(results, methods, figure_dir)\n% 创建校准曲线图\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   figure_dir - 图形保存目录\n\nfig = figure('Name', 'Calibration Curves', 'Position', [100, 100, 1000, 800]);\n\ncolors = lines(length(methods));\nmarkers = {'o', 's', 'd', '^', 'v', '>', '<', 'p', 'h'};\nhold on;\n\nlegend_entries = cell(length(methods), 1);\n\n% 绘制理想校准曲线\nplot([0, 1], [0, 1], 'k--', 'LineWidth', 1.5);\n\nn_bins = 10;  % 分箱数量\nbin_edges = linspace(0, 1, n_bins+1);\nbin_centers = (bin_edges(1:end-1) + bin_edges(2:end)) / 2;\n\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    % 检查是否存在预测概率\n    if isfield(results.(method).performance, 'y_pred_prob') && ...\n       isfield(results.(method).performance, 'y_test')\n        \n        y_pred_prob = results.(method).performance.y_pred_prob;\n        y_test = results.(method).performance.y_test;\n        \n        % 合并所有Bootstrap样本的数据\n        all_probs = [];\n        all_labels = [];\n        \n        for j = 1:length(y_pred_prob)\n            if ~isempty(y_pred_prob{j}) && ~isempty(y_test{j})\n                all_probs = [all_probs; y_pred_prob{j}];\n                all_labels = [all_labels; y_test{j}];\n            end\n        end\n        \n        if ~isempty(all_probs) && ~isempty(all_labels)\n            % 计算校准曲线\n            [fraction_of_positives, mean_predicted_value] = calibration_curve(all_labels, all_probs, n_bins);\n            \n            % 绘制校准曲线\n            color_idx = mod(i-1, size(colors, 1)) + 1;\n            marker_idx = mod(i-1, length(markers)) + 1;\n            \n            plot(mean_predicted_value, fraction_of_positives, ['-' markers{marker_idx}], ...\n                'Color', colors(color_idx,:), 'LineWidth', 2, 'MarkerSize', 8, ...\n                'MarkerFaceColor', colors(color_idx,:));\n            \n            % 计算Brier分数（校准误差）\n            brier_score = mean((all_probs - all_labels).^2);\n            \n            legend_entries{i} = sprintf('%s (Brier=%.3f)', method, brier_score);\n        else\n            legend_entries{i} = method;\n        end\n    else\n        % 使用单点性能指标\n        y_pred = results.(method).performance.avg_sensitivity;\n        y_true = results.(method).performance.avg_precision;\n        \n        color_idx = mod(i-1, size(colors, 1)) + 1;\n        marker_idx = mod(i-1, length(markers)) + 1;\n        \n        plot(y_pred, y_true, markers{marker_idx}, 'Color', colors(color_idx,:), ...\n            'MarkerSize', 12, 'LineWidth', 2, 'MarkerFaceColor', colors(color_idx,:));\n        \n        legend_entries{i} = sprintf('%s (单点)', method);\n    end\nend\n\n% 设置图形属性\nxlim([0, 1]);\nylim([0, 1]);\nxlabel('预测概率', 'FontSize', 12, 'FontWeight', 'bold');\nylabel('实际阳性比例', 'FontSize', 12, 'FontWeight', 'bold');\ntitle('不同变量选择方法的校准曲线比较', 'FontSize', 14, 'FontWeight', 'bold');\nlegend([legend_entries; {'完美校准'}], 'Location', 'southeast', 'FontSize', 10);\ngrid on;\nset(gca, 'FontSize', 11);\nbox on;\n\n% 保存图形\nsave_figure(fig, figure_dir, 'calibration_curves', 'Formats', {'svg'});\nclose(fig);\nend\n\n% 辅助函数：计算校准曲线\nfunction [fraction_of_positives, mean_predicted_value] = calibration_curve(y_true, y_prob, n_bins)\n% 计算校准曲线\n% 输入:\n%   y_true - 真实标签\n%   y_prob - 预测概率\n%   n_bins - 分箱数量\n% 输出:\n%   fraction_of_positives - 每个分箱中的实际阳性比例\n%   mean_predicted_value - 每个分箱的平均预测概率\n\n% 计算分箱边界\nbin_edges = linspace(0, 1, n_bins+1);\n\n% 初始化结果数组\nfraction_of_positives = zeros(n_bins, 1);\nmean_predicted_value = zeros(n_bins, 1);\n\n% 对每个分箱计算\nfor i = 1:n_bins\n    % 找出落入当前分箱的样本\n    bin_mask = (y_prob >= bin_edges(i)) & (y_prob < bin_edges(i+1));\n    \n    % 如果分箱为空，使用默认值\n    if sum(bin_mask) == 0\n        fraction_of_positives(i) = 0;\n        mean_predicted_value(i) = (bin_edges(i) + bin_edges(i+1)) / 2;\n    else\n        % 计算实际阳性比例\n        fraction_of_positives(i) = mean(y_true(bin_mask));\n        \n        % 计算平均预测概率\n        mean_predicted_value(i) = mean(y_prob(bin_mask));\n    end\nend\nend\n\n%% 混淆矩阵可视化函数\nfunction create_confusion_matrices(results, methods, figure_dir)\n    % 创建混淆矩阵可视化\n    % 输入:\n    %   results - 结果结构\n    %   methods - 方法名称\n    %   figure_dir - 图形保存目录\n\n    % 为每种方法创建混淆矩阵\n    for i = 1:length(methods)\n        method = methods{i};\n        \n        % 获取性能指标\n        performance = results.(method).performance;\n        \n        % 计算平均混淆矩阵\n        if isfield(performance, 'y_pred') && isfield(performance, 'y_test')\n            y_pred = performance.y_pred;\n            y_test = performance.y_test;\n            \n            % 初始化混淆矩阵\n            conf_matrix = zeros(2, 2);\n            count = 0;\n            \n            % 合并所有Bootstrap样本的混淆矩阵\n            for j = 1:length(y_pred)\n                if ~isempty(y_pred{j}) && ~isempty(y_test{j})\n                    % 计算当前样本的混淆矩阵\n                    pred = y_pred{j};\n                    test = y_test{j};\n                    \n                    TP = sum(pred == 1 & test == 1);\n                    FP = sum(pred == 1 & test == 0);\n                    FN = sum(pred == 0 & test == 1);\n                    TN = sum(pred == 0 & test == 0);\n                    \n                    conf_matrix = conf_matrix + [TN, FP; FN, TP];\n                    count = count + 1;\n                end\n            end\n            \n            if count > 0\n                conf_matrix = conf_matrix / count;\n            end\n        else\n            % 使用性能指标估算混淆矩阵\n            sensitivity = performance.avg_sensitivity;\n            specificity = performance.avg_specificity;\n            precision = performance.avg_precision;\n            \n            % 假设测试集中正负样本比例为1:1\n            TP = sensitivity * 50;\n            FN = 50 - TP;\n            FP = TP / precision - TP;\n            TN = specificity * 50;\n            \n            conf_matrix = [TN, FP; FN, TP];\n        end\n        \n        % 计算归一化混淆矩阵（按行归一化）\n        conf_matrix_norm = zeros(2, 2);\n        for j = 1:2\n            if sum(conf_matrix(j, :)) > 0\n                conf_matrix_norm(j, :) = conf_matrix(j, :) / sum(conf_matrix(j, :));\n            end\n        end\n        \n        % 创建混淆矩阵图\n        fig = figure('Name', sprintf('%s Confusion Matrix', method), 'Position', [100, 100, 800, 600]);\n        \n        % 绘制混淆矩阵热图\n        subplot(1, 2, 1);\n        h = heatmap(conf_matrix, 'XLabel', '预测', 'YLabel', '实际', ...\n            'XDisplayLabels', {'负类 (0)', '正类 (1)'}, 'YDisplayLabels', {'负类 (0)', '正类 (1)'});\n        % 修改：直接在热图对象上设置标题\n        h.Title = sprintf('%s: 原始混淆矩阵', method);\n        h.FontSize = 12;\n        colormap(jet);\n        \n        % 绘制归一化混淆矩阵热图\n        subplot(1, 2, 2);\n        h_norm = heatmap(conf_matrix_norm, 'XLabel', '预测', 'YLabel', '实际', ...\n            'XDisplayLabels', {'负类 (0)', '正类 (1)'}, 'YDisplayLabels', {'负类 (0)', '正类 (1)'});\n        % 修改：直接在热图对象上设置标题\n        h_norm.Title = sprintf('%s: 归一化混淆矩阵', method);\n        h_norm.FontSize = 12;\n        colormap(jet);\n        \n        % 计算性能指标\n        TN = conf_matrix(1, 1);\n        FP = conf_matrix(1, 2);\n        FN = conf_matrix(2, 1);\n        TP = conf_matrix(2, 2);\n        \n        accuracy = (TP + TN) / sum(conf_matrix(:));\n        sensitivity = TP / (TP + FN);\n        specificity = TN / (TN + FP);\n        precision = TP / (TP + FP);\n        f1_score = 2 * precision * sensitivity / (precision + sensitivity);\n        \n        % 创建标题包含性能指标\n        sgtitle(sprintf('%s 混淆矩阵分析\\n准确率=%.3f, 灵敏度=%.3f, 特异性=%.3f, 精确率=%.3f, F1=%.3f', ...\n            method, accuracy, sensitivity, specificity, precision, f1_score), ...\n            'FontSize', 14, 'FontWeight', 'bold');\n        \n        % 保存图形\n        save_figure(fig, figure_dir, sprintf('%s_confusion_matrix', method), 'Formats', {'svg'});\n        close(fig);\n    end\n\n    % 创建所有方法的混淆矩阵比较图\n    try\n        % 计算每种方法的归一化混淆矩阵\n        all_conf_matrices = cell(length(methods), 1);\n        all_performance = zeros(length(methods), 4); % 准确率、灵敏度、特异性、精确率\n        \n        for i = 1:length(methods)\n            method = methods{i};\n            performance = results.(method).performance;\n            \n            if isfield(performance, 'y_pred') && isfield(performance, 'y_test')\n                y_pred = performance.y_pred;\n                y_test = performance.y_test;\n                \n                % 初始化混淆矩阵\n                conf_matrix = zeros(2, 2);\n                count = 0;\n                \n                % 合并所有Bootstrap样本的混淆矩阵\n                for j = 1:length(y_pred)\n                    if ~isempty(y_pred{j}) && ~isempty(y_test{j})\n                        % 计算当前样本的混淆矩阵\n                        pred = y_pred{j};\n                        test = y_test{j};\n                        \n                        TP = sum(pred == 1 & test == 1);\n                        FP = sum(pred == 1 & test == 0);\n                        FN = sum(pred == 0 & test == 1);\n                        TN = sum(pred == 0 & test == 0);\n                        \n                        conf_matrix = conf_matrix + [TN, FP; FN, TP];\n                        count = count + 1;\n                    end\n                end\n                \n                % 计算平均混淆矩阵\n                if count > 0\n                    conf_matrix = conf_matrix / count;\n                end\n            else\n                % 使用性能指标估算混淆矩阵\n                sensitivity = performance.avg_sensitivity;\n                specificity = performance.avg_specificity;\n                precision = performance.avg_precision;\n                \n                % 假设测试集中正负样本比例为1:1\n                TP = sensitivity * 50;\n                FN = 50 - TP;\n                FP = TP / precision - TP;\n                TN = specificity * 50;\n                \n                conf_matrix = [TN, FP; FN, TP];\n            end\n            \n            % 计算归一化混淆矩阵（按行归一化）\n            conf_matrix_norm = zeros(2, 2);\n            for j = 1:2\n                if sum(conf_matrix(j, :)) > 0\n                    conf_matrix_norm(j, :) = conf_matrix(j, :) / sum(conf_matrix(j, :));\n                end\n            end\n            \n            all_conf_matrices{i} = conf_matrix_norm;\n            \n            % 计算性能指标\n            TN = conf_matrix(1, 1);\n            FP = conf_matrix(1, 2);\n            FN = conf_matrix(2, 1);\n            TP = conf_matrix(2, 2);\n            \n            accuracy = (TP + TN) / sum(conf_matrix(:));\n            sensitivity = TP / (TP + FN);\n            specificity = TN / (TN + FP);\n            precision = TP / (TP + FP);\n            \n            all_performance(i, :) = [accuracy, sensitivity, specificity, precision];\n        end\n        \n        % 创建比较图\n        fig = figure('Name', 'Confusion Matrix Comparison', 'Position', [100, 100, 1200, 900]);\n        \n        n_methods = length(methods);\n        rows = ceil(sqrt(n_methods));\n        cols = ceil(n_methods / rows);\n        \n        for i = 1:n_methods\n            subplot(rows, cols, i);\n            h = heatmap(all_conf_matrices{i}, 'XLabel', '预测', 'YLabel', '实际', ...\n                'XDisplayLabels', {'0', '1'}, 'YDisplayLabels', {'0', '1'});\n            % 修改：直接在热图对象上设置标题\n            h.Title = sprintf('%s\\n准确率=%.3f', methods{i}, all_performance(i, 1));\n            h.FontSize = 9;\n            colormap(jet);\n        end\n        \n        % 添加整体标题\n        sgtitle('各方法混淆矩阵比较 (归一化)', 'FontSize', 14, 'FontWeight', 'bold');\n        \n        % 保存图形\n        save_figure(fig, figure_dir, 'confusion_matrix_comparison', 'Formats', {'svg'});\n        close(fig);\n    catch ME\n        log_message('warning', sprintf('创建混淆矩阵比较图失败: %s', ME.message));\n    end\nend\n\n%% 修改1：修复图形保存函数 - 添加'-bestfit'选项\nfunction create_roc_curves(results, methods, figure_dir)\n    % 创建ROC曲线图\n    % 输入:\n    %   results - 结果结构\n    %   methods - 方法名称\n    %   figure_dir - 图形保存目录\n    fig = figure('Name', 'ROC Curves', 'Position', [100, 100, 1000, 800]);\n    \n    % 禁用工具栏\n    set(gcf, 'Toolbar', 'none');\n\n    colors = lines(length(methods));\n    markers = {'o', 's', 'd', '^', 'v', '>', '<', 'p', 'h'};\n    hold on;\n\n    legend_entries = cell(length(methods), 1);\n\n    for i = 1:length(methods)\n        method = methods{i};\n        auc = results.(method).performance.avg_auc;\n        sensitivity = results.(method).performance.avg_sensitivity;\n        specificity = results.(method).performance.avg_specificity;\n        precision = results.(method).performance.avg_precision;\n        f1_score = results.(method).performance.avg_f1_score;\n\n        fpr = 1 - specificity;\n        color_idx = mod(i-1, size(colors, 1)) + 1;\n        marker_idx = mod(i-1, length(markers)) + 1;\n\n        plot(fpr, sensitivity, [markers{marker_idx}], 'Color', colors(color_idx,:), ...\n            'MarkerSize', 12, 'LineWidth', 2, 'MarkerFaceColor', colors(color_idx,:));\n        plot([0, fpr, 1], [0, sensitivity, 1], '-', 'Color', colors(color_idx,:), 'LineWidth', 1.5);\n\n        legend_entries{i} = sprintf('%s (AUC=%.3f, F1=%.3f)', method, auc, f1_score);\n    end\n\n    plot([0, 1], [0, 1], 'k--', 'LineWidth', 1.5);\n\n    xlim([0, 1]);\n    ylim([0, 1]);\n    xlabel('假阳性率 (1 - 特异性)', 'FontSize', 12, 'FontWeight', 'bold');\n    ylabel('真阳性率 (敏感性)', 'FontSize', 12, 'FontWeight', 'bold');\n    title('不同变量选择方法的ROC曲线比较', 'FontSize', 14, 'FontWeight', 'bold');\n    legend([legend_entries; {'随机猜测'}], 'Location', 'southeast', 'FontSize', 10);\n    grid on;\n    set(gca, 'FontSize', 11);\n    box on;\n\n    text(0.05, 0.95, '注: 点表示在测试集上的平均性能', 'FontSize', 9);\n\n    set(gcf, 'Color', 'white');\n    set(gca, 'TickDir', 'out');\n\n    % 设置纸张属性\n    set(gcf, 'PaperPositionMode', 'manual');\n    set(gcf, 'PaperUnits', 'inches');\n    set(gcf, 'PaperSize', [12 8]); % 设置为 12x8 英寸\n    set(gcf, 'PaperPosition', [0 0 12 8]);\n\n    % 保存矢量图\n    save_figure(fig, figure_dir, 'roc_curves', 'Formats', {'svg'});\n    close(fig);\nend\n\n%% 修改2：修复create_variable_importance_plot函数\nfunction create_variable_importance_plot(results, methods, var_names, figure_dir)\n    % 计算每个变量的平均频率\n    var_freq = zeros(length(var_names), 1);\n    for i = 1:length(methods)\n        method = methods{i};\n        var_freq = var_freq + results.(method).var_freq;\n    end\n    var_freq = var_freq / length(methods);\n\n    [sorted_freq, idx] = sort(var_freq, 'descend');\n    sorted_names = var_names(idx);\n\n    ;\n    fig = figure('Name', 'Variable Importance', 'Position', [100, 100, 900, 700]);\n    \n    % 禁用工具栏\n    set(gcf, 'Toolbar', 'none');\n\n    h = barh(sorted_freq);\n    set(h, 'FaceColor', 'flat');\n\n    colormap(autumn);\n    for i = 1:length(sorted_freq)\n        h.CData(i,:) = [sorted_freq(i), 0.5, 1-sorted_freq(i)];\n    end\n\n    set(gca, 'YTick', 1:length(sorted_names), 'YTickLabel', sorted_names, 'FontSize', 10);\n    xlabel('选择频率', 'FontSize', 12, 'FontWeight', 'bold');\n    title('不同方法中变量重要性比较', 'FontSize', 14, 'FontWeight', 'bold');\n    grid on;\n    box on;\n\n    for i = 1:length(sorted_freq)\n        text(sorted_freq(i) + 0.03, i, sprintf('%.2f', sorted_freq(i)), ...\n            'VerticalAlignment', 'middle', 'FontSize', 9);\n    end\n\n    text(0.5, length(sorted_names) + 1.5, ...\n        ['注: 此图显示每个变量在', num2str(length(methods)), '种方法中的平均选择频率'], ...\n        'FontSize', 9, 'HorizontalAlignment', 'center');\n\n    set(gcf, 'Color', 'white');\n    set(gca, 'TickDir', 'out');\n    set(gcf, 'Position', [100, 100, 900, max(500, 150 + 30*length(sorted_names))]);\n\n    % 设置纸张属性\n    set(gcf, 'PaperPositionMode', 'manual');\n    set(gcf, 'PaperUnits', 'inches');\n    set(gcf, 'PaperSize', [10 8]); % 设置为 10x8 英寸\n    set(gcf, 'PaperPosition', [0 0 10 8]);\n\n    % 保存矢量图\n    save_figure(fig, figure_dir, 'variable_importance', 'Formats', {'svg'});\n    close(fig);\nend\n\n%% 修改3：修复create_variable_group_plot函数中的保存图形部分\nfunction create_variable_group_plot(results, methods, var_names, figure_dir)\n    % 创建变量组合可视化图\n    % 输入:\n    %   results - 结果结构\n    %   methods - 方法名称\n    %   var_names - 变量名称\n    %   figure_dir - 图形保存目录\n\n    % 对于每种方法创建图形\n    for i = 1:length(methods)\n        method = methods{i};\n        group_perf = results.(method).group_performance;\n        \n        % 如果有至少3个不同的组合，则创建图\n        if length(group_perf) >= 2\n            % 取前10个最常见的组合\n            top_n = min(10, length(group_perf));\n            \n            % 提取数据\n            combo_labels = cell(top_n, 1);\n            combo_counts = zeros(top_n, 1);\n            combo_aucs = zeros(top_n, 1);\n            combo_acc = zeros(top_n, 1);\n            combo_sens = zeros(top_n, 1);\n            combo_spec = zeros(top_n, 1);\n            combo_prec = zeros(top_n, 1);    \n            combo_f1 = zeros(top_n, 1);\n            \n            for j = 1:top_n\n                combo = group_perf(j);\n                var_str = sprintf('组合 %d', j);\n                combo_labels{j} = var_str;\n                combo_counts(j) = combo.count;\n                combo_aucs(j) = combo.auc;\n                combo_acc(j) = combo.accuracy;\n                combo_sens(j) = combo.sensitivity;\n                combo_spec(j) = combo.specificity;\n                combo_prec(j) = combo.precision;\n                combo_f1(j) = combo.f1_score;\n            end\n            \n            % 创建组合性能图\n            fig1 = figure('Name', sprintf('%s Variable Combinations', method), 'Position', [100, 100, 1200, 800]);\n            \n            % 创建子图1：组合计数\n            subplot(2, 2, 1);\n            bar(combo_counts, 'FaceColor', [0.3 0.6 0.9]);\n            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45, 'FontSize', 9);\n            title([method, ': 变量组合出现频率'], 'FontSize', 12, 'FontWeight', 'bold');\n            ylabel('频率', 'FontSize', 10);\n            grid on;\n            \n            % 创建子图2：组合AUC和F1分数\n            subplot(2, 2, 2);\n            metrics_2 = [combo_aucs, combo_f1];\n            h2 = bar(metrics_2);\n            set(h2(1), 'FaceColor', [0.9 0.4 0.3]);\n            set(h2(2), 'FaceColor', [0.3 0.8 0.8]);\n            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45, 'FontSize', 9);\n            title([method, ': 变量组合AUC和F1值'], 'FontSize', 12, 'FontWeight', 'bold');\n            ylabel('值', 'FontSize', 10);\n            legend({'AUC', 'F1分数'}, 'Location', 'southwest', 'FontSize', 8);\n            grid on;\n            \n            % 创建子图3：准确率、敏感性和特异性\n            subplot(2, 2, 3);\n            metrics_3 = [combo_acc, combo_sens, combo_spec];\n            h3 = bar(metrics_3);\n            set(h3(1), 'FaceColor', [0.3 0.8 0.3]);\n            set(h3(2), 'FaceColor', [0.9 0.6 0.1]);\n            set(h3(3), 'FaceColor', [0.5 0.5 0.8]);\n            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45, 'FontSize', 9);\n            title([method, ': 组合性能指标1'], 'FontSize', 12, 'FontWeight', 'bold');\n            ylabel('值', 'FontSize', 10);\n            legend({'准确率', '敏感性', '特异性'}, 'Location', 'southeast', 'FontSize', 8);\n            grid on;\n            \n            % 创建子图4：精确率（新增）\n            subplot(2, 2, 4);\n            bar(combo_prec, 'FaceColor', [0.6 0.3 0.8]);\n            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45, 'FontSize', 9);\n            title([method, ': 变量组合精确率'], 'FontSize', 12, 'FontWeight', 'bold');\n            ylabel('精确率', 'FontSize', 10);\n            grid on;\n            \n            % 调整整体间距\n            set(gcf, 'Color', 'white');\n            set(fig1, 'Position', [100, 100, 1200, 800]);\n            \n            % 保存矢量图 - 注意这里传入方法名\n            save_figure(fig1, figure_dir, '%s_variable_combinations', 'MethodName', method, 'Formats', {'svg'});\n            close(fig1);\n            \n            % 创建组合详情图\n            fig2 = figure('Name', sprintf('%s Combination Details', method), 'Position', [100, 100, 1200, 800]);\n            \n            % 创建矩阵显示每个组合包含哪些变量\n            combo_matrix = zeros(top_n, length(var_names));\n            \n            for j = 1:top_n\n                combo = group_perf(j);\n                for k = 1:length(combo.variables)\n                    var_name = combo.variables{k};\n                    var_idx = find(strcmp(var_names, var_name));\n                    if ~isempty(var_idx)\n                        combo_matrix(j, var_idx) = 1;\n                    end\n                end\n            end\n            \n            % 绘制热图\n            h = heatmap(combo_matrix, 'XDisplayLabels', var_names, 'YDisplayLabels', combo_labels);\n            \n            % 自定义颜色映射\n            colormap([1 1 1; 0.2 0.6 0.8]); % 白色和蓝色\n            \n            % 设置标题和标签\n            h.Title = sprintf('%s: 前%d个组合的变量构成', method, top_n);\n            h.XLabel = '变量';\n            h.YLabel = '组合';\n            h.FontSize = 10;\n            \n            % 保存矢量图 - 注意这里传入方法名\n            save_figure(fig2, figure_dir, '%s_combination_details', 'MethodName', method, 'Formats', {'svg'});\n            close(fig2);\n        else\n            log_message('info', sprintf('%s方法的变量组合少于3个，跳过可视化', method));\n        end\n    end\n\n    % 修复创建所有方法的综合比较图部分\n    try\n        % 从所有方法中收集组合信息\n        all_combos = struct('method', {}, 'vars', {}, 'auc', {}, 'f1', {}, 'count', {});\n        for i = 1:length(methods)\n            method = methods{i};\n            group_perf = results.(method).group_performance;\n            \n            for j = 1:min(3, length(group_perf))  % 每个方法取前3个\n                if group_perf(j).count >= 5 % 只考虑出现至少5次的组合\n                    combo = group_perf(j);\n                    var_str = strjoin(cellfun(@(x) x, combo.variables, 'UniformOutput', false), ', ');\n                    new_combo = struct('method', method, 'vars', var_str, 'auc', combo.auc, 'f1', combo.f1_score, 'count', combo.count);\n                    all_combos(end+1) = new_combo;\n                end\n            end\n        end\n        \n        % 如果有足够的组合，创建比较图\n        if length(all_combos) >= 3\n            fig3 = figure('Name', 'Top Combinations Across Methods', 'Position', [100, 100, 1000, 600]);\n            \n            % 提取数据\n            methods_list = {all_combos.method};\n            aucs = [all_combos.auc];\n            f1s = [all_combos.f1];\n            counts = [all_combos.count];\n            vars_list = {all_combos.vars};\n            \n            % 创建气泡图（使用F1分数作为Y轴）\n            scatter(1:length(all_combos), f1s, counts*10, aucs*50, 'filled', 'MarkerFaceAlpha', 0.7);\n            colormap(jet);\n            colorbar;\n            \n            % 添加方法标签\n            text(1:length(all_combos), f1s, methods_list, 'VerticalAlignment', 'bottom', 'HorizontalAlignment', 'center');\n            \n            % 设置图形属性\n            set(gca, 'XTick', 1:length(all_combos));\n            set(gca, 'XTickLabel', vars_list, 'XTickLabelRotation', 45, 'FontSize', 9);\n            xlabel('变量组合', 'FontSize', 12);\n            ylabel('F1分数', 'FontSize', 12);\n            title('各方法中顶级变量组合的性能比较', 'FontSize', 14, 'FontWeight', 'bold');\n            grid on;\n            \n            % 添加说明\n            text(length(all_combos)/2, min(f1s)-0.1, '注: 气泡大小表示组合出现频率，颜色表示AUC值', ...\n                'HorizontalAlignment', 'center', 'FontSize', 10);\n            \n            % 保存矢量图\n            save_figure(fig3, figure_dir, 'top_combinations_comparison', 'Formats', {'svg'});\n            close(fig3);\n        end\n    catch ME\n        log_message('warning', sprintf('创建综合比较图时出错: %s', ME.message));\n    end\nend\n\n%% 图形保存函数\nfunction save_figure(fig, output_dir, filename_base, varargin)\n% 统一的图形保存函数，支持多种格式和高级选项\n% 输入:\n%   fig - 图形句柄\n%   output_dir - 输出目录\n%   filename_base - 基本文件名（可包含%s，将被method_name替换）\n% 可选命名参数:\n%   'Formats' - 要保存的格式列表，默认为 {'png', 'pdf'}\n%   'DPI' - 分辨率，默认为300\n%   'MethodName' - 方法名称，用于替换文件名中的%s\n%   'BestFit' - 是否使用最佳适配选项，默认为true\n\n    % 解析输入参数\n    p = inputParser;\n    addParameter(p, 'Formats', {'svg'}, @(x) iscell(x) || ischar(x));\n    addParameter(p, 'DPI', 300, @isnumeric);\n    addParameter(p, 'MethodName', '', @ischar);\n    addParameter(p, 'BestFit', true, @islogical);\n    parse(p, varargin{:});\n    \n    formats = p.Results.Formats;\n    dpi = p.Results.DPI;\n    method_name = p.Results.MethodName;\n    use_bestfit = p.Results.BestFit;\n    \n    % 如果formats是字符串，转换为cell数组\n    if ischar(formats)\n        formats = {formats};\n    end\n    \n    % 确保输出目录存在\n    if ~exist(output_dir, 'dir')\n        mkdir(output_dir);\n    end\n    \n    % 处理文件名中的方法名称替换\n    if contains(filename_base, '%s')\n        if ~isempty(method_name)\n            actual_filename = strrep(filename_base, '%s', method_name);\n        else\n            actual_filename = strrep(filename_base, '%s', 'unknown');\n            log_message('warning', '文件名中包含%s但未提供method_name');\n        end\n    else\n        actual_filename = filename_base;\n    end\n    \n    % 准备图形\n    set(fig, 'Color', 'white');\n    \n    % 优化图例和文本位置\n    ax = findall(fig, 'Type', 'Axes');\n    for i = 1:length(ax)\n        % 获取图例对象\n        leg = findobj(ax(i), 'Type', 'Legend');\n        if ~isempty(leg)\n            % 确保图例处于最佳位置\n            leg.FontSize = max(leg.FontSize, 9);\n        end\n        \n        % 确保轴标签清晰可见\n        ax(i).FontSize = max(ax(i).FontSize, 9); % 确保字体足够大\n    end\n    \n    % 设置纸张属性\n    set(fig, 'PaperPositionMode', 'manual');\n    set(fig, 'PaperUnits', 'inches');\n    set(fig, 'PaperSize', [10 8]); % 设置为 10x8 英寸\n    set(fig, 'PaperPosition', [0 0 10 8]);\n    \n    % 初始化成功保存的格式列表\n    successful_formats = {};\n    \n    % 保存每种格式\n    for i = 1:length(formats)\n        format = lower(formats{i});\n        filename = fullfile(output_dir, [actual_filename '.' format]);\n        \n        try\n            % 根据不同的格式选择不同的保存方法\n            switch format\n                case {'png', 'jpg', 'jpeg', 'tiff', 'bmp'}\n                    % 位图格式\n                    print(fig, filename, ['-d' format], ['-r' num2str(dpi)]);\n                    \n                case 'pdf'\n                    % PDF格式\n                    if use_bestfit\n                        print(fig, filename, '-dpdf', '-bestfit');\n                    else\n                        print(fig, filename, '-dpdf');\n                    end\n                    \n                case 'eps'\n                    % EPS格式\n                    print(fig, filename, '-depsc2');\n                    \n                case 'svg'\n                    % SVG格式\n                    print(fig, filename, '-dsvg');\n                    \n                otherwise\n                    % 其他格式\n                    saveas(fig, filename);\n            end\n            \n            successful_formats{end+1} = upper(format);\n            \n        catch ME\n            % 保存失败，记录错误并尝试备用方法\n            log_message('debug', ['保存' upper(format) '格式时出错: ' ME.message]);\n            \n            % 尝试备用方法\n            try\n                % 备用保存方法\n                saveas(fig, filename);\n                successful_formats{end+1} = upper(format);\n            catch ME2\n                log_message('warning', ['备用保存方法也失败: ' ME2.message]);\n            end\n        end\n    end\n    \n    % 输出汇总日志消息\n    if ~isempty(successful_formats)\n        % 获取没有路径的文件名基础部分\n        [~, file_basename, ~] = fileparts(actual_filename);\n        \n        % 格式化成功保存的格式列表\n        formats_str = strjoin(successful_formats, ', ');\n        \n        % 如果是调试级别，只记录一条简短的日志\n        log_level = get_log_level();\n        if strcmpi(log_level, 'debug')\n            log_message('debug', sprintf('保存图形: %s (%s)', file_basename, formats_str));\n        else\n            % 对于其他级别，只记录一条简短的信息日志\n            log_message('info', sprintf('图形已保存: %s (%s)', file_basename, formats_str));\n        end\n    else\n        % 如果没有任何格式保存成功\n        log_message('error', ['图形保存失败: ' actual_filename]);\n    end\nend\n\n% 辅助函数\nfunction save_vector_graphic(fig, output_dir, filename_base)\n% 保存矢量图（向后兼容）\n% 输入:\n%   fig - 图形句柄\n%   output_dir - 输出目录\n%   filename_base - 基本文件名\n\n    % 调用统一的保存函数，指定矢量格式\n    save_figure(fig, output_dir, filename_base, 'Formats', {'svg'});\nend\n\n%% 创建增强综合报告 - 新增\nfunction create_enhanced_summary_report(results, methods, var_names, cv_results, coef_stability, param_stats, var_contribution, report_dir)\n% 创建增强综合比较报告，包含K折验证、系数稳定性和变量贡献分析\n% 输入:\n%   results - 结果结构\n%   methods - 方法名称\n%   var_names - 变量名称\n%   cv_results - 交叉验证结果\n%   coef_stability - 系数稳定性\n%   param_stats - 参数统计\n%   var_contribution - 变量贡献\n%   report_dir - 报告保存目录\n\n% 添加时间戳\ntimestamp = datestr(now, 'yyyy-mm-dd HH:MM:SS');\n\n% 打开文件\nfile_path = fullfile(report_dir, 'enhanced_summary_report.txt');\nfid = fopen(file_path, 'w');\n\n% 写入标题\nfprintf(fid, '二元逻辑回归分析增强综合报告\\n');\nfprintf(fid, '==============================\\n');\nfprintf(fid, '生成时间: %s\\n', timestamp);\nfprintf(fid, '系统配置: MacBook Pro 2019, i9-9980HK, 64GB RAM, 8GB 5500M\\n\\n');\n\n% 1. 交叉验证结果\nfprintf(fid, '1. K折交叉验证结果\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfprintf(fid, '使用%d折交叉验证评估模型稳定性和泛化能力:\\n\\n', length(cv_results.accuracy));\n\nfprintf(fid, '平均性能指标：\\n');\nfprintf(fid, '  - 准确率: %.3f ± %.3f\\n', cv_results.avg_accuracy, cv_results.std_accuracy);\nfprintf(fid, '  - 精确率: %.3f ± %.3f\\n', cv_results.avg_precision, cv_results.std_precision);\nfprintf(fid, '  - 召回率: %.3f ± %.3f\\n', cv_results.avg_recall, cv_results.std_recall);\nfprintf(fid, '  - 特异性: %.3f ± %.3f\\n', cv_results.avg_specificity, cv_results.std_specificity);\nfprintf(fid, '  - F1分数: %.3f ± %.3f\\n', cv_results.avg_f1_score, cv_results.std_f1_score);\nfprintf(fid, '  - AUC: %.3f ± %.3f\\n\\n', cv_results.avg_auc, cv_results.std_auc);\n\n% 系数稳定性分析\nfprintf(fid, '系数稳定性分析：\\n');\ncoef_means = cv_results.coef_mean;\ncoef_stds = cv_results.coef_std;\ncoef_cvs = cv_results.coef_cv;\n\n% 输出截距\nfprintf(fid, '  - 截距: %.4f ± %.4f (CV = %.3f)\\n', coef_means(1), coef_stds(1), coef_cvs(1));\n\n% 找出CV较大的系数（不稳定）\nunstable_idx = find(coef_cvs > 0.5);\nif ~isempty(unstable_idx)\n    fprintf(fid, '  - 检测到不稳定系数 (CV > 0.5):\\n');\n    for i = 1:length(unstable_idx)\n        if unstable_idx(i) > 1 % 跳过截距\n            var_idx = unstable_idx(i) - 1;\n            if var_idx <= length(var_names)\n                fprintf(fid, '    * %s: %.4f ± %.4f (CV = %.3f)\\n', ...\n                    var_names{var_idx}, coef_means(unstable_idx(i)), coef_stds(unstable_idx(i)), coef_cvs(unstable_idx(i)));\n            end\n        end\n    end\nelse\n    fprintf(fid, '  - 所有系数均表现稳定 (CV <= 0.5)\\n');\nend\nfprintf(fid, '\\n');\n\n% 2. 变量选择结果\nfprintf(fid, '2. 变量选择结果\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfor i = 1:length(methods)\n    method = methods{i};\n    selected = find(results.(method).selected_vars);\n    selected_names = var_names(selected);\n    \n    fprintf(fid, '%s方法选择的变量：\\n', method);\n    for j = 1:length(selected_names)\n        fprintf(fid, '  - %s (频率: %.2f)\\n', selected_names{j}, results.(method).var_freq(selected(j)));\n    end\n    fprintf(fid, '\\n');\nend\n\n% 3. 变量组合分析\nfprintf(fid, '3. 变量组合分析\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfor i = 1:length(methods)\n    method = methods{i};\n    group_perf = results.(method).group_performance;\n    \n    fprintf(fid, '%s方法发现的变量组合（前5个）：\\n', method);\n    \n    % 显示前5个最常见的组合\n    top_n = min(5, length(group_perf));\n    for j = 1:top_n\n        combo = group_perf(j);\n        var_str = strjoin(cellfun(@(x) x, combo.variables, 'UniformOutput', false), ', ');\n        fprintf(fid, '  组合 #%d (出现%d次):\\n', j, combo.count);\n        fprintf(fid, '    变量: %s\\n', var_str);\n        fprintf(fid, '    性能: 准确率=%.3f, 精确率=%.3f, 召回率=%.3f, 特异性=%.3f, F1=%.3f, AUC=%.3f\\n', ...\n            combo.accuracy, combo.precision, combo.sensitivity, combo.specificity, combo.f1_score, combo.auc);\n    end\n    fprintf(fid, '\\n');\nend\n\n% 4. 模型性能比较\nfprintf(fid, '4. 模型性能比较\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfprintf(fid, '方法\\t\\t准确率\\t精确率\\t召回率\\t特异性\\tF1分数\\tAUC\\n');\nfprintf(fid, '------------------------------------------------------------------------\\n');\nfor i = 1:length(methods)\n    method = methods{i};\n    perf = results.(method).performance;\n    fprintf(fid, '%-12s\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\n', ...\n        method, perf.avg_accuracy, perf.avg_precision, perf.avg_sensitivity, ...\n        perf.avg_specificity, perf.avg_f1_score, perf.avg_auc);\nend\nfprintf(fid, '\\n');\n\n% 5. 参数统计分析\nfprintf(fid, '5. 参数统计分析\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    % 只针对回归类方法\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        if isfield(param_stats, method) && isfield(param_stats.(method), 'table')\n            table_data = param_stats.(method).table;\n            \n            fprintf(fid, '%s方法的参数统计 (基于%d个模型):\\n\\n', method, param_stats.(method).n_samples);\n            fprintf(fid, 'Variable\\t\\tEstimate\\t95%% CI\\t\\t\\tp-value\\tSignificance\\n');\n            fprintf(fid, '------------------------------------------------------------------------\\n');\n            \n            for j = 1:height(table_data)\n                % 动态查找置信区间列名\n                column_names = table_data.Properties.VariableNames;\n                ci_lower_col = '';\n                ci_upper_col = '';\n                \n                % 查找包含'lower'和'upper'的列名（优先使用t分布CI）\n                for col_idx = 1:length(column_names)\n                    col_name = lower(column_names{col_idx});\n                    if contains(col_name, 'lower') && contains(col_name, 't')\n                        ci_lower_col = column_names{col_idx};\n                    elseif contains(col_name, 'upper') && contains(col_name, 't')\n                        ci_upper_col = column_names{col_idx};\n                    end\n                end\n                \n                % 如果未找到t分布CI，尝试BCa\n                if isempty(ci_lower_col) || isempty(ci_upper_col)\n                    for col_idx = 1:length(column_names)\n                        col_name = lower(column_names{col_idx});\n                        if contains(col_name, 'lower') && contains(col_name, 'bca')\n                            ci_lower_col = column_names{col_idx};\n                        elseif contains(col_name, 'upper') && contains(col_name, 'bca')\n                            ci_upper_col = column_names{col_idx};\n                        end\n                    end\n                end\n                \n                % 输出表格行\n                if isempty(ci_lower_col) || isempty(ci_upper_col)\n                    fprintf(fid, '%-15s\\t%.4f\\t[N/A, N/A]\\t%.4f\\t%s\\n', ...\n                        table_data.Variable{j}, table_data.Estimate(j), ...\n                        table_data.p_value(j), table_data.Significance{j});\n                    log_message('warning', sprintf('%s方法的参数统计表中缺少置信区间列', method));\n                else\n                    fprintf(fid, '%-15s\\t%.4f\\t[%.4f, %.4f]\\t%.4f\\t%s\\n', ...\n                        table_data.Variable{j}, table_data.Estimate(j), ...\n                        table_data.(ci_lower_col)(j), table_data.(ci_upper_col)(j), ...\n                        table_data.p_value(j), table_data.Significance{j});\n                end\n            end\n            fprintf(fid, '\\n');\n            \n            % 输出显著参数\n            sig_idx = find(table_data.p_value < 0.05);\n            if ~isempty(sig_idx)\n                fprintf(fid, '统计显著变量 (p < 0.05):\\n');\n                for j = 1:length(sig_idx)\n                    if ~isempty(ci_lower_col) && ~isempty(ci_upper_col)\n                        fprintf(fid, '  - %s: 估计值=%.4f, 95%%CI=[%.4f, %.4f], p=%.4f %s\\n', ...\n                            table_data.Variable{sig_idx(j)}, table_data.Estimate(sig_idx(j)), ...\n                            table_data.(ci_lower_col)(sig_idx(j)), table_data.(ci_upper_col)(sig_idx(j)), ...\n                            table_data.p_value(sig_idx(j)), table_data.Significance{sig_idx(j)});\n                    else\n                        fprintf(fid, '  - %s: 估计值=%.4f, p=%.4f %s\\n', ...\n                            table_data.Variable{sig_idx(j)}, table_data.Estimate(sig_idx(j)), ...\n                            table_data.p_value(sig_idx(j)), table_data.Significance{sig_idx(j)});\n                    end\n                end\n            else\n                fprintf(fid, '没有发现统计显著变量 (p < 0.05)\\n');\n            end\n            fprintf(fid, '\\n');\n        else\n            fprintf(fid, '%s方法没有可用的参数统计信息\\n\\n', method);\n        end\n    else\n        fprintf(fid, '%s方法不适用于传统参数统计分析\\n\\n', method);\n    end\nend\n\n% 6. 变量贡献分析\nfprintf(fid, '6. 变量贡献分析\\n');\nfprintf(fid, '----------------------\\n\\n');\n\n% 6.1 全局变量重要性\nif isfield(var_contribution, 'overall_importance')\n    fprintf(fid, '综合变量重要性排名:\\n');\n    \n    importance_table = var_contribution.overall_importance;\n    top_n = min(10, height(importance_table));\n    \n    for i = 1:top_n\n        fprintf(fid, '  %d. %s (重要性: %.2f%%)\\n', i, importance_table.Variable{i}, importance_table.Normalized_Importance(i));\n    end\n    fprintf(fid, '\\n');\nend\n\n% 6.2 相关性分析\nif isfield(var_contribution, 'correlation')\n    fprintf(fid, '变量相关性分析:\\n');\n    \n    corr_table = var_contribution.correlation;\n    [~, idx] = sort(abs(corr_table.PartialCorr), 'descend');\n    sorted_corr = corr_table(idx,:);\n    top_n = min(5, height(sorted_corr));\n    \n    fprintf(fid, '变量\\t\\t相关系数\\t偏相关系数\\tp值\\n');\n    fprintf(fid, '--------------------------------------------------------\\n');\n    for i = 1:top_n\n        fprintf(fid, '%-15s\\t%.3f\\t\\t%.3f\\t\\t%.4f\\n', ...\n            sorted_corr.Variable{i}, sorted_corr.Correlation(i), ...\n            sorted_corr.PartialCorr(i), sorted_corr.Partial_pvalue(i));\n    end\n    fprintf(fid, '\\n');\nend\n\n% 6.3 各方法变量贡献\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    if isfield(var_contribution, 'methods') && isfield(var_contribution.methods, method) && ...\n       isfield(var_contribution.methods.(method), 'contribution_table')\n    \n        contrib_table = var_contribution.methods.(method).contribution_table;\n        fprintf(fid, '%s方法的变量贡献分析:\\n', method);\n        \n        if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n            fprintf(fid, '变量\\t\\t\\t系数\\t\\tp值\\t\\t相对贡献\\t方向\\n');\n            fprintf(fid, '--------------------------------------------------------\\n');\n            \n            top_n = min(5, height(contrib_table));\n            for j = 1:top_n\n                fprintf(fid, '%-20s\\t%.4f\\t\\t%.4f\\t\\t%.2f%%\\t\\t%s\\n', ...\n                    contrib_table.Variable{j}, contrib_table.Coefficient(j), ...\n                    contrib_table.p_value(j), contrib_table.Relative_Contribution(j), ...\n                    contrib_table.Effect_Direction{j});\n            end\n        else\n            fprintf(fid, '变量\\t\\t\\t重要性\\t\\t相对贡献\\n');\n            fprintf(fid, '--------------------------------------------------------\\n');\n            \n            top_n = min(5, height(contrib_table));\n            for j = 1:top_n\n                fprintf(fid, '%-20s\\t%.4f\\t\\t%.2f%%\\n', ...\n                    contrib_table.Variable{j}, contrib_table.Importance(j), ...\n                    contrib_table.Relative_Contribution(j));\n            end\n        end\n        fprintf(fid, '\\n');\n    end\nend\n\n% 7. 最佳变量组合性能 \nfprintf(fid, '7. 最佳变量组合性能\\n');\nfprintf(fid, '----------------------\\n\\n');\n\n% 找出所有方法中性能最好的组合（基于F1分数）\nbest_combo = struct('method', '', 'f1', 0, 'auc', 0, 'count', 0, 'variables', {{}}, ...\n    'accuracy', 0, 'precision', 0, 'sensitivity', 0, 'specificity', 0);\nfound_valid_combo = false;\n\nfor i = 1:length(methods)\n    method = methods{i};\n    group_perf = results.(method).group_performance;\n    \n    for j = 1:length(group_perf)\n        combo = group_perf(j);\n        % 只考虑出现频率较高的组合（至少5次）\n        if combo.count >= 5 && combo.f1_score > best_combo.f1\n            best_combo.method = method;\n            best_combo.f1 = combo.f1_score;\n            best_combo.auc = combo.auc;\n            best_combo.count = combo.count;\n            best_combo.variables = combo.variables;\n            best_combo.accuracy = combo.accuracy;\n            best_combo.precision = combo.precision;\n            best_combo.sensitivity = combo.sensitivity;\n            best_combo.specificity = combo.specificity;\n            found_valid_combo = true;\n        end\n    end\nend\n\nfprintf(fid, '所有方法中性能最佳的变量组合（基于F1分数）：\\n');\nif found_valid_combo\n    fprintf(fid, '  方法: %s\\n', best_combo.method);\n    fprintf(fid, '  出现次数: %d\\n', best_combo.count);\n    fprintf(fid, '  F1分数: %.3f\\n', best_combo.f1);\n    fprintf(fid, '  AUC: %.3f\\n', best_combo.auc);\n    fprintf(fid, '  准确率: %.3f\\n', best_combo.accuracy);\n    fprintf(fid, '  精确率: %.3f\\n', best_combo.precision);\n    fprintf(fid, '  召回率/敏感性: %.3f\\n', best_combo.sensitivity);\n    fprintf(fid, '  特异性: %.3f\\n', best_combo.specificity);\n    fprintf(fid, '  变量: %s\\n\\n', strjoin(best_combo.variables, ', '));\nelse\n    fprintf(fid, '  未找到出现频率达到5次以上的变量组合\\n\\n');\nend\n\n% 8. 系数稳定性分析\nfprintf(fid, '8. 系数稳定性分析\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfor i = 1:length(methods)\n    method = methods{i};\n    \n    % 只针对回归类方法\n    if any(strcmpi(method, {'stepwise', 'lasso', 'ridge', 'elasticnet'}))\n        if isfield(coef_stability, method) && isfield(coef_stability.(method), 'table')\n            table_data = coef_stability.(method).table;\n            \n            fprintf(fid, '%s方法的系数稳定性分析:\\n\\n', method);\n            fprintf(fid, 'Variable\\t\\tMean\\t\\tStdDev\\t\\tCV\\n');\n            fprintf(fid, '--------------------------------------------------------\\n');\n            \n            for j = 1:height(table_data)\n                fprintf(fid, '%-15s\\t%.4f\\t\\t%.4f\\t\\t%.3f\\n', ...\n                    table_data.Variable{j}, table_data.Mean(j), ...\n                    table_data.StdDev(j), table_data.CV(j));\n            end\n            fprintf(fid, '\\n');\n            \n            % 输出不稳定的系数\n            unstable_idx = find(table_data.CV > 0.5);\n            if ~isempty(unstable_idx)\n                fprintf(fid, '不稳定系数 (CV > 0.5):\\n');\n                for j = 1:length(unstable_idx)\n                    fprintf(fid, '  - %s: CV=%.3f\\n', ...\n                        table_data.Variable{unstable_idx(j)}, table_data.CV(unstable_idx(j)));\n                end\n            else\n                fprintf(fid, '所有系数均表现稳定 (CV <= 0.5)\\n');\n            end\n            fprintf(fid, '\\n');\n        else\n            fprintf(fid, '%s方法没有可用的系数稳定性信息\\n\\n', method);\n        end\n    else\n        fprintf(fid, '%s方法不适用于传统系数稳定性分析\\n\\n', method);\n    end\nend\n\n% 9. 变量重要性\nfprintf(fid, '9. 变量重要性（平均选择频率）\\n');\nfprintf(fid, '----------------------\\n\\n');\n\n% 计算每个变量的平均频率\nvar_freq = zeros(length(var_names), 1);\nfor i = 1:length(methods)\n    method = methods{i};\n    var_freq = var_freq + results.(method).var_freq;\nend\nvar_freq = var_freq / length(methods);\n\n% 排序并输出\n[sorted_freq, idx] = sort(var_freq, 'descend');\nsorted_names = var_names(idx);\n\nfor i = 1:length(sorted_names)\n    fprintf(fid, '%-15s\\t%.3f\\n', sorted_names{i}, sorted_freq(i));\nend\nfprintf(fid, '\\n');\n\n% 10. 并行性能统计\nfprintf(fid, '10. 并行计算性能\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfprintf(fid, '并行池配置:\\n');\nfprintf(fid, '  - CPU: Intel i9-9980HK (8核16线程)\\n');\nfprintf(fid, '  - Worker数量: 8个\\n');\nfprintf(fid, '  - 每个Worker线程数: 2\\n');\nfprintf(fid, '  - 总并行线程: 16\\n');\nfprintf(fid, '  - 保留线程: 0 (系统和主进程)\\n\\n');\n\n% 11. 结论和推荐\nfprintf(fid, '11. 结论和推荐\\n');\nfprintf(fid, '----------------------\\n\\n');\n\n% 找出性能最好的方法（基于F1分数）\nf1_values = zeros(length(methods), 1);\nfor i = 1:length(methods)\n    f1_values(i) = results.(methods{i}).performance.avg_f1_score;\nend\n\nif all(isnan(f1_values))\n    fprintf(fid, '所有方法的F1值都是NaN，无法确定最佳方法。\\n\\n');\nelse\n    [max_f1, best_idx] = max(f1_values);\n    best_method = methods{best_idx};\n    fprintf(fid, '根据F1分数指标，%s方法表现最好，平均F1分数为%.3f。\\n\\n', best_method, max_f1);\nend\n\n% 推荐变量组合\nfprintf(fid, '推荐变量组合：\\n');\nif found_valid_combo\n    fprintf(fid, '  %s\\n', strjoin(best_combo.variables, ', '));\n    fprintf(fid, '  (来自%s方法，F1=%.3f, AUC=%.3f)\\n\\n', best_combo.method, best_combo.f1, best_combo.auc);\nelse\n    fprintf(fid, '  未找到出现频率达到5次以上的变量组合\\n\\n');\nend\n\n% 12. 模型稳定性评价\nfprintf(fid, '12. 模型稳定性评价\\n');\nfprintf(fid, '----------------------\\n\\n');\n\n% 评估K折交叉验证性能的变异系数\ncv_metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\ncv_metric_names = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\ncv_values = zeros(length(cv_metrics), 1);\n\nfor i = 1:length(cv_metrics)\n    metric = cv_metrics{i};\n    mean_val = mean(cv_results.(metric), 'omitnan');\n    std_val = std(cv_results.(metric), 'omitnan');\n    % 计算变异系数\n    if mean_val > 0\n        cv_values(i) = std_val / mean_val;\n    else\n        cv_values(i) = NaN;\n    end\nend\n\nfprintf(fid, 'K折交叉验证各指标变异系数 (CV):\\n');\nfor i = 1:length(cv_metrics)\n    fprintf(fid, '  - %s: CV = %.3f\\n', cv_metric_names{i}, cv_values(i));\nend\n\n% 评估模型稳定性\nmean_cv = mean(cv_values, 'omitnan');\nif mean_cv < 0.1\n    stability_rating = '优秀';\nelseif mean_cv < 0.2\n    stability_rating = '良好';\nelseif mean_cv < 0.3\n    stability_rating = '一般';\nelse\n    stability_rating = '较差';\nend\n\nfprintf(fid, '\\n总体模型稳定性评价: %s (平均CV = %.3f)\\n', stability_rating, mean_cv);\n\n% 变量选择稳定性\nbest_method_freq = results.(best_method).var_freq;\nhigh_freq_vars = best_method_freq > 0.5;\nlow_freq_vars = best_method_freq < 0.2 & best_method_freq > 0;\n\nfprintf(fid, '\\n变量选择稳定性 (在%s方法中):\\n', best_method);\nfprintf(fid, '  - 高稳定性变量 (频率 > 0.5): %d个\\n', sum(high_freq_vars));\nfprintf(fid, '  - 低稳定性变量 (频率 < 0.2): %d个\\n', sum(low_freq_vars));\n\nif sum(high_freq_vars) > 0\n    fprintf(fid, '\\n高稳定性变量名称:\\n');\n    high_vars = var_names(high_freq_vars);\n    for i = 1:length(high_vars)\n        selected_freq = best_method_freq(high_freq_vars);\n        for i = 1:length(high_vars)\n            fprintf(fid, '  - %s (频率: %.2f)\\n', high_vars{i}, selected_freq(i));\n        end\n    end\nend\nfprintf(fid, '\\n');\n\n% 13. 总结\nfprintf(fid, '13. 总结\\n');\nfprintf(fid, '----------------------\\n\\n');\n\nfprintf(fid, '本分析在MacBook Pro 2019上运行，充分利用了i9-9980HK的多核性能\\n');\nfprintf(fid, '和64GB大内存优势。优化的并行配置、智能的GPU利用和高效的内存管理\\n');\nfprintf(fid, '确保了5种变量选择方法在多次重复实验中的高效执行。\\n\\n');\n\nfprintf(fid, '本研究扩展了原有分析框架，增加了以下关键功能：\\n');\nfprintf(fid, '1. 结合K折交叉验证与Bootstrap方法，全面评估模型稳定性\\n');\nfprintf(fid, '2. 监控多种评估指标（准确率、精确率、召回率、F1分数、AUC等）\\n');\nfprintf(fid, '3. 分析了模型系数的稳定性，并计算了参数置信区间和p值\\n');\nfprintf(fid, '4. 通过多种方法评估了变量对模型的贡献\\n\\n');\n\nif found_valid_combo\n    fprintf(fid, '分析结果表明，%s方法选择的变量组合在预测性能上表现最优，\\n', best_combo.method);\n    fprintf(fid, '可作为后续模型构建的基础。推荐变量组合：%s\\n\\n', strjoin(best_combo.variables, ', '));\nelse\n    fprintf(fid, '本次分析虽未找到普遍稳定的变量组合，但各方法的变量选择频率\\n');\n    fprintf(fid, '为后续变量筛选提供了重要参考。建议结合领域知识进行进一步筛选。\\n\\n');\nend\n\nfprintf(fid, '所有详细结果已保存至results文件夹，包括详细的CSV表格和可视化图形。\\n\\n');\n\nfprintf(fid, '分析完成时间: %s\\n', timestamp);\n\n% 关闭文件\nfclose(fid);\nend\n",
              "is_citable": true,
              "prompt_context_metadata": {
                "content_type": "html"
              }
            }
          ],
          "is_error": false,
          "message": "Fetched: https://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m",
          "integration_icon_url": "https://www.google.com/s2/favicons?sz=64&domain=github.com",
          "display_content": {
            "type": "rich_link",
            "link": {
              "title": "https://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m",
              "url": "https://github.com/La-Petite-Princess/Binomial/raw/refs/heads/main/Binomial.m",
              "icon_url": "https://www.google.com/s2/favicons?sz=64&domain=github.com",
              "source": "github"
            },
            "is_trusted": false
          }
        },
        {
          "start_timestamp": "2025-05-08T09:06:37.453385+00:00",
          "stop_timestamp": "2025-05-08T09:06:39.519189+00:00",
          "type": "text",
          "text": "\n\n现在我已经获取了完整的MATLAB代码。基于您提到的13项优化要求，我将开始对代码进行全面优化。由于代码量很大，我将分成几个部分来发送优化后的代码，以便您查看和理解。\n\n## 第一部分：代码结构优化和配置管理\n\n我将先进行模块化设计，将关键参数提取到配置文件中，并创建面向对象编程结构：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:06:39.753416+00:00",
          "stop_timestamp": "2025-05-08T09:07:06.436260+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-config",
            "type": "application/vnd.ant.code",
            "title": "配置文件模块 - BinomialConfig.m",
            "command": "create",
            "content": "classdef BinomialConfig < handle\n    % 配置管理类：集中管理所有可调整的参数\n    % 使用 handle 类确保配置在整个程序中保持一致\n    \n    properties (Access = public)\n        % 数据预处理参数\n        ExcludeRows = [6, 10, 42, 74, 124, 127, 189, 252, 285, 298, 326, 331, 339]\n        ReverseItems = [12, 19, 23]\n        MaxScore = 5\n        TargetColumn = 29\n        ValidRows = []\n        \n        % 变量准备参数\n        VariableGroups = {\n            [1, 2, 3, 4, 5, 6, 12, 19, 23],  % 组1\n            [7, 8, 9],                       % 组2\n            [10, 11],                        % 组3\n            [13, 14],                        % 组4\n            [15, 17, 18, 20, 21],            % 组5\n            [22, 24],                        % 组6\n            [25, 26],                        % 组7\n            [27, 28]                         % 组8\n        }\n        \n        % 多重共线性检查参数\n        VifThreshold = 10\n        ConditionNumberThreshold = 30\n        PcaVarianceThreshold = 95\n        \n        % Bootstrap参数\n        TrainRatio = 0.8\n        NumBootstrapSamples = 100\n        \n        % K折交叉验证参数\n        KFolds = 10\n        \n        % 变量选择参数\n        VariableSelectionMethods = {'stepwise', 'lasso', 'ridge', 'elasticnet', 'randomforest'}\n        StepwisePEnter = 0.15\n        StepwisePRemove = 0.20\n        LassoCrossValidationFolds = 10\n        LassoAlpha = 1\n        RidgeAlpha = 0.001\n        ElasticNetAlpha = 0.5\n        RandomForestNumTrees = 200\n        \n        % 模型评估参数\n        SignificanceLevel = 0.05\n        CoefficientStabilityThreshold = 0.5\n        MinimumModelsForAnalysis = 5\n        \n        % 并行计算参数\n        UseParallelComputing = true\n        NumWorkers = []  % 自动设置\n        NumThreadsPerWorker = 2\n        ParallelClusterJobStorageLocation = '/tmp'\n        \n        % GPU设置\n        UseGpu = true\n        GpuMemoryLimit = 0.6  % 使用总GPU内存的60%\n        GpuMinDataSizeThreshold = 5 * 1024 * 1024  % 5MB\n        \n        % 可视化参数\n        FigureHeight = 600\n        FigureWidth = 900\n        ExportFormats = {'svg', 'png'}\n        ExportDpi = 300\n        \n        % 日志参数\n        LogLevel = 'info'\n        LogToFile = true\n        LogDirectory = 'results'\n        \n        % 输出参数\n        OutputDirectory = 'results'\n        SaveIntermediateResults = true\n        \n        % 系统信息\n        SystemInfo = struct()\n    end\n    \n    methods (Access = public)\n        function obj = BinomialConfig()\n            % 构造函数：初始化配置\n            \n            % 设置系统信息\n            obj.SetSystemInfo();\n            \n            % 计算有效行\n            obj.ValidRows = setdiff(1:375, obj.ExcludeRows);\n            \n            % 自动设置并行参数\n            obj.SetParallelParams();\n            \n            % 确保输出目录存在\n            obj.CreateDirectories();\n        end\n        \n        function SetSystemInfo(obj)\n            % 设置系统信息\n            obj.SystemInfo.CPU = 'Intel i9-9980HK (8核16线程)';\n            obj.SystemInfo.Memory = '64GB RAM';\n            obj.SystemInfo.GPU = 'AMD Radeon Pro 5500M 8GB';\n            obj.SystemInfo.Platform = computer();\n            obj.SystemInfo.MatlabVersion = version();\n            obj.SystemInfo.LogicalProcessors = feature('numcores');\n        end\n        \n        function SetParallelParams(obj)\n            % 自动设置并行计算参数\n            if obj.UseParallelComputing\n                logical_processors = feature('numcores');\n                % 针对i9-9980HK的优化配置\n                if isempty(obj.NumWorkers)\n                    obj.NumWorkers = min(8, logical_processors);\n                end\n                \n                % 创建临时存储目录\n                timestamp = datestr(now, 'yyyymmdd_HHMMSS');\n                obj.ParallelClusterJobStorageLocation = fullfile(tempdir, ...\n                    ['matlab_parallel_', timestamp]);\n                \n                if ~exist(obj.ParallelClusterJobStorageLocation, 'dir')\n                    mkdir(obj.ParallelClusterJobStorageLocation);\n                end\n            end\n        end\n        \n        function CreateDirectories(obj)\n            % 创建必要的目录\n            dirs = {\n                obj.OutputDirectory,\n                fullfile(obj.OutputDirectory, 'figures'),\n                fullfile(obj.OutputDirectory, 'csv'),\n                fullfile(obj.OutputDirectory, 'reports'),\n                obj.LogDirectory\n            };\n            \n            for i = 1:length(dirs)\n                if ~exist(dirs{i}, 'dir')\n                    mkdir(dirs{i});\n                end\n            end\n        end\n        \n        function SaveConfig(obj)\n            % 保存配置到文件\n            config_file = fullfile(obj.OutputDirectory, 'analysis_config.mat');\n            config = obj.ToStruct();\n            save(config_file, 'config', '-v7.3');\n        end\n        \n        function config_struct = ToStruct(obj)\n            % 将配置转换为结构体\n            props = properties(obj);\n            config_struct = struct();\n            \n            for i = 1:length(props)\n                config_struct.(props{i}) = obj.(props{i});\n            end\n        end\n        \n        function LoadConfig(obj, config_file)\n            % 从文件加载配置\n            if exist(config_file, 'file')\n                loaded = load(config_file);\n                config = loaded.config;\n                \n                props = fields(config);\n                for i = 1:length(props)\n                    if isprop(obj, props{i})\n                        obj.(props{i}) = config.(props{i});\n                    end\n                end\n            else\n                warning('配置文件不存在: %s', config_file);\n            end\n        end\n        \n        function DisplayConfig(obj)\n            % 显示当前配置\n            fprintf('\\n=== 当前分析配置 ===\\n');\n            \n            % 数据处理\n            fprintf('\\n数据处理参数:\\n');\n            fprintf('  - 排除行: [%s]\\n', num2str(obj.ExcludeRows));\n            fprintf('  - 反转项目: [%s]\\n', num2str(obj.ReverseItems));\n            fprintf('  - 目标列: %d\\n', obj.TargetColumn);\n            \n            % 模型参数\n            fprintf('\\n模型参数:\\n');\n            fprintf('  - Bootstrap样本数: %d\\n', obj.NumBootstrapSamples);\n            fprintf('  - K折验证: %d\\n', obj.KFolds);\n            fprintf('  - VIF阈值: %.1f\\n', obj.VifThreshold);\n            \n            % 变量选择方法\n            fprintf('\\n变量选择方法:\\n');\n            for i = 1:length(obj.VariableSelectionMethods)\n                fprintf('  - %s\\n', obj.VariableSelectionMethods{i});\n            end\n            \n            % 并行设置\n            fprintf('\\n并行计算设置:\\n');\n            fprintf('  - 使用并行: %s\\n', mat2str(obj.UseParallelComputing));\n            fprintf('  - Worker数量: %d\\n', obj.NumWorkers);\n            fprintf('  - 每个Worker线程数: %d\\n', obj.NumThreadsPerWorker);\n            \n            % 系统信息\n            fprintf('\\n系统信息:\\n');\n            fprintf('  - CPU: %s\\n', obj.SystemInfo.CPU);\n            fprintf('  - 内存: %s\\n', obj.SystemInfo.Memory);\n            fprintf('  - GPU: %s\\n', obj.SystemInfo.GPU);\n            \n            fprintf('\\n===================\\n\\n');\n        end\n    end\n    \n    methods (Access = private)\n        % 私有辅助方法可以在这里添加\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "7be20c35-ab03-46c2-870b-36924567ed9c"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "f3a5002e-344d-479e-86b7-11ab66ccbf56"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:07:07.791950+00:00",
          "stop_timestamp": "2025-05-08T09:07:08.411101+00:00",
          "type": "text",
          "text": "\n\n## 第二部分：日志管理模块\n\n创建一个专门的日志管理类，支持不同级别的日志记录和更好的输出格式：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:07:08.604776+00:00",
          "stop_timestamp": "2025-05-08T09:07:44.083146+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-logger",
            "type": "application/vnd.ant.code",
            "title": "日志管理模块 - BinomialLogger.m",
            "command": "create",
            "content": "classdef BinomialLogger < handle\n    % 日志管理类：负责所有日志记录功能\n    % 支持多种日志级别、文件和控制台输出\n    \n    properties (Access = private)\n        LogFile\n        LogLevel\n        FigureSaveLevel\n        Console\n        LogBuffer\n        BufferSize\n    end\n    \n    properties (Constant)\n        LEVELS = struct(...\n            'debug', 0, ...\n            'info', 1, ...\n            'warning', 2, ...\n            'error', 3 ...\n        )\n        \n        LEVEL_NAMES = {'DEBUG', 'INFO', 'WARNING', 'ERROR'}\n        \n        % ANSI颜色代码\n        COLORS = struct(...\n            'debug', '\\033[0;34m',   % 蓝色\n            'info', '\\033[0;32m',    % 绿色\n            'warning', '\\033[1;33m', % 黄色\n            'error', '\\033[1;31m',   % 红色\n            'reset', '\\033[0m'       % 重置\n        )\n    end\n    \n    methods (Access = public)\n        function obj = BinomialLogger(log_file, log_level, figure_save_level)\n            % 构造函数\n            % 输入:\n            %   log_file - 日志文件路径\n            %   log_level - 日志级别 ('debug', 'info', 'warning', 'error')\n            %   figure_save_level - 图形保存日志级别（可选）\n            \n            if nargin < 2\n                log_level = 'info';\n            end\n            \n            if nargin < 3\n                % 图形保存日志级别比一般日志级别高一级\n                switch lower(log_level)\n                    case 'debug'\n                        figure_save_level = 'info';\n                    case 'info'\n                        figure_save_level = 'warning';\n                    otherwise\n                        figure_save_level = log_level;\n                end\n            end\n            \n            obj.LogFile = log_file;\n            obj.LogLevel = lower(log_level);\n            obj.FigureSaveLevel = lower(figure_save_level);\n            obj.Console = true;\n            obj.BufferSize = 100;\n            obj.LogBuffer = cell(obj.BufferSize, 1);\n            \n            % 初始化日志文件\n            obj.InitializeLogFile();\n            \n            % 记录启动信息\n            obj.Log('info', '=== 日志系统初始化 ===');\n            obj.Log('info', sprintf('日志级别: %s (图形保存级别: %s)', ...\n                upper(obj.LogLevel), upper(obj.FigureSaveLevel)));\n        end\n        \n        function delete(obj)\n            % 析构函数：确保缓冲区内容写入文件\n            obj.FlushBuffer();\n        end\n        \n        function Log(obj, level, message)\n            % 记录日志\n            % 输入:\n            %   level - 日志级别\n            %   message - 日志信息\n            \n            level = lower(level);\n            \n            % 检查是否应记录此级别的日志\n            if ~obj.ShouldLog(level)\n                return;\n            end\n            \n            % 生成时间戳\n            timestamp = datestr(now, 'yyyy-mm-dd HH:MM:SS.FFF');\n            \n            % 获取调用函数信息\n            stack = dbstack('-completenames');\n            if length(stack) > 1\n                % 跳过当前函数，获取调用者信息\n                caller = stack(2);\n                [~, caller_func, ~] = fileparts(caller.name);\n                caller_info = sprintf('%s:%d', caller_func, caller.line);\n            else\n                caller_info = 'unknown';\n            end\n            \n            % 格式化日志消息\n            level_name = upper(level);\n            formatted_message = sprintf('[%s] [%s] [%s] %s', ...\n                timestamp, level_name, caller_info, message);\n            \n            % 输出到控制台（带颜色）\n            if obj.Console && obj.ShouldOutputToConsole(level)\n                if ispc\n                    % Windows系统不支持ANSI颜色\n                    fprintf('%s\\n', formatted_message);\n                else\n                    % Unix系统支持ANSI颜色\n                    color = obj.COLORS.(level);\n                    reset = obj.COLORS.reset;\n                    fprintf('%s%s%s\\n', color, formatted_message, reset);\n                end\n            end\n            \n            % 添加到缓冲区\n            obj.AddToBuffer(formatted_message);\n        end\n        \n        function LogPerformance(obj, operation, duration, additional_info)\n            % 记录性能信息\n            % 输入:\n            %   operation - 操作名称\n            %   duration - 持续时间（秒）\n            %   additional_info - 额外信息（可选）\n            \n            if nargin < 4\n                additional_info = '';\n            end\n            \n            if ~isempty(additional_info)\n                message = sprintf('性能: %s 完成，耗时: %.2f秒 (%s)', ...\n                    operation, duration, additional_info);\n            else\n                message = sprintf('性能: %s 完成，耗时: %.2f秒', ...\n                    operation, duration);\n            end\n            \n            obj.Log('info', message);\n        end\n        \n        function LogMemoryUsage(obj)\n            % 记录内存使用情况\n            if ispc\n                % Windows系统\n                [~, sys_mem] = memory();\n                total_mem = sys_mem.TotalPhys / (1024^3);  % GB\n                used_mem = (sys_mem.TotalPhys - sys_mem.AvailPhys) / (1024^3);  % GB\n                free_mem = sys_mem.AvailPhys / (1024^3);  % GB\n                \n                obj.Log('debug', sprintf('内存使用: 总计%.2fGB, 已用%.2fGB, 可用%.2fGB', ...\n                    total_mem, used_mem, free_mem));\n            else\n                % Unix系统\n                feature('memstats');  % 可能需要root权限\n            end\n        end\n        \n        function LogProgress(obj, current, total, description)\n            % 记录进度信息（进度条式）\n            % 输入:\n            %   current - 当前进度\n            %   total - 总进度\n            %   description - 描述信息\n            \n            percentage = current / total * 100;\n            progress_bar_width = 50;\n            filled_width = round(progress_bar_width * current / total);\n            bar = ['[' repmat('=', filled_width, 1) repmat(' ', progress_bar_width - filled_width, 1) ']'];\n            \n            message = sprintf('%s %s %.1f%% (%d/%d)', description, bar, percentage, current, total);\n            \n            % 使用回车符实现覆盖输出（仅适用于console）\n            if obj.Console\n                fprintf('\\r%s', message);\n                if current == total\n                    fprintf('\\n'); % 完成时换行\n                end\n            end\n            \n            % 只在特定进度点记录到文件\n            if mod(current, max(1, round(total / 10))) == 0 || current == total\n                obj.Log('debug', message);\n            end\n        end\n        \n        function LogException(obj, exception, context)\n            % 记录异常信息\n            % 输入:\n            %   exception - MException对象\n            %   context - 上下文信息\n            \n            obj.Log('error', sprintf('异常发生在 %s: %s', context, exception.message));\n            \n            % 记录堆栈跟踪\n            for i = 1:length(exception.stack)\n                frame = exception.stack(i);\n                obj.Log('error', sprintf('  在 %s (行 %d): %s', ...\n                    frame.name, frame.line, frame.file));\n            end\n            \n            % 如果有cause，也记录它\n            if ~isempty(exception.cause)\n                obj.Log('error', '原因:');\n                for i = 1:length(exception.cause)\n                    obj.LogException(exception.cause{i}, '嵌套异常');\n                end\n            end\n        end\n        \n        function SetLogLevel(obj, level)\n            % 设置日志级别\n            obj.LogLevel = lower(level);\n            obj.Log('info', sprintf('日志级别已更改为: %s', upper(level)));\n        end\n        \n        function SetFigureSaveLevel(obj, level)\n            % 设置图形保存日志级别\n            obj.FigureSaveLevel = lower(level);\n            obj.Log('info', sprintf('图形保存日志级别已更改为: %s', upper(level)));\n        end\n        \n        function CreateSection(obj, title)\n            % 创建日志分节\n            separator = repmat('=', 1, 60);\n            obj.Log('info', separator);\n            obj.Log('info', sprintf(' %s ', title));\n            obj.Log('info', separator);\n        end\n        \n        function Summary = GetSummary(obj)\n            % 获取日志摘要\n            Summary = struct();\n            Summary.LogFile = obj.LogFile;\n            Summary.LogLevel = obj.LogLevel;\n            Summary.FigureSaveLevel = obj.FigureSaveLevel;\n            \n            % 统计不同级别的日志数量\n            if exist(obj.LogFile, 'file')\n                fid = fopen(obj.LogFile, 'r');\n                if fid ~= -1\n                    log_content = fread(fid, '*char')';\n                    fclose(fid);\n                    \n                    % 计算各级别出现次数\n                    for i = 1:length(obj.LEVEL_NAMES)\n                        level_name = obj.LEVEL_NAMES{i};\n                        count = length(regexp(log_content, ['\\[' level_name '\\]']));\n                        Summary.(sprintf('%sCount', level_name)) = count;\n                    end\n                end\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function InitializeLogFile(obj)\n            % 初始化日志文件\n            [dir_path, ~, ~] = fileparts(obj.LogFile);\n            if ~exist(dir_path, 'dir')\n                mkdir(dir_path);\n            end\n            \n            % 如果文件已存在，备份旧文件\n            if exist(obj.LogFile, 'file')\n                timestamp = datestr(now, 'yyyymmdd_HHMMSS');\n                [dir_path, name, ext] = fileparts(obj.LogFile);\n                backup_file = fullfile(dir_path, sprintf('%s_%s%s', name, timestamp, ext));\n                copyfile(obj.LogFile, backup_file);\n            end\n            \n            % 创建新文件\n            fid = fopen(obj.LogFile, 'w');\n            if fid == -1\n                error('无法创建日志文件: %s', obj.LogFile);\n            end\n            fclose(fid);\n        end\n        \n        function should_log = ShouldLog(obj, level)\n            % 判断是否应记录此级别的日志\n            should_log = obj.LEVELS.(level) >= obj.LEVELS.(obj.LogLevel);\n        end\n        \n        function should_output = ShouldOutputToConsole(obj, level)\n            % 判断是否应输出到控制台\n            should_output = obj.Console && obj.ShouldLog(level);\n        end\n        \n        function AddToBuffer(obj, message)\n            % 添加消息到缓冲区\n            % 使用循环缓冲区\n            persistent buffer_index;\n            if isempty(buffer_index)\n                buffer_index = 1;\n            end\n            \n            obj.LogBuffer{buffer_index} = message;\n            buffer_index = mod(buffer_index, obj.BufferSize) + 1;\n            \n            % 定期刷新缓冲区\n            if buffer_index == 1\n                obj.FlushBuffer();\n            end\n        end\n        \n        function FlushBuffer(obj)\n            % 将缓冲区内容写入文件\n            try\n                fid = fopen(obj.LogFile, 'a');\n                if fid ~= -1\n                    for i = 1:obj.BufferSize\n                        if ~isempty(obj.LogBuffer{i})\n                            fprintf(fid, '%s\\n', obj.LogBuffer{i});\n                        end\n                    end\n                    fclose(fid);\n                    % 清空缓冲区\n                    obj.LogBuffer = cell(obj.BufferSize, 1);\n                end\n            catch ME\n                warning('写入日志文件失败: %s', ME.message);\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "ad183c42-1178-4ae3-833b-66b36b6255d5"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "fe5f8135-4227-46cd-84f3-05ac7444cb07"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:07:45.690940+00:00",
          "stop_timestamp": "2025-05-08T09:07:46.433480+00:00",
          "type": "text",
          "text": "\n\n## 第三部分：主分析器类\n\n创建主分析器类，使用面向对象的方式组织代码，增强可维护性和复用性：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:07:46.626406+00:00",
          "stop_timestamp": "2025-05-08T09:08:39.709127+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-analyzer",
            "type": "application/vnd.ant.code",
            "title": "主分析器类 - BinomialAnalyzer.m",
            "command": "create",
            "content": "classdef BinomialAnalyzer < handle\n    % 二元逻辑回归分析器主类\n    % 封装所有分析功能，提供统一的接口\n    \n    properties (Access = private)\n        Config     % 配置对象\n        Logger     % 日志对象\n        Data       % 数据管理对象\n        Parallel   % 并行管理对象\n        GPU        % GPU管理对象\n        Results    % 结果存储\n        StartTime  % 分析开始时间\n    end\n    \n    methods (Access = public)\n        function obj = BinomialAnalyzer(varargin)\n            % 构造函数\n            % 参数可以是:\n            %   - 配置文件路径\n            %   - 配置对象\n            %   - 空（使用默认配置）\n            \n            % 开始计时\n            obj.StartTime = tic;\n            \n            % 初始化配置\n            if nargin == 0\n                obj.Config = BinomialConfig();\n            elseif isa(varargin{1}, 'BinomialConfig')\n                obj.Config = varargin{1};\n            elseif ischar(varargin{1}) || isstring(varargin{1})\n                obj.Config = BinomialConfig();\n                obj.Config.LoadConfig(varargin{1});\n            else\n                error('无效的输入参数类型');\n            end\n            \n            % 初始化日志系统\n            log_file = fullfile(obj.Config.LogDirectory, 'analysis.log');\n            obj.Logger = BinomialLogger(log_file, obj.Config.LogLevel);\n            \n            % 记录系统信息\n            obj.LogSystemInfo();\n            \n            % 初始化其他组件\n            obj.InitializeComponents();\n            \n            % 初始化结果存储\n            obj.Results = struct();\n        end\n        \n        function delete(obj)\n            % 析构函数：清理资源\n            if ~isempty(obj.Parallel)\n                obj.Parallel.Cleanup();\n            end\n            \n            if ~isempty(obj.GPU)\n                obj.GPU.Cleanup();\n            end\n            \n            total_time = toc(obj.StartTime);\n            obj.Logger.Log('info', sprintf('分析完成，总耗时: %.2f秒', total_time));\n        end\n        \n        function RunAnalysis(obj, data_file)\n            % 运行完整分析流程\n            % 输入:\n            %   data_file - 数据文件路径\n            \n            try\n                % 创建主要分析阶段\n                obj.Logger.CreateSection('开始二元逻辑回归分析');\n                \n                % 1. 数据加载和预处理\n                obj.LoadAndPreprocessData(data_file);\n                \n                % 2. 变量准备\n                obj.PrepareVariables();\n                \n                % 3. 多重共线性检查\n                obj.CheckMulticollinearity();\n                \n                % 4. 变量相关性分析\n                obj.AnalyzeVariableCorrelations();\n                \n                % 5. Bootstrap抽样\n                obj.GenerateBootstrapSamples();\n                \n                % 6. K折交叉验证\n                obj.PerformCrossValidation();\n                \n                % 7. 变量选择\n                obj.PerformVariableSelection();\n                \n                % 8. 系数稳定性监控\n                obj.MonitorCoefficientStability();\n                \n                % 9. 参数统计分析\n                obj.CalculateParameterStatistics();\n                \n                % 10. 变量贡献分析\n                obj.EvaluateVariableContribution();\n                \n                % 11. 残差分析\n                obj.PerformResidualAnalysis();\n                \n                % 12. 创建可视化\n                obj.CreateVisualizations();\n                \n                % 13. 保存结果\n                obj.SaveResults();\n                \n                % 14. 生成报告\n                obj.GenerateReport();\n                \n                obj.Logger.CreateSection('分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'RunAnalysis');\n                rethrow(ME);\n            end\n        end\n        \n        function CustomAnalysis(obj, data_file, analysis_steps)\n            % 运行自定义分析步骤\n            % 输入:\n            %   data_file - 数据文件路径\n            %   analysis_steps - 要执行的分析步骤数组\n            \n            try\n                obj.Logger.CreateSection('开始自定义分析');\n                \n                % 总是需要先加载数据\n                if ~isfield(obj.Results, 'data_raw')\n                    obj.LoadAndPreprocessData(data_file);\n                end\n                \n                % 执行指定的分析步骤\n                for i = 1:length(analysis_steps)\n                    step = analysis_steps{i};\n                    \n                    switch lower(step)\n                        case 'preprocess'\n                            obj.PrepareVariables();\n                        case 'multicollinearity'\n                            obj.CheckMulticollinearity();\n                        case 'correlation'\n                            obj.AnalyzeVariableCorrelations();\n                        case 'bootstrap'\n                            obj.GenerateBootstrapSamples();\n                        case 'crossvalidation'\n                            obj.PerformCrossValidation();\n                        case 'variableselection'\n                            obj.PerformVariableSelection();\n                        case 'coefficientstability'\n                            obj.MonitorCoefficientStability();\n                        case 'parameterstats'\n                            obj.CalculateParameterStatistics();\n                        case 'contribution'\n                            obj.EvaluateVariableContribution();\n                        case 'residual'\n                            obj.PerformResidualAnalysis();\n                        case 'visualization'\n                            obj.CreateVisualizations();\n                        case 'save'\n                            obj.SaveResults();\n                        case 'report'\n                            obj.GenerateReport();\n                        otherwise\n                            obj.Logger.Log('warning', sprintf('未知的分析步骤: %s', step));\n                    end\n                end\n                \n                obj.Logger.CreateSection('自定义分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CustomAnalysis');\n                rethrow(ME);\n            end\n        end\n        \n        function result = GetResults(obj, component)\n            % 获取特定组件的结果\n            % 输入:\n            %   component - 组件名称（可选，默认返回所有结果）\n            \n            if nargin < 2\n                result = obj.Results;\n            else\n                if isfield(obj.Results, component)\n                    result = obj.Results.(component);\n                else\n                    warning('结果中不存在组件: %s', component);\n                    result = [];\n                end\n            end\n        end\n        \n        function config = GetConfig(obj)\n            % 获取当前配置\n            config = obj.Config;\n        end\n        \n        function logger = GetLogger(obj)\n            % 获取日志对象\n            logger = obj.Logger;\n        end\n        \n        function ShowProgress(obj, message)\n            % 显示进度信息\n            obj.Logger.Log('info', message);\n        end\n    end\n    \n    methods (Access = private)\n        function InitializeComponents(obj)\n            % 初始化各个组件\n            \n            % 初始化数据管理器\n            obj.Data = DataManager(obj.Config, obj.Logger);\n            \n            % 初始化并行计算管理器\n            obj.Parallel = ParallelManager(obj.Config, obj.Logger);\n            \n            % 初始化GPU管理器\n            obj.GPU = GPUManager(obj.Config, obj.Logger);\n            \n            % 验证必要的工具箱\n            obj.ValidateToolboxes();\n        end\n        \n        function ValidateToolboxes(obj)\n            % 验证必要的MATLAB工具箱\n            required_toolboxes = {\n                'statistics_toolbox',\n                'optimization_toolbox'\n            };\n            \n            for i = 1:length(required_toolboxes)\n                if ~license('test', required_toolboxes{i})\n                    error('需要安装 %s', required_toolboxes{i});\n                end\n            end\n            \n            obj.Logger.Log('info', '所有必要的工具箱验证成功');\n        end\n        \n        function LogSystemInfo(obj)\n            % 记录系统信息\n            obj.Logger.CreateSection('系统配置信息');\n            \n            info = obj.Config.SystemInfo;\n            obj.Logger.Log('info', sprintf('CPU: %s', info.CPU));\n            obj.Logger.Log('info', sprintf('内存: %s', info.Memory));\n            obj.Logger.Log('info', sprintf('GPU: %s', info.GPU));\n            obj.Logger.Log('info', sprintf('平台: %s', info.Platform));\n            obj.Logger.Log('info', sprintf('MATLAB版本: %s', info.MatlabVersion));\n            obj.Logger.Log('info', sprintf('逻辑处理器数: %d', info.LogicalProcessors));\n            \n            % 显示配置\n            obj.Config.DisplayConfig();\n        end\n        \n        function LoadAndPreprocessData(obj, data_file)\n            % 加载和预处理数据\n            obj.Logger.CreateSection('数据加载和预处理');\n            \n            start_time = tic;\n            try\n                % 加载数据\n                [data_raw, success, msg] = obj.Data.LoadData(data_file);\n                if ~success\n                    error(msg);\n                end\n                \n                % 预处理数据\n                [data_processed, valid_rows] = obj.Data.PreprocessData(data_raw);\n                \n                % 保存到结果\n                obj.Results.data_raw = data_raw;\n                obj.Results.data_processed = data_processed;\n                obj.Results.valid_rows = valid_rows;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('数据加载和预处理', duration, ...\n                    sprintf('样本数: %d, 变量数: %d', size(data_processed, 1), size(data_processed, 2)));\n                \n            catch ME\n                obj.Logger.LogException(ME, '数据加载和预处理');\n                rethrow(ME);\n            end\n        end\n        \n        function PrepareVariables(obj)\n            % 准备自变量和因变量\n            obj.Logger.CreateSection('变量准备');\n            \n            start_time = tic;\n            try\n                [X, y, var_names, group_means] = obj.Data.PrepareVariables(obj.Results.data_processed);\n                \n                % 保存到结果\n                obj.Results.X = X;\n                obj.Results.y = y;\n                obj.Results.var_names = var_names;\n                obj.Results.group_means = group_means;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('变量准备', duration, ...\n                    sprintf('自变量数: %d', size(X, 2)));\n                \n            catch ME\n                obj.Logger.LogException(ME, '变量准备');\n                rethrow(ME);\n            end\n        end\n        \n        function CheckMulticollinearity(obj)\n            % 检查多重共线性\n            obj.Logger.CreateSection('多重共线性检查');\n            \n            start_time = tic;\n            try\n                collinearity_checker = CollinearityChecker(obj.Config, obj.Logger);\n                [X_final, vif_values, removed_vars] = collinearity_checker.Check(obj.Results.X, obj.Results.var_names);\n                \n                % 保存结果\n                obj.Results.X_final = X_final;\n                obj.Results.vif_values = vif_values;\n                obj.Results.removed_vars = removed_vars;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('多重共线性检查', duration, ...\n                    sprintf('最终自变量数: %d', size(X_final, 2)));\n                \n            catch ME\n                obj.Logger.LogException(ME, '多重共线性检查');\n                rethrow(ME);\n            end\n        end\n        \n        function AnalyzeVariableCorrelations(obj)\n            % 分析变量相关性\n            obj.Logger.CreateSection('变量相关性分析');\n            \n            start_time = tic;\n            try\n                correlation_analyzer = CorrelationAnalyzer(obj.Config, obj.Logger);\n                pca_results = correlation_analyzer.Analyze(obj.Results.X_final, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.pca_results = pca_results;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('变量相关性分析', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '变量相关性分析');\n                rethrow(ME);\n            end\n        end\n        \n        function GenerateBootstrapSamples(obj)\n            % 生成Bootstrap样本\n            obj.Logger.CreateSection('Bootstrap抽样');\n            \n            start_time = tic;\n            try\n                bootstrap_sampler = BootstrapSampler(obj.Config, obj.Logger);\n                [train_indices, test_indices] = bootstrap_sampler.Sample(obj.Results.y);\n                \n                % 保存结果\n                obj.Results.train_indices = train_indices;\n                obj.Results.test_indices = test_indices;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('Bootstrap抽样', duration, ...\n                    sprintf('生成了 %d 个训练/测试集', length(train_indices)));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'Bootstrap抽样');\n                rethrow(ME);\n            end\n        end\n        \n        function PerformCrossValidation(obj)\n            % 执行K折交叉验证\n            obj.Logger.CreateSection('K折交叉验证');\n            \n            start_time = tic;\n            try\n                cv_validator = CrossValidator(obj.Config, obj.Logger);\n                cv_results = cv_validator.Validate(obj.Results.X_final, obj.Results.y, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.cv_results = cv_results;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('K折交叉验证', duration, ...\n                    sprintf('K=%d', obj.Config.KFolds));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'K折交叉验证');\n                rethrow(ME);\n            end\n        end\n        \n        function PerformVariableSelection(obj)\n            % 执行变量选择\n            obj.Logger.CreateSection('变量选择');\n            \n            start_time = tic;\n            try\n                variable_selector = VariableSelector(obj.Config, obj.Logger, obj.Parallel);\n                results = variable_selector.SelectVariables(obj.Results.X_final, obj.Results.y, ...\n                    obj.Results.train_indices, obj.Results.test_indices, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.variable_selection = results;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('变量选择', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '变量选择');\n                rethrow(ME);\n            end\n        end\n        \n        function MonitorCoefficientStability(obj)\n            % 监控系数稳定性\n            obj.Logger.CreateSection('系数稳定性监控');\n            \n            start_time = tic;\n            try\n                stability_monitor = CoefficientStabilityMonitor(obj.Config, obj.Logger);\n                coef_stability = stability_monitor.Monitor(obj.Results.variable_selection, ...\n                    obj.Config.VariableSelectionMethods, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.coef_stability = coef_stability;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('系数稳定性监控', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '系数稳定性监控');\n                rethrow(ME);\n            end\n        end\n        \n        function CalculateParameterStatistics(obj)\n            % 计算参数统计\n            obj.Logger.CreateSection('参数统计分析');\n            \n            start_time = tic;\n            try\n                param_stats_calculator = ParameterStatisticsCalculator(obj.Config, obj.Logger);\n                param_stats = param_stats_calculator.Calculate(obj.Results.variable_selection, ...\n                    obj.Config.VariableSelectionMethods, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.param_stats = param_stats;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('参数统计分析', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '参数统计分析');\n                rethrow(ME);\n            end\n        end\n        \n        function EvaluateVariableContribution(obj)\n            % 评估变量贡献\n            obj.Logger.CreateSection('变量贡献分析');\n            \n            start_time = tic;\n            try\n                contribution_evaluator = VariableContributionEvaluator(obj.Config, obj.Logger);\n                var_contribution = contribution_evaluator.Evaluate(obj.Results.X_final, obj.Results.y, ...\n                    obj.Results.variable_selection, obj.Config.VariableSelectionMethods, obj.Results.var_names(~obj.Results.removed_vars));\n                \n                % 保存结果\n                obj.Results.var_contribution = var_contribution;\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('变量贡献分析', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '变量贡献分析');\n                rethrow(ME);\n            end\n        end\n        \n        function PerformResidualAnalysis(obj)\n            % 执行残差分析\n            obj.Logger.CreateSection('残差分析');\n            \n            start_time = tic;\n            try\n                residual_analyzer = ResidualAnalyzer(obj.Config, obj.Logger);\n                residual_analyzer.Analyze(obj.Results.variable_selection, obj.Config.VariableSelectionMethods);\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('残差分析', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '残差分析');\n                rethrow(ME);\n            end\n        end\n        \n        function CreateVisualizations(obj)\n            % 创建可视化图表\n            obj.Logger.CreateSection('创建可视化图表');\n            \n            start_time = tic;\n            try\n                visualizer = ResultVisualizer(obj.Config, obj.Logger);\n                visualizer.CreateAllVisualization(obj.Results, obj.Config.VariableSelectionMethods);\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('可视化创建', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '创建可视化图表');\n                rethrow(ME);\n            end\n        end\n        \n        function SaveResults(obj)\n            % 保存结果\n            obj.Logger.CreateSection('保存分析结果');\n            \n            start_time = tic;\n            try\n                result_saver = ResultSaver(obj.Config, obj.Logger);\n                result_saver.SaveAll(obj.Results, obj.Config.VariableSelectionMethods);\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('结果保存', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '保存结果');\n                rethrow(ME);\n            end\n        end\n        \n        function GenerateReport(obj)\n            % 生成分析报告\n            obj.Logger.CreateSection('生成分析报告');\n            \n            start_time = tic;\n            try\n                report_generator = ReportGenerator(obj.Config, obj.Logger);\n                report_generator.Generate(obj.Results, obj.Config.VariableSelectionMethods);\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance('报告生成', duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, '生成报告');\n                rethrow(ME);\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "e6424c5e-e747-4c82-a190-17baf1b25374"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "8b7346a7-0a5b-44f7-83d4-28b8d3838050"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:08:41.030993+00:00",
          "stop_timestamp": "2025-05-08T09:08:41.717331+00:00",
          "type": "text",
          "text": "\n\n## 第四部分：数据管理模块\n\n创建数据管理模块，包含数据清洗、缺失值处理和异常值检测：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:08:41.907672+00:00",
          "stop_timestamp": "2025-05-08T09:09:44.862123+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-data-manager",
            "type": "application/vnd.ant.code",
            "title": "数据管理模块 - DataManager.m",
            "command": "create",
            "content": "classdef DataManager < handle\n    % 数据管理类：负责所有数据相关操作\n    % 包括加载、预处理、清洗和变量准备\n    \n    properties (Access = private)\n        Config\n        Logger\n    end\n    \n    methods (Access = public)\n        function obj = DataManager(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n        end\n        \n        function [data, success, message] = LoadData(obj, filename)\n            % 加载数据文件\n            % 输入:\n            %   filename - 数据文件名\n            % 输出:\n            %   data - 加载的数据\n            %   success - 是否成功加载\n            %   message - 成功或错误消息\n            \n            success = false;\n            message = '';\n            data = [];\n            \n            try\n                obj.Logger.Log('info', sprintf('正在加载数据文件: %s', filename));\n                \n                % 检查文件是否存在\n                if ~exist(filename, 'file')\n                    message = sprintf('文件不存在: %s', filename);\n                    obj.Logger.Log('error', message);\n                    return;\n                end\n                \n                % 获取文件信息\n                file_info = dir(filename);\n                file_size_mb = file_info.bytes / (1024^2);\n                obj.Logger.Log('debug', sprintf('文件大小: %.2f MB', file_size_mb));\n                \n                % 根据文件扩展名选择加载方法\n                [~, ~, ext] = fileparts(filename);\n                \n                switch lower(ext)\n                    case '.mat'\n                        data = obj.LoadMatFile(filename);\n                    case {'.csv', '.txt'}\n                        data = obj.LoadTextFile(filename);\n                    case {'.xlsx', '.xls'}\n                        data = obj.LoadExcelFile(filename);\n                    otherwise\n                        % 尝试作为.mat文件加载\n                        data = obj.LoadMatFile(filename);\n                end\n                \n                % 验证数据\n                [isValid, validationMessage] = obj.ValidateData(data);\n                if ~isValid\n                    message = sprintf('数据验证失败: %s', validationMessage);\n                    obj.Logger.Log('error', message);\n                    return;\n                end\n                \n                success = true;\n                message = sprintf('数据加载成功，样本数: %d，变量数: %d', size(data, 1), size(data, 2));\n                obj.Logger.Log('info', message);\n                \n            catch ME\n                message = sprintf('数据文件 %s 加载失败: %s', filename, ME.message);\n                obj.Logger.LogException(ME, 'LoadData');\n            end\n        end\n        \n        function [data_processed, valid_rows] = PreprocessData(obj, data)\n            % 数据清洗与预处理\n            % 输入:\n            %   data - 原始数据\n            % 输出:\n            %   data_processed - 处理后的数据\n            %   valid_rows - 有效行索引\n            \n            obj.Logger.Log('info', '开始数据预处理');\n            \n            try\n                % 1. 反转指定列\n                obj.Logger.Log('debug', sprintf('反转项目: %s', mat2str(obj.Config.ReverseItems)));\n                data_processed = data;\n                data_processed(:, obj.Config.ReverseItems) = obj.Config.MaxScore + 1 - data_processed(:, obj.Config.ReverseItems);\n                \n                % 2. 选择有效行\n                valid_rows = obj.Config.ValidRows;\n                data_processed = data_processed(valid_rows, :);\n                obj.Logger.Log('info', sprintf('有效样本数: %d', length(valid_rows)));\n                \n                % 3. 检查缺失值\n                [data_processed, missing_stats] = obj.HandleMissingValues(data_processed);\n                obj.Logger.Log('info', sprintf('缺失值处理: 填充了 %d 个值', missing_stats.filled_count));\n                \n                % 4. 异常值检测\n                [data_processed, outlier_stats] = obj.DetectAndHandleOutliers(data_processed);\n                obj.Logger.Log('info', sprintf('异常值检测: 检测到 %d 个异常值', outlier_stats.total_outliers));\n                \n                % 5. 数据验证\n                obj.ValidateProcessedData(data_processed);\n                \n                % 6. 数据摘要\n                summary = obj.GenerateDataSummary(data_processed);\n                obj.LogDataSummary(summary);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PreprocessData');\n                rethrow(ME);\n            end\n        end\n        \n        function [X, y, var_names, group_means] = PrepareVariables(obj, data)\n            % 准备自变量和因变量\n            % 输入:\n            %   data - 预处理后的数据\n            % 输出:\n            %   X - 自变量矩阵\n            %   y - 因变量向量\n            %   var_names - 变量名称\n            %   group_means - 分组均值\n            \n            obj.Logger.Log('info', '开始变量准备');\n            \n            try\n                % 1. 提取因变量\n                y = data(:, obj.Config.TargetColumn);\n                \n                % 验证因变量\n                obj.ValidateDependentVariable(y);\n                \n                % 2. 二元化因变量\n                y = double(y > 2);\n                obj.Logger.Log('info', sprintf('因变量二元化完成，正类比例: %.2f%%', mean(y) * 100));\n                \n                % 3. 处理分组变量\n                groups = obj.Config.VariableGroups;\n                n_groups = length(groups);\n                X = zeros(size(data, 1), n_groups);\n                group_means = cell(n_groups, 1);\n                var_names = cell(n_groups, 1);\n                \n                % 并行处理各组\n                parfor i = 1:n_groups\n                    group_cols = groups{i};\n                    [X(:, i), group_means{i}, var_names{i}] = obj.ProcessGroup(data, group_cols, i);\n                end\n                \n                obj.Logger.Log('info', sprintf('变量准备完成，自变量数: %d', size(X, 2)));\n                \n                % 4. 验证准备好的变量\n                obj.ValidatePreparedVariables(X, y);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PrepareVariables');\n                rethrow(ME);\n            end\n        end\n        \n        function summary = GenerateDataSummary(obj, data)\n            % 生成数据摘要\n            % 输入:\n            %   data - 数据矩阵\n            % 输出:\n            %   summary - 数据摘要结构体\n            \n            summary = struct();\n            summary.dimensions = size(data);\n            summary.missing_count = sum(isnan(data(:)));\n            summary.missing_percentage = summary.missing_count / numel(data) * 100;\n            \n            % 统计信息\n            summary.stats = struct();\n            summary.stats.mean = mean(data, 'omitnan');\n            summary.stats.std = std(data, 'omitnan');\n            summary.stats.min = min(data, [], 'omitnan');\n            summary.stats.max = max(data, [], 'omitnan');\n            summary.stats.median = median(data, 'omitnan');\n            \n            % 数据类型分析\n            summary.data_types = struct();\n            for i = 1:size(data, 2)\n                col_data = data(:, i);\n                unique_vals = length(unique(col_data(~isnan(col_data))));\n                total_vals = sum(~isnan(col_data));\n                \n                if unique_vals <= 2\n                    summary.data_types.(['col_' num2str(i)]) = 'binary';\n                elseif unique_vals / total_vals < 0.05\n                    summary.data_types.(['col_' num2str(i)]) = 'categorical';\n                else\n                    summary.data_types.(['col_' num2str(i)]) = 'continuous';\n                end\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function data = LoadMatFile(obj, filename)\n            % 加载.mat文件\n            try\n                s = load(filename);\n                if isfield(s, 'data')\n                    data = s.data;\n                else\n                    % 如果没有'data'字段，尝试获取第一个字段\n                    fn = fieldnames(s);\n                    if ~isempty(fn)\n                        data = s.(fn{1});\n                    else\n                        error('数据文件中没有找到有效变量');\n                    end\n                end\n                \n                % 转换为数值矩阵\n                if istable(data)\n                    data = table2array(data);\n                elseif ~isnumeric(data)\n                    error('数据必须是数值矩阵或表格');\n                end\n                \n            catch ME\n                % 尝试无变量名加载\n                data = load(filename);\n                if ~isnumeric(data)\n                    error('无法加载数值数据：%s', ME.message);\n                end\n            end\n        end\n        \n        function data = LoadTextFile(obj, filename)\n            % 加载文本文件（CSV等）\n            try\n                % 检测分隔符\n                delimiter = obj.DetectDelimiter(filename);\n                \n                % 使用readmatrix（MATLAB R2019a+）或csvread\n                if exist('readmatrix', 'file')\n                    data = readmatrix(filename, 'Delimiter', delimiter);\n                else\n                    % 回退到csvread（对于旧版本）\n                    data = csvread(filename);\n                end\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('使用标准方法失败，尝试备用方法: %s', ME.message));\n                \n                % 尝试使用importdata\n                imported = importdata(filename);\n                if isnumeric(imported)\n                    data = imported;\n                elseif isstruct(imported) && isfield(imported, 'data')\n                    data = imported.data;\n                else\n                    error('无法从文本文件中提取数值数据');\n                end\n            end\n        end\n        \n        function data = LoadExcelFile(obj, filename)\n            % 加载Excel文件\n            try\n                % 获取所有工作表名称\n                [~, sheets] = xlsfinfo(filename);\n                \n                if isempty(sheets)\n                    error('Excel文件中没有找到工作表');\n                end\n                \n                obj.Logger.Log('debug', sprintf('找到 %d 个工作表，使用第一个', length(sheets)));\n                \n                % 读取第一个工作表\n                data = xlsread(filename, sheets{1});\n                \n                if isempty(data)\n                    error('Excel文件中没有找到数值数据');\n                end\n                \n            catch ME\n                error('加载Excel文件失败: %s', ME.message);\n            end\n        end\n        \n        function delimiter = DetectDelimiter(obj, filename)\n            % 检测文本文件的分隔符\n            fid = fopen(filename, 'r');\n            if fid == -1\n                error('无法打开文件');\n            end\n            \n            % 读取前几行\n            first_lines = cell(5, 1);\n            for i = 1:5\n                line = fgetl(fid);\n                if ~ischar(line)\n                    break;\n                end\n                first_lines{i} = line;\n            end\n            fclose(fid);\n            \n            % 测试不同的分隔符\n            delimiters = {',', ';', '\\t', ' ', '|'};\n            max_count = 0;\n            best_delimiter = ',';\n            \n            for i = 1:length(delimiters)\n                count = 0;\n                for j = 1:length(first_lines)\n                    if ~isempty(first_lines{j})\n                        count = count + length(regexp(first_lines{j}, delimiters{i}));\n                    end\n                end\n                \n                if count > max_count\n                    max_count = count;\n                    best_delimiter = delimiters{i};\n                end\n            end\n            \n            delimiter = best_delimiter;\n            obj.Logger.Log('debug', sprintf('检测到分隔符: \"%s\"', delimiter));\n        end\n        \n        function [isValid, message] = ValidateData(obj, data)\n            % 验证数据\n            isValid = true;\n            message = '';\n            \n            % 检查数据是否为空\n            if isempty(data)\n                isValid = false;\n                message = '数据为空';\n                return;\n            end\n            \n            % 检查数据类型\n            if ~isnumeric(data)\n                isValid = false;\n                message = '数据不是数值类型';\n                return;\n            end\n            \n            % 检查维度\n            if size(data, 2) < obj.Config.TargetColumn\n                isValid = false;\n                message = sprintf('数据列数不足，需要至少 %d 列', obj.Config.TargetColumn);\n                return;\n            end\n            \n            % 检查数据范围\n            if any(data(:) < 0) || any(data(:) > obj.Config.MaxScore)\n                obj.Logger.Log('warning', '数据中存在超出预期范围的值');\n            end\n        end\n        \n        function [data_processed, missing_stats] = HandleMissingValues(obj, data)\n            % 处理缺失值\n            missing_stats = struct();\n            missing_stats.initial_count = sum(isnan(data(:)));\n            missing_stats.filled_count = 0;\n            \n            data_processed = data;\n            \n            if missing_stats.initial_count > 0\n                obj.Logger.Log('warning', sprintf('检测到 %d 个缺失值', missing_stats.initial_count));\n                \n                % 使用多种方法填充缺失值\n                for j = 1:size(data, 2)\n                    col_data = data(:, j);\n                    missing_mask = isnan(col_data);\n                    \n                    if any(missing_mask)\n                        % 根据数据分布选择填充方法\n                        if sum(missing_mask) / length(col_data) < 0.05\n                            % 缺失值少于5%，使用均值填充\n                            fill_value = mean(col_data, 'omitnan');\n                            method = '均值';\n                        elseif sum(missing_mask) / length(col_data) < 0.15\n                            % 缺失值少于15%，使用中位数填充\n                            fill_value = median(col_data, 'omitnan');\n                            method = '中位数';\n                        else\n                            % 缺失值较多，使用线性插值\n                            data_processed(:, j) = fillmissing(col_data, 'linear');\n                            missing_stats.filled_count = missing_stats.filled_count + sum(missing_mask);\n                            continue;\n                        end\n                        \n                        data_processed(missing_mask, j) = fill_value;\n                        missing_stats.filled_count = missing_stats.filled_count + sum(missing_mask);\n                        obj.Logger.Log('debug', sprintf('列 %d 使用%s填充 %d 个缺失值', j, method, sum(missing_mask)));\n                    end\n                end\n            end\n        end\n        \n        function [data_processed, outlier_stats] = DetectAndHandleOutliers(obj, data)\n            % 检测和处理异常值\n            outlier_stats = struct();\n            outlier_stats.total_outliers = 0;\n            outlier_stats.outliers_by_column = zeros(1, size(data, 2));\n            \n            data_processed = data;\n            \n            % 使用改进的Tukey方法检测异常值\n            for j = 1:size(data, 2)\n                col_data = data(:, j);\n                \n                % 计算四分位数\n                Q1 = prctile(col_data, 25);\n                Q3 = prctile(col_data, 75);\n                IQR = Q3 - Q1;\n                \n                % 计算异常值阈值（使用1.5倍IQR）\n                lower_bound = Q1 - 1.5 * IQR;\n                upper_bound = Q3 + 1.5 * IQR;\n                \n                % 检测异常值\n                outlier_mask = col_data < lower_bound | col_data > upper_bound;\n                n_outliers = sum(outlier_mask);\n                \n                if n_outliers > 0\n                    outlier_stats.total_outliers = outlier_stats.total_outliers + n_outliers;\n                    outlier_stats.outliers_by_column(j) = n_outliers;\n                    \n                    % 处理异常值（Winsorization）\n                    data_processed(col_data < lower_bound, j) = lower_bound;\n                    data_processed(col_data > upper_bound, j) = upper_bound;\n                    \n                    obj.Logger.Log('debug', sprintf('列 %d 检测到 %d 个异常值', j, n_outliers));\n                end\n            end\n            \n            if outlier_stats.total_outliers > 0\n                obj.Logger.Log('info', sprintf('总计处理 %d 个异常值', outlier_stats.total_outliers));\n            end\n        end\n        \n        function ValidateProcessedData(obj, data)\n            % 验证预处理后的数据\n            try\n                % 检查是否仍有缺失值\n                if any(isnan(data(:)))\n                    obj.Logger.Log('warning', '预处理后仍存在缺失值');\n                end\n                \n                % 检查数据范围\n                min_val = min(data(:));\n                max_val = max(data(:));\n                \n                if min_val < 0 || max_val > obj.Config.MaxScore\n                    obj.Logger.Log('warning', sprintf('数据超出预期范围 [0, %d]: [%.2f, %.2f]', ...\n                        obj.Config.MaxScore, min_val, max_val));\n                end\n                \n                % 检查方差\n                col_vars = var(data, 'omitnan');\n                zero_var_cols = sum(col_vars < 1e-10);\n                \n                if zero_var_cols > 0\n                    obj.Logger.Log('warning', sprintf('%d 个变量方差接近零', zero_var_cols));\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ValidateProcessedData');\n            end\n        end\n        \n        function ValidateDependentVariable(obj, y)\n            % 验证因变量\n            unique_vals = unique(y);\n            \n            % 检查值的范围\n            if any(y < 1) || any(y > 4)\n                error('因变量中存在异常值，请检查数据！');\n            end\n            \n            % 检查分布\n            value_counts = histcounts(y, 1:5);\n            obj.Logger.Log('info', sprintf('因变量分布: 1(%d), 2(%d), 3(%d), 4(%d)', value_counts));\n            \n            % 检查是否过于不平衡\n            min_count = min(value_counts);\n            max_count = max(value_counts);\n            \n            if min_count / max_count < 0.05\n                obj.Logger.Log('warning', '因变量分布极不平衡，可能影响模型性能');\n            end\n        end\n        \n        function [X_col, group_mean, var_name] = ProcessGroup(obj, data, group_cols, group_idx)\n            % 处理单个变量组\n            group_data = data(:, group_cols);\n            \n            % 标准化处理\n            group_data_std = zscore(group_data);\n            \n            % 计算标准化后的均值\n            X_col = mean(group_data_std, 2);\n            \n            % 存储原始均值（未标准化）\n            group_mean = mean(group_data, 2);\n            \n            % 生成变量名\n            var_name = sprintf('Group%d', group_idx);\n        end\n        \n        function ValidatePreparedVariables(obj, X, y)\n            % 验证准备好的变量\n            try\n                % 检查维度匹配\n                if size(X, 1) ~= length(y)\n                    error('自变量和因变量样本数不匹配');\n                end\n                \n                % 检查变量范围\n                if any(isnan(X(:))) || any(isinf(X(:)))\n                    obj.Logger.Log('warning', '自变量中存在NaN或Inf');\n                end\n                \n                % 检查相关性\n                try\n                    R = corr(X);\n                    if any(isnan(R(:))) || any(isinf(R(:)))\n                        obj.Logger.Log('warning', '相关矩阵计算有问题');\n                    end\n                catch\n                    obj.Logger.Log('warning', '无法计算相关矩阵');\n                end\n                \n                % 记录变量统计信息\n                var_stats = struct();\n                var_stats.mean = mean(X);\n                var_stats.std = std(X);\n                var_stats.min = min(X);\n                var_stats.max = max(X);\n                \n                obj.Logger.Log('debug', '变量统计信息验证完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ValidatePreparedVariables');\n            end\n        end\n        \n        function LogDataSummary(obj, summary)\n            % 记录数据摘要到日志\n            obj.Logger.Log('info', '=== 数据摘要 ===');\n            obj.Logger.Log('info', sprintf('数据维度: %d x %d', summary.dimensions(1), summary.dimensions(2)));\n            obj.Logger.Log('info', sprintf('缺失值: %d (%.2f%%)', summary.missing_count, summary.missing_percentage));\n            \n            % 记录基本统计\n            obj.Logger.Log('debug', '基本统计信息:');\n            mean_stats = summary.stats.mean;\n            std_stats = summary.stats.std;\n            \n            for i = 1:min(5, length(mean_stats))  % 只记录前5个变量\n                obj.Logger.Log('debug', sprintf('  变量 %d: 均值=%.2f, 标准差=%.2f', i, mean_stats(i), std_stats(i)));\n            end\n            \n            if length(mean_stats) > 5\n                obj.Logger.Log('debug', '  ... (更多变量统计信息省略)');\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "05929850-4fa4-4d66-9cf7-d755193a57e3"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "49bafb9f-7e5e-4422-8c09-520187d91b23"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:09:46.256096+00:00",
          "stop_timestamp": "2025-05-08T09:09:46.803365+00:00",
          "type": "text",
          "text": "\n\n## 第五部分：并行计算管理模块\n\n创建一个专门的并行计算管理类，优化性能和资源利用：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:09:46.986757+00:00",
          "stop_timestamp": "2025-05-08T09:10:29.326758+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-parallel-manager",
            "type": "application/vnd.ant.code",
            "title": "并行计算管理模块 - ParallelManager.m",
            "command": "create",
            "content": "classdef ParallelManager < handle\n    % 并行计算管理类：专门针对i9-9980HK优化的并行计算管理\n    % 包括并行池管理、任务分配和性能监控\n    \n    properties (Access = private)\n        Config\n        Logger\n        ParallelPool\n        ClusterProfile\n        PerformanceStats\n    end\n    \n    properties (Access = public)\n        IsInitialized = false\n        PoolSize\n        ThreadsPerWorker\n    end\n    \n    methods (Access = public)\n        function obj = ParallelManager(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.PerformanceStats = struct();\n            \n            if obj.Config.UseParallelComputing\n                obj.Initialize();\n            end\n        end\n        \n        function delete(obj)\n            % 析构函数：清理并行池\n            if obj.IsInitialized\n                obj.Cleanup();\n            end\n        end\n        \n        function Initialize(obj)\n            % 初始化并行计算环境\n            if obj.IsInitialized\n                obj.Logger.Log('info', '并行环境已初始化，跳过');\n                return;\n            end\n            \n            try\n                obj.Logger.Log('info', '正在初始化并行计算环境...');\n                \n                % 检查现有并行池\n                if ~isempty(gcp('nocreate'))\n                    obj.Logger.Log('info', '使用现有并行池');\n                    obj.ParallelPool = gcp;\n                    obj.PoolSize = obj.ParallelPool.NumWorkers;\n                    obj.ThreadsPerWorker = obj.ParallelPool.NumThreads;\n                else\n                    % 创建新的并行池\n                    obj.CreateParallelPool();\n                end\n                \n                % 配置并行环境\n                obj.ConfigureParallelEnvironment();\n                \n                % 初始化性能统计\n                obj.InitializePerformanceStats();\n                \n                obj.IsInitialized = true;\n                obj.Logger.Log('info', '并行计算环境初始化完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ParallelManager.Initialize');\n                rethrow(ME);\n            end\n        end\n        \n        function results = RunParallelTask(obj, taskFun, taskData, taskName)\n            % 运行并行任务\n            % 输入:\n            %   taskFun - 任务函数句柄\n            %   taskData - 任务数据\n            %   taskName - 任务名称（用于日志）\n            % 输出:\n            %   results - 任务结果\n            \n            if ~obj.IsInitialized\n                obj.Initialize();\n            end\n            \n            start_time = tic;\n            obj.Logger.Log('info', sprintf('开始并行任务: %s', taskName));\n            \n            try\n                % 记录任务开始\n                task_id = datestr(now, 'yyyymmdd_HHMMSS');\n                obj.PerformanceStats.tasks.(task_id) = struct();\n                obj.PerformanceStats.tasks.(task_id).name = taskName;\n                obj.PerformanceStats.tasks.(task_id).start_time = datetime('now');\n                \n                % 预分配结果\n                n_tasks = length(taskData);\n                results = cell(n_tasks, 1);\n                \n                % 创建进度监控\n                progress_interval = max(1, round(n_tasks / 20));\n                \n                % 使用parfor执行任务\n                parfor i = 1:n_tasks\n                    try\n                        results{i} = taskFun(taskData{i});\n                        \n                        % 定期报告进度\n                        if mod(i, progress_interval) == 0\n                            obj.Logger.LogProgress(i, n_tasks, sprintf('%s 进度', taskName));\n                        end\n                    catch task_error\n                        % 记录单个任务错误但不中断整体流程\n                        warning('Task %d failed: %s', i, task_error.message);\n                        results{i} = [];\n                    end\n                end\n                \n                % 记录任务完成\n                duration = toc(start_time);\n                obj.PerformanceStats.tasks.(task_id).duration = duration;\n                obj.PerformanceStats.tasks.(task_id).num_tasks = n_tasks;\n                obj.PerformanceStats.tasks.(task_id).throughput = n_tasks / duration;\n                \n                obj.Logger.LogPerformance(taskName, duration, sprintf('%d 个子任务', n_tasks));\n                \n            catch ME\n                obj.Logger.LogException(ME, sprintf('ParallelTask: %s', taskName));\n                rethrow(ME);\n            end\n        end\n        \n        function futures = RunAsyncTask(obj, taskFun, taskData, taskName)\n            % 运行异步任务\n            % 输入:\n            %   taskFun - 任务函数句柄\n            %   taskData - 任务数据\n            %   taskName - 任务名称\n            % 输出:\n            %   futures - 未来对象数组\n            \n            if ~obj.IsInitialized\n                obj.Initialize();\n            end\n            \n            obj.Logger.Log('info', sprintf('启动异步任务: %s', taskName));\n            \n            try\n                n_tasks = length(taskData);\n                futures = cell(n_tasks, 1);\n                \n                % 使用parfeval异步执行\n                for i = 1:n_tasks\n                    futures{i} = parfeval(@obj.ExecuteTask, 1, taskFun, taskData{i}, i);\n                end\n                \n                obj.Logger.Log('info', sprintf('异步任务启动完成，%d 个子任务', n_tasks));\n                \n            catch ME\n                obj.Logger.LogException(ME, sprintf('AsyncTask: %s', taskName));\n                rethrow(ME);\n            end\n        end\n        \n        function results = WaitForAsyncResults(obj, futures, taskName)\n            % 等待异步任务结果\n            % 输入:\n            %   futures - 未来对象数组\n            %   taskName - 任务名称\n            % 输出:\n            %   results - 任务结果\n            \n            obj.Logger.Log('info', sprintf('等待异步任务完成: %s', taskName));\n            \n            try\n                n_tasks = length(futures);\n                results = cell(n_tasks, 1);\n                completed = false(n_tasks, 1);\n                \n                % 监控进度\n                start_time = tic;\n                \n                while ~all(completed)\n                    for i = 1:n_tasks\n                        if ~completed(i) && strcmp(futures{i}.State, 'finished')\n                            results{i} = fetchOutputs(futures{i});\n                            completed(i) = true;\n                            \n                            % 报告进度\n                            progress = sum(completed) / n_tasks * 100;\n                            obj.Logger.LogProgress(sum(completed), n_tasks, sprintf('%s 收集结果', taskName));\n                        end\n                    end\n                    \n                    % 防止CPU占用过高\n                    pause(0.1);\n                end\n                \n                duration = toc(start_time);\n                obj.Logger.LogPerformance(sprintf('等待异步任务: %s', taskName), duration);\n                \n            catch ME\n                obj.Logger.LogException(ME, sprintf('WaitForAsyncResults: %s', taskName));\n                rethrow(ME);\n            end\n        end\n        \n        function Cleanup(obj)\n            % 清理并行环境\n            try\n                obj.Logger.Log('info', '正在清理并行环境...');\n                \n                % 记录并行性能统计\n                obj.LogPerformanceStats();\n                \n                % 清理临时目录\n                if exist(obj.Config.ParallelClusterJobStorageLocation, 'dir')\n                    rmdir(obj.Config.ParallelClusterJobStorageLocation, 's');\n                end\n                \n                % 关闭并行池\n                if ~isempty(obj.ParallelPool)\n                    delete(obj.ParallelPool);\n                    obj.ParallelPool = [];\n                end\n                \n                obj.IsInitialized = false;\n                obj.Logger.Log('info', '并行环境清理完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ParallelManager.Cleanup');\n            end\n        end\n        \n        function stats = GetPerformanceStats(obj)\n            % 获取并行性能统计信息\n            stats = obj.PerformanceStats;\n        end\n        \n        function opts = GetParallelOptions(obj)\n            % 获取并行选项配置\n            opts = statset('UseParallel', obj.IsInitialized, ...\n                'UseSubstreams', true, ...\n                'Display', 'off');\n        end\n    end\n    \n    methods (Access = private)\n        function CreateParallelPool(obj)\n            % 创建针对i9-9980HK优化的并行池\n            try\n                % 创建本地集群配置\n                obj.ClusterProfile = parcluster('local');\n                \n                % 设置工作器数量\n                obj.PoolSize = obj.Config.NumWorkers;\n                obj.ThreadsPerWorker = obj.Config.NumThreadsPerWorker;\n                \n                % 设置并行配置\n                obj.ClusterProfile.NumWorkers = obj.PoolSize;\n                obj.ClusterProfile.NumThreads = obj.ThreadsPerWorker;\n                \n                % 配置存储位置\n                obj.ClusterProfile.JobStorageLocation = obj.Config.ParallelClusterJobStorageLocation;\n                \n                % 优化并行池设置\n                obj.ClusterProfile.AdditionalProperties.ClusterMatlabRoot = matlabroot;\n                obj.ClusterProfile.AdditionalProperties.UseUniqueSubfolders = true;\n                \n                % 保存配置\n                obj.ClusterProfile.saveProfile;\n                \n                % 创建并行池\n                obj.ParallelPool = parpool(obj.ClusterProfile, obj.PoolSize);\n                \n                obj.Logger.Log('info', sprintf('创建并行池成功: %d workers x %d threads', ...\n                    obj.PoolSize, obj.ThreadsPerWorker));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateParallelPool');\n                rethrow(ME);\n            end\n        end\n        \n        function ConfigureParallelEnvironment(obj)\n            % 配置并行环境\n            try\n                % 设置并行池属性\n                obj.ParallelPool.AutoCreate = false;\n                obj.ParallelPool.IdleTimeout = 60;  % 60分钟空闲超时\n                \n                % 初始化工作器\n                spmd\n                    % 在每个工作器上设置随机数种子\n                    rng(42 + labindex, 'twister');\n                    \n                    % 设置警告级别\n                    warning('off', 'MATLAB:mir_warning_maybe_uninitialized_temporary');\n                end\n                \n                % 预热并行池（执行简单操作以初始化工作器）\n                obj.WarmupParallelPool();\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ConfigureParallelEnvironment');\n            end\n        end\n        \n        function WarmupParallelPool(obj)\n            % 预热并行池\n            obj.Logger.Log('debug', '正在预热并行池...');\n            \n            % 执行简单的并行操作\n            dummy_data = num2cell(1:obj.PoolSize);\n            \n            parfor i = 1:obj.PoolSize\n                % 简单的数学运算\n                result = sum(rand(1000, 1000));\n            end\n            \n            obj.Logger.Log('debug', '并行池预热完成');\n        end\n        \n        function InitializePerformanceStats(obj)\n            % 初始化性能统计\n            obj.PerformanceStats = struct();\n            obj.PerformanceStats.pool_creation_time = datetime('now');\n            obj.PerformanceStats.pool_size = obj.PoolSize;\n            obj.PerformanceStats.threads_per_worker = obj.ThreadsPerWorker;\n            obj.PerformanceStats.total_threads = obj.PoolSize * obj.ThreadsPerWorker;\n            obj.PerformanceStats.tasks = struct();\n            obj.PerformanceStats.memory_usage = struct();\n            obj.PerformanceStats.cpu_utilization = struct();\n        end\n        \n        function result = ExecuteTask(~, taskFun, taskData, taskIndex)\n            % 执行单个任务（用于parfeval）\n            try\n                result = taskFun(taskData);\n            catch ME\n                warning('Task %d failed: %s', taskIndex, ME.message);\n                result = [];\n            end\n        end\n        \n        function LogPerformanceStats(obj)\n            % 记录并行性能统计\n            obj.Logger.CreateSection('并行性能统计');\n            \n            stats = obj.PerformanceStats;\n            \n            % 基本信息\n            obj.Logger.Log('info', sprintf('并行池配置: %d workers x %d threads', ...\n                stats.pool_size, stats.threads_per_worker));\n            obj.Logger.Log('info', sprintf('总并行线程: %d', stats.total_threads));\n            \n            % 任务统计\n            task_names = fieldnames(stats.tasks);\n            if ~isempty(task_names)\n                obj.Logger.Log('info', sprintf('执行任务数: %d', length(task_names)));\n                \n                total_duration = 0;\n                total_tasks = 0;\n                \n                for i = 1:length(task_names)\n                    task = stats.tasks.(task_names{i});\n                    total_duration = total_duration + task.duration;\n                    total_tasks = total_tasks + task.num_tasks;\n                    \n                    obj.Logger.Log('debug', sprintf('  任务: %s', task.name));\n                    obj.Logger.Log('debug', sprintf('    持续时间: %.2f秒', task.duration));\n                    obj.Logger.Log('debug', sprintf('    子任务数: %d', task.num_tasks));\n                    obj.Logger.Log('debug', sprintf('    吞吐量: %.2f 任务/秒', task.throughput));\n                end\n                \n                avg_throughput = total_tasks / total_duration;\n                obj.Logger.Log('info', sprintf('平均吞吐量: %.2f 任务/秒', avg_throughput));\n            end\n            \n            % 估计的并行加速比\n            if total_duration > 0\n                estimated_sequential_time = total_tasks * (total_duration / (stats.total_threads * 0.8));  % 假设80%效率\n                speedup = estimated_sequential_time / total_duration;\n                obj.Logger.Log('info', sprintf('估计并行加速比: %.2fx', speedup));\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "6b80788f-f744-4a67-b417-467f7d8a51a2"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "80461eec-6081-42b9-8b88-22a59412e21e"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:10:30.646886+00:00",
          "stop_timestamp": "2025-05-08T09:10:31.076818+00:00",
          "type": "text",
          "text": "\n\n## 第六部分：GPU管理模块\n\n创建GPU管理模块，针对AMD GPU进行优化：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:10:31.267975+00:00",
          "stop_timestamp": "2025-05-08T09:11:12.035766+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-gpu-manager",
            "type": "application/vnd.ant.code",
            "title": "GPU管理模块 - GPUManager.m",
            "command": "create",
            "content": "classdef GPUManager < handle\n    % GPU管理类：专门针对AMD GPU的智能管理\n    % 自动检测数据大小，决定是否使用GPU加速\n    \n    properties (Access = private)\n        Config\n        Logger\n        GPUDevice\n        GPUMemoryInfo\n        GPUAvailable\n        TransferThreshold\n    end\n    \n    properties (Access = public)\n        IsInitialized = false\n        GPUEnabled = false\n        TransferCount = 0\n        GPUMemoryUsed = 0\n    end\n    \n    methods (Access = public)\n        function obj = GPUManager(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.TransferCount = 0;\n            obj.GPUMemoryUsed = 0;\n            \n            if obj.Config.UseGpu\n                obj.Initialize();\n            end\n        end\n        \n        function delete(obj)\n            % 析构函数：清理GPU内存\n            if obj.IsInitialized\n                obj.Cleanup();\n            end\n        end\n        \n        function Initialize(obj)\n            % 初始化GPU环境\n            if obj.IsInitialized\n                obj.Logger.Log('info', 'GPU环境已初始化，跳过');\n                return;\n            end\n            \n            try\n                obj.Logger.Log('info', '正在初始化GPU环境...');\n                \n                % 检查GPU可用性\n                obj.CheckGPUAvailability();\n                \n                if obj.GPUAvailable\n                    % 设置GPU设备\n                    obj.SetupGPUDevice();\n                    \n                    % 检查内存\n                    obj.CheckGPUMemory();\n                    \n                    % 设置数据传输阈值\n                    obj.SetTransferThreshold();\n                    \n                    obj.GPUEnabled = true;\n                    obj.Logger.Log('info', 'GPU环境初始化成功');\n                else\n                    obj.Logger.Log('warning', 'GPU不可用，将使用CPU计算');\n                end\n                \n                obj.IsInitialized = true;\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GPUManager.Initialize');\n                obj.GPUEnabled = false;\n                obj.IsInitialized = true;  % 即使失败也标记为已初始化\n            end\n        end\n        \n        function gpu_data = ToGPU(obj, data)\n            % 智能地将数据转移到GPU\n            % 输入:\n            %   data - 输入数据\n            % 输出:\n            %   gpu_data - GPU上的数据或原始数据\n            \n            if ~obj.GPUEnabled\n                gpu_data = data;\n                return;\n            end\n            \n            try\n                % 检查数据类型\n                if ~isnumeric(data)\n                    gpu_data = data;\n                    return;\n                end\n                \n                % 计算数据大小\n                data_size = numel(data) * 8;  % 假设是double类型\n                \n                % 决定是否使用GPU\n                if obj.ShouldUseGPU(data_size)\n                    % 检查GPU内存\n                    available_memory = obj.GPUDevice.AvailableMemory;\n                    \n                    if data_size < available_memory * 0.8  % 保留20%内存\n                        gpu_data = gpuArray(data);\n                        obj.TransferCount = obj.TransferCount + 1;\n                        obj.GPUMemoryUsed = obj.GPUMemoryUsed + data_size;\n                        \n                        obj.Logger.Log('debug', sprintf('数据转移到GPU: %.2f MB', data_size / (1024^2)));\n                    else\n                        obj.Logger.Log('warning', 'GPU内存不足，使用CPU计算');\n                        gpu_data = data;\n                    end\n                else\n                    gpu_data = data;\n                end\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('GPU转移失败: %s，使用CPU计算', ME.message));\n                gpu_data = data;\n            end\n        end\n        \n        function cpu_data = ToCPU(obj, gpu_data)\n            % 将数据从GPU转移回CPU\n            % 输入:\n            %   gpu_data - GPU上的数据\n            % 输出:\n            %   cpu_data - CPU上的数据\n            \n            if isa(gpu_data, 'gpuArray')\n                try\n                    cpu_data = gather(gpu_data);\n                    \n                    % 更新统计信息\n                    data_size = numel(cpu_data) * 8;\n                    obj.Logger.Log('debug', sprintf('数据从GPU转移到CPU: %.2f MB', data_size / (1024^2)));\n                    \n                catch ME\n                    obj.Logger.Log('warning', sprintf('GPU数据回传失败: %s', ME.message));\n                    cpu_data = gpu_data;  % 如果失败，返回原始数据\n                end\n            else\n                cpu_data = gpu_data;  % 如果不是GPU数据，直接返回\n            end\n        end\n        \n        function result = GPUCompute(obj, operation, data, varargin)\n            % 在GPU上执行计算操作\n            % 输入:\n            %   operation - 操作函数句柄\n            %   data - 输入数据\n            %   varargin - 额外参数\n            % 输出:\n            %   result - 计算结果\n            \n            if ~obj.GPUEnabled\n                result = operation(data, varargin{:});\n                return;\n            end\n            \n            try\n                % 将数据转移到GPU\n                gpu_data = obj.ToGPU(data);\n                \n                % 在GPU上执行操作\n                start_time = tic;\n                gpu_result = operation(gpu_data, varargin{:});\n                gpu_duration = toc(start_time);\n                \n                % 将结果转移回CPU\n                result = obj.ToCPU(gpu_result);\n                \n                obj.Logger.Log('debug', sprintf('GPU计算完成，耗时: %.4f秒', gpu_duration));\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('GPU计算失败: %s，回退到CPU', ME.message));\n                result = operation(data, varargin{:});\n            end\n        end\n        \n        function Cleanup(obj)\n            % 清理GPU资源\n            try\n                obj.Logger.Log('info', '正在清理GPU资源...');\n                \n                % 清理GPU内存\n                if obj.GPUEnabled\n                    gpuDevice([]);  % 清空GPU\n                    obj.Logger.Log('info', sprintf('GPU传输次数: %d', obj.TransferCount));\n                    obj.Logger.Log('info', sprintf('总GPU内存使用: %.2f MB', obj.GPUMemoryUsed / (1024^2)));\n                end\n                \n                obj.GPUEnabled = false;\n                obj.IsInitialized = false;\n                obj.Logger.Log('info', 'GPU资源清理完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GPUManager.Cleanup');\n            end\n        end\n        \n        function stats = GetGPUStats(obj)\n            % 获取GPU统计信息\n            stats = struct();\n            \n            if obj.GPUAvailable\n                stats.device = obj.GPUDevice;\n                stats.total_memory = obj.GPUDevice.TotalMemory;\n                stats.available_memory = obj.GPUDevice.AvailableMemory;\n                stats.used_memory = obj.GPUDevice.TotalMemory - obj.GPUDevice.AvailableMemory;\n                stats.memory_utilization = stats.used_memory / stats.total_memory * 100;\n                stats.transfer_count = obj.TransferCount;\n                stats.cumulative_transfer = obj.GPUMemoryUsed;\n            else\n                stats.device = 'None';\n                stats.available = false;\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function CheckGPUAvailability(obj)\n            % 检查GPU可用性\n            try\n                % 检查GPU函数是否存在\n                if exist('gpuArray', 'file') == 2 && gpuDeviceCount > 0\n                    obj.GPUAvailable = true;\n                    obj.Logger.Log('info', 'GPU可用');\n                else\n                    obj.GPUAvailable = false;\n                    obj.Logger.Log('info', 'GPU不可用');\n                end\n            catch ME\n                obj.GPUAvailable = false;\n                obj.Logger.Log('warning', sprintf('GPU检查失败: %s', ME.message));\n            end\n        end\n        \n        function SetupGPUDevice(obj)\n            % 设置GPU设备\n            try\n                % 获取GPU设备\n                obj.GPUDevice = gpuDevice();\n                \n                % 记录GPU信息\n                obj.Logger.Log('info', sprintf('GPU设备: %s', obj.GPUDevice.Name));\n                obj.Logger.Log('info', sprintf('计算能力: %s', obj.GPUDevice.ComputeCapability));\n                obj.Logger.Log('info', sprintf('总内存: %.2f GB', obj.GPUDevice.TotalMemory / 1e9));\n                obj.Logger.Log('info', sprintf('可用内存: %.2f GB', obj.GPUDevice.AvailableMemory / 1e9));\n                \n                % 重置GPU（清理之前的数据）\n                reset(obj.GPUDevice);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'SetupGPUDevice');\n                obj.GPUAvailable = false;\n            end\n        end\n        \n        function CheckGPUMemory(obj)\n            % 检查GPU内存状态\n            try\n                % 获取内存信息\n                obj.GPUMemoryInfo = struct();\n                obj.GPUMemoryInfo.total = obj.GPUDevice.TotalMemory;\n                obj.GPUMemoryInfo.available = obj.GPUDevice.AvailableMemory;\n                obj.GPUMemoryInfo.used = obj.GPUMemoryInfo.total - obj.GPUMemoryInfo.available;\n                obj.GPUMemoryInfo.utilization = obj.GPUMemoryInfo.used / obj.GPUMemoryInfo.total * 100;\n                \n                obj.Logger.Log('debug', sprintf('GPU内存使用率: %.1f%%', obj.GPUMemoryInfo.utilization));\n                \n                % 警告内存使用过高\n                if obj.GPUMemoryInfo.utilization > 80\n                    obj.Logger.Log('warning', 'GPU内存使用率超过80%');\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CheckGPUMemory');\n            end\n        end\n        \n        function SetTransferThreshold(obj)\n            % 设置数据传输阈值\n            % AMD GPU的传输开销相对较高，需要更高的阈值\n            \n            % 基础阈值\n            base_threshold = obj.Config.GpuMinDataSizeThreshold;\n            \n            % 根据GPU内存调整阈值\n            gpu_memory_gb = obj.GPUDevice.TotalMemory / 1e9;\n            \n            if gpu_memory_gb < 4\n                % 小内存GPU，增加阈值\n                obj.TransferThreshold = base_threshold * 2;\n            elseif gpu_memory_gb > 8\n                % 大内存GPU，可以降低阈值\n                obj.TransferThreshold = base_threshold * 0.5;\n            else\n                obj.TransferThreshold = base_threshold;\n            end\n            \n            obj.Logger.Log('debug', sprintf('GPU传输阈值设置为: %.2f MB', obj.TransferThreshold / (1024^2)));\n        end\n        \n        function should_use = ShouldUseGPU(obj, data_size)\n            % 决定是否应该使用GPU\n            % 输入:\n            %   data_size - 数据大小（字节）\n            % 输出:\n            %   should_use - 是否应该使用GPU\n            \n            % 检查基本条件\n            if ~obj.GPUEnabled || data_size < obj.TransferThreshold\n                should_use = false;\n                return;\n            end\n            \n            % 检查GPU内存限制\n            gpu_limit = obj.Config.GpuMemoryLimit * obj.GPUDevice.TotalMemory;\n            if data_size > gpu_limit\n                should_use = false;\n                return;\n            end\n            \n            % 检查当前GPU内存使用情况\n            obj.CheckGPUMemory();\n            required_memory = data_size * 1.5;  % 考虑操作需要的额外内存\n            \n            if required_memory > obj.GPUMemoryInfo.available\n                should_use = false;\n                return;\n            end\n            \n            % 对于特定操作类型的启发式判断\n            % AMD GPU在某些操作上性能可能不如预期\n            if data_size < 50 * 1024 * 1024  % 50MB\n                % 小数据集，传输开销可能大于收益\n                should_use = false;\n                return;\n            end\n            \n            should_use = true;\n        end\n        \n        function MonitorGPUPerformance(obj, operation_name, duration)\n            % 监控GPU操作性能\n            % 输入:\n            %   operation_name - 操作名称\n            %   duration - 操作耗时\n            \n            persistent perf_history;\n            if isempty(perf_history)\n                perf_history = struct();\n            end\n            \n            % 记录性能数据\n            if ~isfield(perf_history, operation_name)\n                perf_history.(operation_name) = [];\n            end\n            \n            perf_history.(operation_name) = [perf_history.(operation_name), duration];\n            \n            % 分析性能趋势\n            if length(perf_history.(operation_name)) > 10\n                recent_perf = perf_history.(operation_name)(end-9:end);\n                avg_perf = mean(recent_perf);\n                \n                obj.Logger.Log('debug', sprintf('GPU操作 %s 平均耗时: %.4f秒', operation_name, avg_perf));\n                \n                % 如果性能下降，提出警告\n                if length(perf_history.(operation_name)) > 20\n                    older_perf = mean(perf_history.(operation_name)(end-19:end-10));\n                    if avg_perf > older_perf * 1.5\n                        obj.Logger.Log('warning', sprintf('GPU操作 %s 性能下降', operation_name));\n                    end\n                end\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "35e6a03b-e88b-4308-a3a9-255f5b099830"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "ada475b2-9f01-49f6-a95d-6a1d1fa9fca9"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:11:12.308980+00:00",
          "stop_timestamp": "2025-05-08T09:11:12.308980+00:00",
          "type": "text",
          "text": "",
          "citations": []
        }
      ],
      "sender": "assistant",
      "index": 1,
      "created_at": "2025-05-08T09:11:12.365347+00:00",
      "updated_at": "2025-05-08T09:11:12.365347+00:00",
      "truncated": true,
      "stop_reason": "max_tokens",
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "3a0c7d3e-bceb-43e4-80da-eada71bb8b9a"
    },
    {
      "uuid": "ae4038cf-5785-4151-9969-477f3cb1c609",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T09:13:29.238291+00:00",
          "stop_timestamp": "2025-05-08T09:13:29.238291+00:00",
          "type": "text",
          "text": "Continue",
          "citations": []
        }
      ],
      "sender": "human",
      "index": 2,
      "created_at": "2025-05-08T09:13:29.241706+00:00",
      "updated_at": "2025-05-08T09:13:29.241706+00:00",
      "truncated": false,
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "928e78a8-786d-4dae-9b40-17b2dbb37cc4"
    },
    {
      "uuid": "0fc6b3b3-2ecf-4a51-aa80-03f0f5ea1d51",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T09:13:32.088903+00:00",
          "stop_timestamp": "2025-05-08T09:13:36.397201+00:00",
          "type": "thinking",
          "thinking": "用户让我继续发送优化后的代码。我已经完成了前六个部分的代码优化，包括：\n\n1. 配置管理模块 (BinomialConfig.m)\n2. 日志管理模块 (BinomialLogger.m)\n3. 主分析器类 (BinomialAnalyzer.m)\n4. 数据管理模块 (DataManager.m)\n5. 并行计算管理模块 (ParallelManager.m)\n6. GPU管理模块 (GPUManager.m)\n\n接下来我应该继续提供其他重要的功能模块，包括：\n\n7. 多重共线性检查模块\n8. 相关性分析模块\n9. Bootstrap采样模块\n10. 交叉验证模块\n11. 变量选择模块\n12. 系数稳定性监控模块\n13. 参数统计计算模块\n14. 变量贡献评估模块\n15. 残差分析模块\n16. 结果可视化模块\n17. 结果保存模块\n18. 报告生成模块\n19. 主程序入口优化\n\n我会继续按照模块化的方式组织这些代码。",
          "summaries": [
            {
              "summary": "Thinking about continuing an unspecified task or conversation"
            },
            {
              "summary": "Preparing to develop additional functional modules for project"
            },
            {
              "summary": "Mapped out comprehensive code optimization for advanced statistical module."
            }
          ],
          "cut_off": false
        },
        {
          "start_timestamp": "2025-05-08T09:13:36.558611+00:00",
          "stop_timestamp": "2025-05-08T09:13:36.892606+00:00",
          "type": "text",
          "text": "## 第七部分：多重共线性检查模块\n\n创建专门处理多重共线性检查的模块：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:13:37.099618+00:00",
          "stop_timestamp": "2025-05-08T09:14:43.273185+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-collinearity-checker",
            "type": "application/vnd.ant.code",
            "title": "多重共线性检查模块 - CollinearityChecker.m",
            "command": "create",
            "content": "classdef CollinearityChecker < handle\n    % 多重共线性检查器类：检测和处理变量间的多重共线性\n    % 使用多种方法：VIF、条件数、相关系数等\n    \n    properties (Access = private)\n        Config\n        Logger\n        Results\n    end\n    \n    methods (Access = public)\n        function obj = CollinearityChecker(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.Results = struct();\n        end\n        \n        function [X_cleaned, vif_values, removed_vars] = Check(obj, X, var_names)\n            % 执行多重共线性检查\n            % 输入:\n            %   X - 自变量矩阵\n            %   var_names - 变量名称\n            % 输出:\n            %   X_cleaned - 清理后的自变量矩阵\n            %   vif_values - VIF值\n            %   removed_vars - 被移除的变量标记\n            \n            obj.Logger.Log('info', '开始多重共线性检查');\n            \n            try\n                % 初始化结果\n                obj.Results.original_vars = var_names;\n                obj.Results.original_dim = size(X);\n                \n                % 1. 计算基本统计信息\n                obj.CalculateBasicStats(X, var_names);\n                \n                % 2. 计算相关矩阵\n                obj.CalculateCorrelationMatrix(X);\n                \n                % 3. 检查矩阵条件\n                obj.CheckMatrixCondition();\n                \n                % 4. 计算VIF值\n                vif_values = obj.CalculateVIF(X);\n                \n                % 5. 检测高相关变量对\n                obj.DetectHighCorrelationPairs();\n                \n                % 6. 处理多重共线性\n                [X_cleaned, removed_vars] = obj.HandleMulticollinearity(X, var_names, vif_values);\n                \n                % 7. 验证清理后的矩阵\n                obj.ValidateCleanedMatrix(X_cleaned);\n                \n                % 8. 生成报告\n                obj.GenerateCollinearityReport(var_names, removed_vars);\n                \n                obj.Logger.Log('info', sprintf('多重共线性检查完成，最终变量数: %d', size(X_cleaned, 2)));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CollinearityChecker.Check');\n                rethrow(ME);\n            end\n        end\n        \n        function results = GetResults(obj)\n            % 获取检查结果\n            results = obj.Results;\n        end\n        \n        function SaveResults(obj, output_dir)\n            % 保存检查结果\n            try\n                % 保存结果到mat文件\n                result_file = fullfile(output_dir, 'collinearity_results.mat');\n                results = obj.Results;\n                save(result_file, 'results', '-v7.3');\n                \n                % 保存VIF结果到CSV\n                if isfield(obj.Results, 'vif_table')\n                    csv_file = fullfile(output_dir, 'vif_values.csv');\n                    writetable(obj.Results.vif_table, csv_file);\n                end\n                \n                % 保存相关矩阵图\n                obj.SaveCorrelationHeatmap(output_dir);\n                \n                obj.Logger.Log('info', '多重共线性检查结果已保存');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CollinearityChecker.SaveResults');\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function CalculateBasicStats(obj, X, var_names)\n            % 计算基本统计信息\n            obj.Results.basic_stats = struct();\n            obj.Results.basic_stats.mean = mean(X);\n            obj.Results.basic_stats.std = std(X);\n            obj.Results.basic_stats.variance = var(X);\n            obj.Results.basic_stats.range = range(X);\n            \n            % 检查零方差变量\n            zero_var_idx = find(var(X) < 1e-10);\n            if ~isempty(zero_var_idx)\n                obj.Logger.Log('warning', sprintf('发现 %d 个零方差变量:', length(zero_var_idx)));\n                for i = 1:length(zero_var_idx)\n                    obj.Logger.Log('warning', sprintf('  - %s', var_names{zero_var_idx(i)}));\n                end\n            end\n            \n            obj.Results.basic_stats.zero_variance_vars = zero_var_idx;\n        end\n        \n        function CalculateCorrelationMatrix(obj, X)\n            % 计算相关矩阵\n            try\n                obj.Results.correlation_matrix = corr(X, 'Type', 'Pearson');\n                \n                % 处理可能出现的NaN\n                if any(isnan(obj.Results.correlation_matrix(:)))\n                    obj.Logger.Log('warning', '相关矩阵包含NaN值，使用Spearman相关系数重新计算');\n                    obj.Results.correlation_matrix = corr(X, 'Type', 'Spearman');\n                end\n                \n                % 计算平均相关系数\n                n_vars = size(X, 2);\n                upper_tri_idx = triu(true(n_vars), 1);\n                correlations = obj.Results.correlation_matrix(upper_tri_idx);\n                \n                obj.Results.avg_correlation = mean(abs(correlations));\n                obj.Results.max_correlation = max(abs(correlations));\n                \n                obj.Logger.Log('debug', sprintf('平均相关系数绝对值: %.3f', obj.Results.avg_correlation));\n                obj.Logger.Log('debug', sprintf('最大相关系数绝对值: %.3f', obj.Results.max_correlation));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CalculateCorrelationMatrix');\n                % 使用备用方法\n                obj.Results.correlation_matrix = eye(size(X, 2));\n            end\n        end\n        \n        function CheckMatrixCondition(obj)\n            % 检查矩阵条件数\n            try\n                R = obj.Results.correlation_matrix;\n                \n                % 计算条件数\n                obj.Results.condition_number = cond(R);\n                \n                % 计算特征值\n                eigenvalues = eig(R);\n                obj.Results.eigenvalues = eigenvalues;\n                obj.Results.min_eigenvalue = min(eigenvalues);\n                obj.Results.max_eigenvalue = max(eigenvalues);\n                \n                % 检查矩阵是否接近奇异\n                if obj.Results.condition_number > obj.Config.ConditionNumberThreshold\n                    obj.Logger.Log('warning', sprintf('相关矩阵条件数过高 (%.2f)，可能存在严重多重共线性', obj.Results.condition_number));\n                end\n                \n                if obj.Results.min_eigenvalue < 1e-10\n                    obj.Logger.Log('warning', '相关矩阵接近奇异，最小特征值接近零');\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CheckMatrixCondition');\n            end\n        end\n        \n        function vif_values = CalculateVIF(obj, X)\n            % 计算方差膨胀因子（VIF）\n            n_vars = size(X, 2);\n            vif_values = zeros(n_vars, 1);\n            \n            try\n                % 使用并行计算VIF\n                parfor i = 1:n_vars\n                    vif_values(i) = obj.CalculateSingleVIF(X, i);\n                end\n                \n                % 保存VIF结果\n                obj.Results.vif_values = vif_values;\n                \n                % 创建VIF表格\n                obj.Results.vif_table = table((1:n_vars)', vif_values, obj.Results.original_vars', ...\n                    'VariableNames', {'VariableIndex', 'VIF', 'VariableName'});\n                \n                % 按VIF值排序\n                obj.Results.vif_table = sortrows(obj.Results.vif_table, 'VIF', 'descend');\n                \n                % 记录VIF统计\n                obj.Logger.Log('info', sprintf('平均VIF: %.2f', mean(vif_values)));\n                obj.Logger.Log('info', sprintf('最大VIF: %.2f', max(vif_values)));\n                \n                % 记录高VIF变量\n                high_vif_idx = find(vif_values > obj.Config.VifThreshold);\n                if ~isempty(high_vif_idx)\n                    obj.Logger.Log('warning', sprintf('发现 %d 个高VIF变量:', length(high_vif_idx)));\n                    for i = 1:length(high_vif_idx)\n                        idx = high_vif_idx(i);\n                        obj.Logger.Log('warning', sprintf('  - %s: VIF = %.2f', ...\n                            obj.Results.original_vars{idx}, vif_values(idx)));\n                    end\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CalculateVIF');\n                % 使用备用方法\n                vif_values = ones(n_vars, 1);\n            end\n        end\n        \n        function vif = CalculateSingleVIF(~, X, var_index)\n            % 计算单个变量的VIF\n            try\n                % 选择其他变量作为自变量\n                other_idx = setdiff(1:size(X, 2), var_index);\n                X_other = X(:, other_idx);\n                y_target = X(:, var_index);\n                \n                % 执行线性回归\n                mdl = fitlm(X_other, y_target, 'Intercept', true);\n                \n                % 计算VIF\n                r_squared = mdl.Rsquared.Ordinary;\n                vif = 1 / (1 - r_squared);\n                \n                % 处理特殊情况\n                if isinf(vif) || isnan(vif)\n                    vif = 1000;  % 设置一个大值表示严重共线性\n                end\n                \n            catch\n                % 计算失败，返回默认值\n                vif = 1;\n            end\n        end\n        \n        function DetectHighCorrelationPairs(obj)\n            % 检测高相关变量对\n            try\n                R = obj.Results.correlation_matrix;\n                n_vars = size(R, 1);\n                \n                % 找出高相关变量对\n                high_corr_pairs = [];\n                threshold = 0.8;  % 相关系数阈值\n                \n                for i = 1:n_vars-1\n                    for j = i+1:n_vars\n                        if abs(R(i, j)) > threshold\n                            high_corr_pairs = [high_corr_pairs; i, j, R(i, j)];\n                        end\n                    end\n                end\n                \n                obj.Results.high_correlation_pairs = high_corr_pairs;\n                \n                if ~isempty(high_corr_pairs)\n                    obj.Logger.Log('warning', sprintf('发现 %d 个高相关变量对 (|r| > %.2f):', ...\n                        size(high_corr_pairs, 1), threshold));\n                    \n                    for i = 1:size(high_corr_pairs, 1)\n                        var1_idx = high_corr_pairs(i, 1);\n                        var2_idx = high_corr_pairs(i, 2);\n                        corr_val = high_corr_pairs(i, 3);\n                        \n                        obj.Logger.Log('warning', sprintf('  - %s 与 %s: r = %.3f', ...\n                            obj.Results.original_vars{var1_idx}, ...\n                            obj.Results.original_vars{var2_idx}, ...\n                            corr_val));\n                    end\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'DetectHighCorrelationPairs');\n            end\n        end\n        \n        function [X_cleaned, removed_vars] = HandleMulticollinearity(obj, X, var_names, vif_values)\n            % 处理多重共线性\n            removed_vars = false(size(X, 2), 1);\n            X_cleaned = X;\n            \n            try\n                % 检查是否需要使用PCA\n                if obj.Results.condition_number > obj.Config.ConditionNumberThreshold * 2\n                    obj.Logger.Log('warning', '检测到严重多重共线性，使用PCA处理');\n                    [X_cleaned, removed_vars] = obj.ApplyPCA(X);\n                    return;\n                end\n                \n                % 逐步移除高VIF变量\n                [X_cleaned, removed_vars] = obj.RemoveHighVIFVariables(X, var_names, vif_values);\n                \n                % 递归检查剩余变量\n                if sum(removed_vars) > 0 && sum(~removed_vars) > 1\n                    obj.Logger.Log('info', '递归检查剩余变量的VIF值');\n                    [X_cleaned_rec, removed_vars_rec] = obj.RecursiveCheck(X_cleaned, var_names(~removed_vars));\n                    \n                    % 更新removed_vars\n                    still_removed = false(size(X, 2), 1);\n                    still_removed(~removed_vars) = removed_vars_rec;\n                    removed_vars = removed_vars | still_removed;\n                    X_cleaned = X_cleaned_rec;\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'HandleMulticollinearity');\n                % 如果失败，使用原始数据\n                X_cleaned = X;\n                removed_vars = false(size(X, 2), 1);\n            end\n        end\n        \n        function [X_cleaned, removed_vars] = RemoveHighVIFVariables(obj, X, var_names, vif_values)\n            % 移除高VIF变量\n            removed_vars = false(size(X, 2), 1);\n            X_cleaned = X;\n            \n            while true\n                % 找出最高VIF值\n                [max_vif, max_idx] = max(vif_values);\n                \n                if max_vif <= obj.Config.VifThreshold\n                    break;  % 所有变量VIF都在阈值内\n                end\n                \n                % 标记移除该变量\n                removed_vars(max_idx) = true;\n                \n                obj.Logger.Log('info', sprintf('移除变量: %s (VIF = %.2f)', var_names{max_idx}, max_vif));\n                \n                % 更新数据\n                X_cleaned = X_cleaned(:, ~removed_vars);\n                \n                if size(X_cleaned, 2) < 2\n                    obj.Logger.Log('warning', '移除变量导致剩余变量过少，停止移除');\n                    break;\n                end\n                \n                % 重新计算VIF\n                vif_values_new = obj.CalculateVIF(X_cleaned);\n                \n                % 更新原始VIF向量\n                temp_vif = zeros(size(vif_values));\n                temp_vif(~removed_vars) = vif_values_new;\n                vif_values = temp_vif;\n            end\n        end\n        \n        function [X_pca, removed_vars] = ApplyPCA(obj, X)\n            % 使用主成分分析处理多重共线性\n            try\n                obj.Logger.Log('info', '开始PCA降维处理');\n                \n                % 执行PCA\n                [coeff, score, ~, ~, explained, mu] = pca(X, 'Algorithm', 'svd');\n                \n                % 确定保留的主成分数量\n                cum_var = cumsum(explained);\n                n_components = find(cum_var >= obj.Config.PcaVarianceThreshold, 1, 'first');\n                \n                if isempty(n_components)\n                    n_components = size(X, 2);  % 保留所有成分\n                end\n                \n                % 选择主成分\n                X_pca = score(:, 1:n_components);\n                \n                % 记录PCA结果\n                obj.Results.pca_results = struct();\n                obj.Results.pca_results.coefficients = coeff;\n                obj.Results.pca_results.explained_variance = explained;\n                obj.Results.pca_results.cumulative_variance = cum_var;\n                obj.Results.pca_results.n_components = n_components;\n                obj.Results.pca_results.variance_threshold = obj.Config.PcaVarianceThreshold;\n                \n                obj.Logger.Log('info', sprintf('PCA降维完成：从 %d 个变量降至 %d 个主成分', ...\n                    size(X, 2), n_components));\n                obj.Logger.Log('info', sprintf('保留 %.1f%% 的方差', cum_var(n_components)));\n                \n                % 所有原始变量都被\"移除\"（转换为主成分）\n                removed_vars = true(size(X, 2), 1);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ApplyPCA');\n                % 如果PCA失败，返回原始数据\n                X_pca = X;\n                removed_vars = false(size(X, 2), 1);\n            end\n        end\n        \n        function [X_cleaned, removed_vars] = RecursiveCheck(obj, X, var_names)\n            % 递归检查多重共线性\n            n_iterations = 0;\n            max_iterations = 10;  % 防止无限循环\n            \n            removed_vars = false(size(X, 2), 1);\n            X_cleaned = X;\n            \n            while n_iterations < max_iterations\n                n_iterations = n_iterations + 1;\n                \n                % 计算VIF\n                vif_values = obj.CalculateVIF(X_cleaned);\n                \n                % 检查是否还有高VIF变量\n                high_vif_idx = find(vif_values > obj.Config.VifThreshold);\n                \n                if isempty(high_vif_idx)\n                    break;  % 没有高VIF变量了\n                end\n                \n                % 移除VIF最高的变量\n                [~, remove_idx] = max(vif_values);\n                \n                obj.Logger.Log('debug', sprintf('递归检查第 %d 轮：移除 %s (VIF = %.2f)', ...\n                    n_iterations, var_names{remove_idx}, vif_values(remove_idx)));\n                \n                % 更新标记\n                removed_vars(remove_idx) = true;\n                \n                % 更新数据\n                X_cleaned = X_cleaned(:, ~removed_vars);\n                var_names = var_names(~removed_vars);\n                \n                if size(X_cleaned, 2) < 2\n                    obj.Logger.Log('warning', '递归检查导致剩余变量过少，停止检查');\n                    break;\n                end\n            end\n            \n            if n_iterations >= max_iterations\n                obj.Logger.Log('warning', '递归检查达到最大迭代次数，可能仍存在共线性');\n            end\n        end\n        \n        function ValidateCleanedMatrix(obj, X_cleaned)\n            % 验证清理后的矩阵\n            try\n                % 检查维度\n                if size(X_cleaned, 2) < 1\n                    obj.Logger.Log('error', '清理后没有剩余变量');\n                    return;\n                end\n                \n                % 检查相关矩阵条件数\n                try\n                    R_cleaned = corr(X_cleaned);\n                    cond_num_cleaned = cond(R_cleaned);\n                    \n                    obj.Logger.Log('info', sprintf('清理后相关矩阵条件数: %.2f', cond_num_cleaned));\n                    \n                    if cond_num_cleaned > obj.Config.ConditionNumberThreshold\n                        obj.Logger.Log('warning', '清理后仍存在多重共线性问题');\n                    end\n                catch\n                    obj.Logger.Log('warning', '无法计算清理后矩阵的条件数');\n                end\n                \n                % 检查方差\n                variances = var(X_cleaned);\n                if any(variances < 1e-10)\n                    obj.Logger.Log('warning', '清理后存在零方差变量');\n                end\n                \n                % 保存验证结果\n                obj.Results.validation = struct();\n                obj.Results.validation.final_variables = size(X_cleaned, 2);\n                obj.Results.validation.condition_number_final = cond_num_cleaned;\n                obj.Results.validation.min_variance = min(variances);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ValidateCleanedMatrix');\n            end\n        end\n        \n        function GenerateCollinearityReport(obj, var_names, removed_vars)\n            % 生成多重共线性报告\n            try\n                % 创建报告结构\n                report = struct();\n                report.original_variables = length(var_names);\n                report.removed_variables = sum(removed_vars);\n                report.final_variables = sum(~removed_vars);\n                report.removal_rate = report.removed_variables / report.original_variables * 100;\n                \n                % 添加详细信息\n                if ~isempty(removed_vars)\n                    report.removed_variable_names = var_names(removed_vars);\n                    report.kept_variable_names = var_names(~removed_vars);\n                end\n                \n                % 添加统计信息\n                report.original_condition_number = obj.Results.condition_number;\n                if isfield(obj.Results, 'validation')\n                    report.final_condition_number = obj.Results.validation.condition_number_final;\n                end\n                \n                % 添加VIF信息\n                if isfield(obj.Results, 'vif_values')\n                    report.max_original_vif = max(obj.Results.vif_values);\n                    report.avg_original_vif = mean(obj.Results.vif_values);\n                end\n                \n                % 保存报告\n                obj.Results.report = report;\n                \n                % 记录摘要信息\n                obj.Logger.Log('info', '=== 多重共线性检查报告 ===');\n                obj.Logger.Log('info', sprintf('原始变量数: %d', report.original_variables));\n                obj.Logger.Log('info', sprintf('移除变量数: %d', report.removed_variables));\n                obj.Logger.Log('info', sprintf('最终变量数: %d', report.final_variables));\n                obj.Logger.Log('info', sprintf('移除率: %.1f%%', report.removal_rate));\n                \n                if isfield(report, 'removed_variable_names') && ~isempty(report.removed_variable_names)\n                    obj.Logger.Log('info', '移除的变量:');\n                    for i = 1:length(report.removed_variable_names)\n                        obj.Logger.Log('info', sprintf('  - %s', report.removed_variable_names{i}));\n                    end\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GenerateCollinearityReport');\n            end\n        end\n        \n        function SaveCorrelationHeatmap(obj, output_dir)\n            % 保存相关矩阵热图\n            try\n                if isfield(obj.Results, 'correlation_matrix')\n                    fig = figure('Visible', 'off');\n                    imagesc(obj.Results.correlation_matrix, [-1, 1]);\n                    colorbar;\n                    colormap('RdBu_r');\n                    \n                    title('变量相关性矩阵');\n                    xlabel('变量');\n                    ylabel('变量');\n                    \n                    % 添加变量名标签\n                    if length(obj.Results.original_vars) <= 20\n                        set(gca, 'XTick', 1:length(obj.Results.original_vars), ...\n                            'XTickLabel', obj.Results.original_vars, ...\n                            'XTickLabelRotation', 45);\n                        set(gca, 'YTick', 1:length(obj.Results.original_vars), ...\n                            'YTickLabel', obj.Results.original_vars);\n                    end\n                    \n                    % 保存图形\n                    saveas(fig, fullfile(output_dir, 'correlation_heatmap.png'), 'png');\n                    saveas(fig, fullfile(output_dir, 'correlation_heatmap.svg'), 'svg');\n                    \n                    close(fig);\n                    obj.Logger.Log('info', '相关矩阵热图已保存');\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'SaveCorrelationHeatmap');\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "bfaa00db-15a7-471f-acb4-f77ba2c457af"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "d3d1b77f-c063-4847-bd15-0051912d8576"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:14:44.909624+00:00",
          "stop_timestamp": "2025-05-08T09:14:45.688132+00:00",
          "type": "text",
          "text": "\n\n## 第八部分：相关性分析模块\n\n创建变量相关性分析模块，包含PCA等高级分析：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:14:45.750417+00:00",
          "stop_timestamp": "2025-05-08T09:16:18.014988+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-correlation-analyzer",
            "type": "application/vnd.ant.code",
            "title": "相关性分析模块 - CorrelationAnalyzer.m",
            "command": "create",
            "content": "classdef CorrelationAnalyzer < handle\n    % 相关性分析器类：执行变量间的相关性分析\n    % 包括主成分分析、偏相关分析等\n    \n    properties (Access = private)\n        Config\n        Logger\n        Results\n    end\n    \n    methods (Access = public)\n        function obj = CorrelationAnalyzer(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.Results = struct();\n        end\n        \n        function pca_results = Analyze(obj, X, var_names)\n            % 执行相关性分析\n            % 输入:\n            %   X - 自变量矩阵\n            %   var_names - 变量名称\n            % 输出:\n            %   pca_results - PCA分析结果\n            \n            obj.Logger.Log('info', '开始相关性分析');\n            \n            try\n                % 1. 计算基本相关性\n                obj.CalculateBasicCorrelations(X, var_names);\n                \n                % 2. 执行主成分分析\n                pca_results = obj.PerformPCA(X, var_names);\n                \n                % 3. 计算偏相关系数\n                obj.CalculatePartialCorrelations(X, var_names);\n                \n                % 4. 因子分析\n                obj.PerformFactorAnalysis(X, var_names);\n                \n                % 5. 聚类分析\n                obj.PerformVariableClustering(X, var_names);\n                \n                % 6. 创建可视化\n                obj.CreateVisualizations();\n                \n                % 7. 生成分析报告\n                obj.GenerateAnalysisReport();\n                \n                obj.Logger.Log('info', '相关性分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CorrelationAnalyzer.Analyze');\n                rethrow(ME);\n            end\n        end\n        \n        function results = GetResults(obj)\n            % 获取分析结果\n            results = obj.Results;\n        end\n    end\n    \n    methods (Access = private)\n        function CalculateBasicCorrelations(obj, X, var_names)\n            % 计算基本相关性\n            try\n                obj.Logger.Log('debug', '计算基本相关性');\n                \n                % 计算Pearson相关系数\n                [R_pearson, P_pearson] = corr(X, 'Type', 'Pearson');\n                \n                % 计算Spearman相关系数\n                [R_spearman, P_spearman] = corr(X, 'Type', 'Spearman');\n                \n                % 计算Kendall相关系数\n                try\n                    [R_kendall, P_kendall] = corr(X, 'Type', 'Kendall');\n                catch\n                    obj.Logger.Log('warning', 'Kendall相关系数计算失败，跳过');\n                    R_kendall = [];\n                    P_kendall = [];\n                end\n                \n                % 保存结果\n                obj.Results.correlations = struct();\n                obj.Results.correlations.pearson = R_pearson;\n                obj.Results.correlations.pearson_pvalues = P_pearson;\n                obj.Results.correlations.spearman = R_spearman;\n                obj.Results.correlations.spearman_pvalues = P_spearman;\n                obj.Results.correlations.kendall = R_kendall;\n                obj.Results.correlations.kendall_pvalues = P_kendall;\n                \n                % 创建相关性汇总\n                obj.CreateCorrelationSummary(var_names);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CalculateBasicCorrelations');\n            end\n        end\n        \n        function CreateCorrelationSummary(obj, var_names)\n            % 创建相关性汇总\n            try\n                R = obj.Results.correlations.pearson;\n                n_vars = size(R, 1);\n                \n                % 创建上三角矩阵索引\n                upper_tri = triu(true(n_vars), 1);\n                \n                % 提取相关系数\n                correlations = R(upper_tri);\n                \n                % 计算统计信息\n                summary = struct();\n                summary.mean_correlation = mean(abs(correlations));\n                summary.median_correlation = median(abs(correlations));\n                summary.max_correlation = max(abs(correlations));\n                summary.min_correlation = min(abs(correlations));\n                summary.std_correlation = std(abs(correlations));\n                \n                % 找出高相关变量对\n                threshold = 0.7;\n                high_corr_pairs = [];\n                \n                for i = 1:n_vars-1\n                    for j = i+1:n_vars\n                        if abs(R(i, j)) > threshold\n                            high_corr_pairs = [high_corr_pairs; ...\n                                {var_names{i}, var_names{j}, R(i, j), abs(R(i, j))}];\n                        end\n                    end\n                end\n                \n                % 保存高相关对\n                if ~isempty(high_corr_pairs)\n                    summary.high_correlation_pairs = cell2table(high_corr_pairs, ...\n                        'VariableNames', {'Variable1', 'Variable2', 'Correlation', 'AbsCorrelation'});\n                    summary.high_correlation_pairs = sortrows(summary.high_correlation_pairs, ...\n                        'AbsCorrelation', 'descend');\n                else\n                    summary.high_correlation_pairs = table();\n                end\n                \n                obj.Results.correlation_summary = summary;\n                \n                % 记录统计信息\n                obj.Logger.Log('info', sprintf('相关性统计：平均=%.3f, 最大=%.3f, 标准差=%.3f', ...\n                    summary.mean_correlation, summary.max_correlation, summary.std_correlation));\n                \n                if height(summary.high_correlation_pairs) > 0\n                    obj.Logger.Log('info', sprintf('发现 %d 对高相关变量 (|r| > %.2f)', ...\n                        height(summary.high_correlation_pairs), threshold));\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateCorrelationSummary');\n            end\n        end\n        \n        function pca_results = PerformPCA(obj, X, var_names)\n            % 执行主成分分析\n            try\n                obj.Logger.Log('debug', '开始主成分分析');\n                \n                % 执行PCA\n                [coeff, score, latent, tsquared, explained, mu] = pca(X, ...\n                    'Algorithm', 'svd', 'VariableWeights', 'variance');\n                \n                % 保存PCA结果\n                pca_results = struct();\n                pca_results.coefficients = coeff;\n                pca_results.scores = score;\n                pca_results.latent = latent;\n                pca_results.tsquared = tsquared;\n                pca_results.explained = explained;\n                pca_results.mu = mu;\n                pca_results.cumulative_variance = cumsum(explained);\n                \n                % 确定保留的主成分数量\n                pca_results.n_components = struct();\n                pca_results.n_components.kaiser = sum(latent > 1);  % Kaiser准则\n                pca_results.n_components.variance_80 = find(pca_results.cumulative_variance >= 80, 1, 'first');\n                pca_results.n_components.variance_90 = find(pca_results.cumulative_variance >= 90, 1, 'first');\n                pca_results.n_components.variance_95 = find(pca_results.cumulative_variance >= 95, 1, 'first');\n                \n                % 计算变量载荷\n                loadings = coeff .* sqrt(latent)';\n                pca_results.loadings = loadings;\n                \n                % 创建PCA解释表\n                pca_table = table((1:length(explained))', explained, pca_results.cumulative_variance, ...\n                    'VariableNames', {'Component', 'ExplainedVariance', 'CumulativeVariance'});\n                pca_results.variance_table = pca_table;\n                \n                % 创建变量贡献表\n                contribution_table = table(var_names, abs(loadings(:, 1)), abs(loadings(:, 2)), ...\n                    'VariableNames', {'Variable', 'PC1_Loading', 'PC2_Loading'});\n                contribution_table = sortrows(contribution_table, 'PC1_Loading', 'descend');\n                pca_results.contribution_table = contribution_table;\n                \n                % 保存到主结果\n                obj.Results.pca = pca_results;\n                \n                % 记录PCA统计信息\n                obj.Logger.Log('info', sprintf('PCA分析完成：'));\n                obj.Logger.Log('info', sprintf('  - Kaiser准则建议保留 %d 个主成分', pca_results.n_components.kaiser));\n                obj.Logger.Log('info', sprintf('  - 前 %d 个主成分解释了 80%% 的方差', pca_results.n_components.variance_80));\n                obj.Logger.Log('info', sprintf('  - 前 %d 个主成分解释了 90%% 的方差', pca_results.n_components.variance_90));\n                obj.Logger.Log('info', sprintf('  - 前 %d 个主成分解释了 95%% 的方差', pca_results.n_components.variance_95));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PerformPCA');\n                pca_results = struct();\n            end\n        end\n        \n        function CalculatePartialCorrelations(obj, X, var_names)\n            % 计算偏相关系数\n            try\n                obj.Logger.Log('debug', '计算偏相关系数');\n                \n                n_vars = size(X, 2);\n                partial_corr = zeros(n_vars, n_vars);\n                partial_pval = ones(n_vars, n_vars);\n                \n                % 计算每对变量的偏相关\n                for i = 1:n_vars\n                    for j = i+1:n_vars\n                        % 选择控制变量\n                        control_vars = setdiff(1:n_vars, [i, j]);\n                        \n                        if ~isempty(control_vars)\n                            % 计算偏相关\n                            [rho, pval] = obj.CalculatePartialCorr(X(:, i), X(:, j), X(:, control_vars));\n                            partial_corr(i, j) = rho;\n                            partial_corr(j, i) = rho;\n                            partial_pval(i, j) = pval;\n                            partial_pval(j, i) = pval;\n                        else\n                            % 如果没有控制变量，使用简单相关\n                            [rho, pval] = corr(X(:, i), X(:, j));\n                            partial_corr(i, j) = rho;\n                            partial_corr(j, i) = rho;\n                            partial_pval(i, j) = pval;\n                            partial_pval(j, i) = pval;\n                        end\n                    end\n                end\n                \n                % 对角线设为1\n                partial_corr(eye(n_vars) == 1) = 1;\n                partial_pval(eye(n_vars) == 1) = 0;\n                \n                % 保存结果\n                obj.Results.partial_correlations = struct();\n                obj.Results.partial_correlations.matrix = partial_corr;\n                obj.Results.partial_correlations.pvalues = partial_pval;\n                \n                % 创建偏相关汇总\n                obj.CreatePartialCorrelationSummary(partial_corr, var_names);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CalculatePartialCorrelations');\n            end\n        end\n        \n        function [rho, pval] = CalculatePartialCorr(~, x, y, z)\n            % 计算单个偏相关系数\n            try\n                % 回归残差法\n                if size(z, 2) > 0\n                    % 对x和y分别回归z\n                    mdl_x = fitlm(z, x);\n                    mdl_y = fitlm(z, y);\n                    \n                    % 获取残差\n                    res_x = mdl_x.Residuals.Raw;\n                    res_y = mdl_y.Residuals.Raw;\n                    \n                    % 计算残差间的相关\n                    [rho, pval] = corr(res_x, res_y);\n                else\n                    % 如果没有控制变量，使用简单相关\n                    [rho, pval] = corr(x, y);\n                end\n                \n                % 处理特殊情况\n                if isnan(rho)\n                    rho = 0;\n                    pval = 1;\n                end\n                \n            catch\n                rho = 0;\n                pval = 1;\n            end\n        end\n        \n        function CreatePartialCorrelationSummary(obj, partial_corr, var_names)\n            % 创建偏相关汇总\n            try\n                n_vars = size(partial_corr, 1);\n                upper_tri = triu(true(n_vars), 1);\n                correlations = partial_corr(upper_tri);\n                \n                % 计算统计信息\n                summary = struct();\n                summary.mean_partial_correlation = mean(abs(correlations));\n                summary.median_partial_correlation = median(abs(correlations));\n                summary.max_partial_correlation = max(abs(correlations));\n                summary.min_partial_correlation = min(abs(correlations));\n                \n                % 对比简单相关和偏相关\n                simple_corr = obj.Results.correlations.pearson;\n                simple_correlations = simple_corr(upper_tri);\n                \n                summary.correlation_difference = mean(abs(simple_correlations) - abs(correlations));\n                \n                obj.Results.partial_correlation_summary = summary;\n                \n                obj.Logger.Log('info', sprintf('偏相关分析：平均=%.3f, 最大=%.3f', ...\n                    summary.mean_partial_correlation, summary.max_partial_correlation));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreatePartialCorrelationSummary');\n            end\n        end\n        \n        function PerformFactorAnalysis(obj, X, var_names)\n            % 执行因子分析\n            try\n                obj.Logger.Log('debug', '执行因子分析');\n                \n                % 确定因子数量\n                n_factors = obj.DetermineFactorNumber(X);\n                \n                % 执行因子分析\n                [lambda, psi, T, stats, F] = factoran(X, n_factors, 'rotate', 'varimax');\n                \n                % 保存结果\n                factor_results = struct();\n                factor_results.n_factors = n_factors;\n                factor_results.loadings = lambda;\n                factor_results.specific_var = psi;\n                factor_results.rotation_matrix = T;\n                factor_results.stats = stats;\n                factor_results.scores = F;\n                \n                % 计算因子解释的方差\n                factor_results.variance_explained = sum(lambda.^2, 1);\n                factor_results.proportion_explained = factor_results.variance_explained / sum(factor_results.variance_explained);\n                factor_results.cumulative_proportion = cumsum(factor_results.proportion_explained);\n                \n                % 创建因子载荷表\n                loading_table = array2table([var_names, num2cell(lambda)]);\n                loading_table.Properties.VariableNames = ['Variable', ...\n                    cellfun(@(x) sprintf('Factor%d', x), num2cell(1:n_factors), 'UniformOutput', false)];\n                factor_results.loading_table = loading_table;\n                \n                obj.Results.factor_analysis = factor_results;\n                \n                obj.Logger.Log('info', sprintf('因子分析完成：提取 %d 个因子', n_factors));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PerformFactorAnalysis');\n                obj.Results.factor_analysis = struct();\n            end\n        end\n        \n        function n_factors = DetermineFactorNumber(obj, X)\n            % 确定因子数量\n            try\n                % 使用特征值准则\n                R = corr(X);\n                eigenvalues = eig(R);\n                n_factors_eigen = sum(eigenvalues > 1);\n                \n                % 使用碎石图准则\n                diff_eigenvalues = diff(eigenvalues);\n                diff_diff = diff(diff_eigenvalues);\n                [~, elbow_idx] = max(abs(diff_diff));\n                n_factors_scree = length(eigenvalues) - elbow_idx - 1;\n                \n                % 使用解释方差准则\n                explained_var = cumsum(eigenvalues) / sum(eigenvalues) * 100;\n                n_factors_var80 = find(explained_var >= 80, 1, 'first');\n                n_factors_var90 = find(explained_var >= 90, 1, 'first');\n                \n                % 综合决策\n                n_factors = min([n_factors_eigen, n_factors_scree, n_factors_var80]);\n                \n                obj.Logger.Log('debug', sprintf('因子数量建议：特征值准则=%d, 碎石图准则=%d, 方差准则80%%=%d', ...\n                    n_factors_eigen, n_factors_scree, n_factors_var80));\n                \n                % 确保最小和最大值\n                n_factors = max(1, min(n_factors, size(X, 2) - 1));\n                \n            catch\n                % 如果失败，使用默认值\n                n_factors = min(3, size(X, 2) - 1);\n            end\n        end\n        \n        function PerformVariableClustering(obj, X, var_names)\n            % 执行变量聚类分析\n            try\n                obj.Logger.Log('debug', '执行变量聚类分析');\n                \n                % 使用相关系数作为距离度量\n                R = obj.Results.correlations.pearson;\n                D = 1 - abs(R);  % 将相关系数转换为距离\n                \n                % 执行层次聚类\n                Z = linkage(squareform(D), 'average');\n                \n                % 确定聚类数量\n                n_clusters = obj.DetermineClusterNumber(Z, var_names);\n                \n                % 获取聚类结果\n                clusters = cluster(Z, 'maxclust', n_clusters);\n                \n                % 保存结果\n                clustering_results = struct();\n                clustering_results.n_clusters = n_clusters;\n                clustering_results.linkage_matrix = Z;\n                clustering_results.cluster_assignments = clusters;\n                clustering_results.distance_matrix = D;\n                \n                % 创建聚类结果表\n                cluster_table = table(var_names, clusters, ...\n                    'VariableNames', {'Variable', 'Cluster'});\n                cluster_table = sortrows(cluster_table, 'Cluster');\n                clustering_results.cluster_table = cluster_table;\n                \n                % 分析每个聚类\n                cluster_stats = [];\n                for i = 1:n_clusters\n                    cluster_vars = var_names(clusters == i);\n                    cluster_size = length(cluster_vars);\n                    \n                    % 计算聚类内相关性\n                    if cluster_size > 1\n                        cluster_idx = clusters == i;\n                        cluster_corr = R(cluster_idx, cluster_idx);\n                        avg_corr = mean(cluster_corr(triu(true(cluster_size), 1)));\n                    else\n                        avg_corr = 1;\n                    end\n                    \n                    cluster_stats = [cluster_stats; i, cluster_size, avg_corr];\n                end\n                \n                clustering_results.cluster_stats = array2table(cluster_stats, ...\n                    'VariableNames', {'Cluster', 'Size', 'AvgIntraCorrelation'});\n                \n                obj.Results.variable_clustering = clustering_results;\n                \n                obj.Logger.Log('info', sprintf('变量聚类完成：识别出 %d 个聚类', n_clusters));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PerformVariableClustering');\n                obj.Results.variable_clustering = struct();\n            end\n        end\n        \n        function n_clusters = DetermineClusterNumber(obj, Z, var_names)\n            % 确定聚类数量\n            try\n                n_vars = length(var_names);\n                \n                % 使用肘部法则\n                inertia = [];\n                for k = 1:min(10, n_vars-1)\n                    T = cluster(Z, 'maxclust', k);\n                    inertia = [inertia, sum(Z(end-k+2:end, 3))];\n                end\n                \n                % 找到肘部点\n                if length(inertia) > 2\n                    diff1 = diff(inertia);\n                    diff2 = diff(diff1);\n                    [~, elbow_idx] = max(abs(diff2));\n                    n_clusters = elbow_idx + 1;\n                else\n                    n_clusters = 2;\n                end\n                \n                % 使用轮廓系数验证\n                if n_clusters > 1 && n_clusters < n_vars\n                    T = cluster(Z, 'maxclust', n_clusters);\n                    try\n                        silhouette_vals = silhouette(var_names, T);\n                        avg_silhouette = mean(silhouette_vals);\n                        \n                        if avg_silhouette < 0.3\n                            n_clusters = max(2, n_clusters - 1);\n                        end\n                    catch\n                        % silhouette函数可能不适用于所有数据类型\n                    end\n                end\n                \n                % 确保合理范围\n                n_clusters = max(2, min(n_clusters, floor(n_vars/2)));\n                \n            catch\n                % 默认值\n                n_clusters = min(3, length(var_names) - 1);\n            end\n        end\n        \n        function CreateVisualizations(obj)\n            % 创建相关性分析可视化\n            try\n                obj.Logger.Log('debug', '创建相关性分析可视化');\n                \n                figure_dir = fullfile(obj.Config.OutputDirectory, 'figures');\n                \n                % 1. 相关性热图\n                obj.CreateCorrelationHeatmap(figure_dir);\n                \n                % 2. PCA双标图\n                obj.CreatePCABiplot(figure_dir);\n                \n                % 3. 主成分方差解释图\n                obj.CreateVarianceExplainedPlot(figure_dir);\n                \n                % 4. 因子载荷图\n                obj.CreateFactorLoadingPlot(figure_dir);\n                \n                % 5. 变量聚类树状图\n                obj.CreateClusterDendrogram(figure_dir);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateVisualizations');\n            end\n        end\n        \n        function CreateCorrelationHeatmap(obj, figure_dir)\n            % 创建相关性热图\n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1000, 900]);\n                \n                % 使用Pearson相关系数\n                R = obj.Results.correlations.pearson;\n                var_names = obj.Results.correlation_summary.high_correlation_pairs.Variable1;\n                \n                % 创建热图\n                h = heatmap(R, 'XDisplayLabels', var_names, 'YDisplayLabels', var_names);\n                h.Title = '变量间相关性热图';\n                h.FontSize = 10;\n                h.Colormap = colormap('RdBu_r');\n                h.ColorLimits = [-1, 1];\n                \n                % 保存图形\n                save_figure_util(fig, figure_dir, 'correlation_heatmap');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateCorrelationHeatmap');\n            end\n        end\n        \n        function CreatePCABiplot(obj, figure_dir)\n            % 创建PCA双标图\n            try\n                if ~isfield(obj.Results, 'pca') || isempty(obj.Results.pca)\n                    return;\n                end\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 900]);\n                \n                pca_results = obj.Results.pca;\n                \n                % 创建双标图\n                biplot(pca_results.coefficients(:, 1:2), ...\n                    'Scores', pca_results.scores(:, 1:2), ...\n                    'VarLabels', obj.Results.correlation_summary.high_correlation_pairs.Variable1);\n                \n                xlabel(sprintf('PC1 (%.1f%% variance)', pca_results.explained(1)));\n                ylabel(sprintf('PC2 (%.1f%% variance)', pca_results.explained(2)));\n                title('PCA双标图');\n                grid on;\n                \n                % 保存图形\n                save_figure_util(fig, figure_dir, 'pca_biplot');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreatePCABiplot');\n            end\n        end\n        \n        function CreateVarianceExplainedPlot(obj, figure_dir)\n            % 创建方差解释图\n            try\n                if ~isfield(obj.Results, 'pca') || isempty(obj.Results.pca)\n                    return;\n                end\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 900, 600]);\n                \n                pca_results = obj.Results.pca;\n                \n                % 创建两个子图\n                subplot(2, 1, 1);\n                bar(pca_results.explained);\n                xlabel('主成分');\n                ylabel('解释方差百分比');\n                title('各主成分解释方差');\n                grid on;\n                \n                subplot(2, 1, 2);\n                plot(pca_results.cumulative_variance, 'o-', 'LineWidth', 2);\n                xlabel('主成分数量');\n                ylabel('累积解释方差百分比');\n                title('累积解释方差');\n                grid on;\n                \n                % 添加参考线\n                yline(80, '--', '80%');\n                yline(90, '--', '90%');\n                yline(95, '--', '95%');\n                \n                % 保存图形\n                save_figure_util(fig, figure_dir, 'variance_explained');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateVarianceExplainedPlot');\n            end\n        end\n        \n        function CreateFactorLoadingPlot(obj, figure_dir)\n            % 创建因子载荷图\n            try\n                if ~isfield(obj.Results, 'factor_analysis') || isempty(obj.Results.factor_analysis)\n                    return;\n                end\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1000, 800]);\n                \n                factor_results = obj.Results.factor_analysis;\n                loadings = factor_results.loadings;\n                \n                % 绘制前两个因子的载荷图\n                if size(loadings, 2) >= 2\n                    scatter(loadings(:, 1), loadings(:, 2), 100, 'filled');\n                    \n                    % 添加标签\n                    var_names = obj.Results.correlation_summary.high_correlation_pairs.Variable1;\n                    for i = 1:length(var_names)\n                        text(loadings(i, 1), loadings(i, 2), var_names{i}, ...\n                            'HorizontalAlignment', 'center', 'VerticalAlignment', 'bottom');\n                    end\n                    \n                    % 添加坐标轴\n                    axisLim = max(abs(loadings(:, 1:2)));\n                    xlim([-axisLim, axisLim]);\n                    ylim([-axisLim, axisLim]);\n                    \n                    % 添加网格和标签\n                    grid on;\n                    xlabel('因子1');\n                    ylabel('因子2');\n                    title('因子载荷图');\n                    \n                    % 添加单位圆\n                    theta = linspace(0, 2*pi, 100);\n                    plot(cos(theta), sin(theta), 'k--');\n                end\n                \n                % 保存图形\n                save_figure_util(fig, figure_dir, 'factor_loadings');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateFactorLoadingPlot');\n            end\n        end\n        \n        function CreateClusterDendrogram(obj, figure_dir)\n            % 创建聚类树状图\n            try\n                if ~isfield(obj.Results, 'variable_clustering') || isempty(obj.Results.variable_clustering)\n                    return;\n                end\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 800]);\n                \n                clustering_results = obj.Results.variable_clustering;\n                \n                % 创建树状图\n                dendrogram(clustering_results.linkage_matrix, ...\n                    'Labels', obj.Results.correlation_summary.high_correlation_pairs.Variable1);\n                \n                xlabel('变量');\n                ylabel('距离');\n                title('变量层次聚类树状图');\n                \n                % 添加聚类切割线\n                n_clusters = clustering_results.n_clusters;\n                if n_clusters > 1\n                    cutoff = clustering_results.linkage_matrix(end-n_clusters+2, 3);\n                    yline(cutoff, 'r--', sprintf('%d clusters', n_clusters));\n                end\n                \n                % 保存图形\n                save_figure_util(fig, figure_dir, 'cluster_dendrogram');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateClusterDendrogram');\n            end\n        end\n        \n        function GenerateAnalysisReport(obj)\n            % 生成相关性分析报告\n            try\n                obj.Logger.Log('debug', '生成相关性分析报告');\n                \n                report = struct();\n                report.timestamp = datetime('now');\n                \n                % 基本统计\n                if isfield(obj.Results, 'correlation_summary')\n                    report.correlation_stats = obj.Results.correlation_summary;\n                end\n                \n                % PCA结果\n                if isfield(obj.Results, 'pca') && ~isempty(obj.Results.pca)\n                    report.pca_summary = struct();\n                    report.pca_summary.n_components_80pct = obj.Results.pca.n_components.variance_80;\n                    report.pca_summary.n_components_90pct = obj.Results.pca.n_components.variance_90;\n                    report.pca_summary.n_components_95pct = obj.Results.pca.n_components.variance_95;\n                    report.pca_summary.kaiser_components = obj.Results.pca.n_components.kaiser;\n                end\n                \n                % 因子分析结果\n                if isfield(obj.Results, 'factor_analysis') && ~isempty(obj.Results.factor_analysis)\n                    report.factor_summary = struct();\n                    report.factor_summary.n_factors = obj.Results.factor_analysis.n_factors;\n                    report.factor_summary.total_variance_explained = sum(obj.Results.factor_analysis.proportion_explained);\n                end\n                \n                % 聚类结果\n                if isfield(obj.Results, 'variable_clustering') && ~isempty(obj.Results.variable_clustering)\n                    report.clustering_summary = struct();\n                    report.clustering_summary.n_clusters = obj.Results.variable_clustering.n_clusters;\n                    report.clustering_summary.avg_intra_correlation = ...\n                        mean(obj.Results.variable_clustering.cluster_stats.AvgIntraCorrelation);\n                end\n                \n                % 保存报告\n                obj.Results.analysis_report = report;\n                \n                % 记录关键发现\n                obj.LogKeyFindings(report);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GenerateAnalysisReport');\n            end\n        end\n        \n        function LogKeyFindings(obj, report)\n            % 记录关键发现\n            obj.Logger.CreateSection('相关性分析关键发现');\n            \n            try\n                % 相关性发现\n                if isfield(report, 'correlation_stats')\n                    stats = report.correlation_stats;\n                    obj.Logger.Log('info', sprintf('变量间平均相关性: %.3f', stats.mean_correlation));\n                    \n                    if isfield(stats, 'high_correlation_pairs') && height(stats.high_correlation_pairs) > 0\n                        top_pair = stats.high_correlation_pairs(1, :);\n                        obj.Logger.Log('info', sprintf('最高相关性: %s 与 %s (r = %.3f)', ...\n                            top_pair.Variable1{1}, top_pair.Variable2{1}, top_pair.Correlation));\n                    end\n                end\n                \n                % PCA发现\n                if isfield(report, 'pca_summary')\n                    pca = report.pca_summary;\n                    obj.Logger.Log('info', sprintf('主成分分析：前 %d 个主成分解释了 90%% 的方差', ...\n                        pca.n_components_90pct));\n                end\n                \n                % 因子分析发现\n                if isfield(report, 'factor_summary')\n                    factor = report.factor_summary;\n                    obj.Logger.Log('info', sprintf('因子分析：提取了 %d 个因子，解释了 %.1f%% 的总方差', ...\n                        factor.n_factors, factor.total_variance_explained * 100));\n                end\n                \n                % 聚类发现\n                if isfield(report, 'clustering_summary')\n                    cluster = report.clustering_summary;\n                    obj.Logger.Log('info', sprintf('变量聚类：识别出 %d 个聚类，平均簇内相关性 %.3f', ...\n                        cluster.n_clusters, cluster.avg_intra_correlation));\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'LogKeyFindings');\n            end\n        end\n    end\nend\n\n% 辅助函数：保存图形\nfunction save_figure_util(fig, output_dir, filename_base)\n    % 统一保存图形的辅助函数\n    formats = {'svg', 'png'};\n    \n    for i = 1:length(formats)\n        format = formats{i};\n        filepath = fullfile(output_dir, [filename_base '.' format]);\n        \n        try\n            switch format\n                case 'svg'\n                    print(fig, filepath, '-dsvg');\n                case 'png'\n                    print(fig, filepath, '-dpng', '-r300');\n                otherwise\n                    saveas(fig, filepath);\n            end\n        catch\n            % 忽略保存失败\n        end\n    end\n    \n    % 关闭图形\n    close(fig);\nend\n",
            "language": "matlab",
            "version_uuid": "e7f6a8f0-af1d-465d-9e0d-3bfcc42bbe6b"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "8ea9ad95-9850-4b0e-a991-92ac71f99255"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:16:21.389510+00:00",
          "stop_timestamp": "2025-05-08T09:16:21.953893+00:00",
          "type": "text",
          "text": "\n\n## 第九部分：Bootstrap采样模块\n\n创建Bootstrap采样模块，优化分层抽样和并行处理：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T09:16:22.146403+00:00",
          "stop_timestamp": "2025-05-08T09:17:28.889822+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-bootstrap-sampler",
            "type": "application/vnd.ant.code",
            "title": "Bootstrap采样模块 - BootstrapSampler.m",
            "command": "create",
            "content": "classdef BootstrapSampler < handle\n    % Bootstrap采样器类：实现高效的分层Bootstrap采样\n    % 包括平衡采样、扰动增强和质量控制\n    \n    properties (Access = private)\n        Config\n        Logger\n        SamplingStats\n    end\n    \n    properties (Access = public)\n        SampleStats\n    end\n    \n    methods (Access = public)\n        function obj = BootstrapSampler(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.SamplingStats = struct();\n            obj.SampleStats = struct();\n        end\n        \n        function [train_indices, test_indices] = Sample(obj, y)\n            % 执行分层Bootstrap采样\n            % 输入:\n            %   y - 因变量\n            % 输出:\n            %   train_indices - 训练集索引（细胞数组）\n            %   test_indices - 测试集索引（细胞数组）\n            \n            obj.Logger.Log('info', '开始Bootstrap分层抽样');\n            \n            try\n                % 初始化\n                n_samples = obj.Config.NumBootstrapSamples;\n                train_ratio = obj.Config.TrainRatio;\n                \n                % 分析标签分布\n                obj.AnalyzeLabelDistribution(y);\n                \n                % 生成采样策略\n                sampling_strategy = obj.DetermineSamplingStrategy(y);\n                \n                % 执行采样\n                [train_indices, test_indices] = obj.PerformSampling(y, n_samples, train_ratio, sampling_strategy);\n                \n                % 验证采样质量\n                obj.ValidateSamples(y, train_indices, test_indices);\n                \n                % 生成采样报告\n                obj.GenerateSamplingReport();\n                \n                obj.Logger.Log('info', sprintf('Bootstrap采样完成，生成了%d个训练/测试集对', n_samples));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'BootstrapSampler.Sample');\n                rethrow(ME);\n            end\n        end\n        \n        function stats = GetSamplingStats(obj)\n            % 获取采样统计信息\n            stats = obj.SamplingStats;\n        end\n        \n        function ExportSamples(obj, train_indices, test_indices, output_dir)\n            % 导出采样结果\n            try\n                % 创建导出目录\n                export_dir = fullfile(output_dir, 'bootstrap_samples');\n                if ~exist(export_dir, 'dir')\n                    mkdir(export_dir);\n                end\n                \n                % 保存索引\n                save(fullfile(export_dir, 'train_indices.mat'), 'train_indices', '-v7.3');\n                save(fullfile(export_dir, 'test_indices.mat'), 'test_indices', '-v7.3');\n                \n                % 保存统计信息\n                stats = obj.SamplingStats;\n                save(fullfile(export_dir, 'sampling_stats.mat'), 'stats', '-v7.3');\n                \n                % 创建CSV报告\n                obj.CreateCSVReport(export_dir);\n                \n                obj.Logger.Log('info', '采样结果已导出');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'BootstrapSampler.ExportSamples');\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function AnalyzeLabelDistribution(obj, y)\n            % 分析标签分布\n            obj.SamplingStats.label_analysis = struct();\n            \n            % 计算基本统计\n            unique_labels = unique(y);\n            label_counts = histcounts(y, [unique_labels; unique_labels(end)+1]);\n            label_props = label_counts / length(y);\n            \n            obj.SamplingStats.label_analysis.unique_labels = unique_labels;\n            obj.SamplingStats.label_analysis.label_counts = label_counts;\n            obj.SamplingStats.label_analysis.label_proportions = label_props;\n            obj.SamplingStats.label_analysis.imbalance_ratio = max(label_counts) / min(label_counts);\n            \n            % 记录分布信息\n            obj.Logger.Log('info', '标签分布分析:');\n            for i = 1:length(unique_labels)\n                obj.Logger.Log('info', sprintf('  标签 %d: %d 个样本 (%.1f%%)', ...\n                    unique_labels(i), label_counts(i), label_props(i) * 100));\n            end\n            obj.Logger.Log('info', sprintf('  不平衡比: %.2f:1', obj.SamplingStats.label_analysis.imbalance_ratio));\n        end\n        \n        function strategy = DetermineSamplingStrategy(obj, y)\n            % 确定采样策略\n            strategy = struct();\n            \n            % 基础策略\n            strategy.type = 'stratified';  % 默认分层采样\n            strategy.preserve_distribution = true;\n            \n            % 根据不平衡程度调整策略\n            imbalance_ratio = obj.SamplingStats.label_analysis.imbalance_ratio;\n            \n            if imbalance_ratio > 5\n                strategy.type = 'balanced_stratified';  % 平衡分层采样\n                strategy.balancing_method = 'oversampling';\n            elseif imbalance_ratio > 10\n                strategy.type = 'balanced_stratified';\n                strategy.balancing_method = 'hybrid';  % 混合方法\n            end\n            \n            % 特殊处理小样本\n            if length(y) < 100\n                strategy.type = 'systematic';\n                strategy.replace_on_rare = true;\n            end\n            \n            % 设置额外参数\n            strategy.bootstrap_perturbation = true;  % 启用扰动\n            strategy.ensure_all_classes = true;      % 确保所有类别都存在\n            \n            obj.Logger.Log('info', sprintf('采样策略: %s', strategy.type));\n            if isfield(strategy, 'balancing_method')\n                obj.Logger.Log('info', sprintf('平衡方法: %s', strategy.balancing_method));\n            end\n        end\n        \n        function [train_indices, test_indices] = PerformSampling(obj, y, n_samples, train_ratio, strategy)\n            % 执行采样\n            \n            % 预分配结果\n            train_indices = cell(n_samples, 1);\n            test_indices = cell(n_samples, 1);\n            \n            % 分析类别\n            unique_labels = unique(y);\n            label_indices = cell(length(unique_labels), 1);\n            for i = 1:length(unique_labels)\n                label_indices{i} = find(y == unique_labels(i));\n            end\n            \n            % 预分配随机种子\n            rng_seeds = randi(2^32-1, n_samples, 1);\n            \n            % 初始化进度统计\n            sample_stats = struct();\n            sample_stats.train_sizes = zeros(n_samples, 1);\n            sample_stats.test_sizes = zeros(n_samples, 1);\n            sample_stats.label_distributions = cell(n_samples, 1);\n            \n            % 并行采样\n            parfor i = 1:n_samples\n                % 设置随机种子\n                rng(rng_seeds(i));\n                \n                % 根据策略执行采样\n                [train_idx, test_idx] = obj.SampleSingleIteration(y, train_ratio, strategy, label_indices);\n                \n                % 存储结果\n                train_indices{i} = train_idx;\n                test_indices{i} = test_idx;\n                \n                % 记录统计信息\n                sample_stats.train_sizes(i) = length(train_idx);\n                sample_stats.test_sizes(i) = length(test_idx);\n                sample_stats.label_distributions{i} = obj.CalculateLabelDistribution(y(train_idx));\n                \n                % 进度更新\n                if mod(i, max(1, round(n_samples/10))) == 0\n                    progress = i / n_samples * 100;\n                end\n            end\n            \n            % 保存采样统计\n            obj.SampleStats = sample_stats;\n            \n            % 分析采样质量\n            obj.AnalyzeSamplingQuality(sample_stats);\n        end\n        \n        function [train_idx, test_idx] = SampleSingleIteration(obj, y, train_ratio, strategy, label_indices)\n            % 执行单次采样\n            \n            train_idx = [];\n            test_idx = [];\n            \n            switch strategy.type\n                case 'stratified'\n                    [train_idx, test_idx] = obj.StratifiedSample(y, train_ratio, label_indices);\n                    \n                case 'balanced_stratified'\n                    [train_idx, test_idx] = obj.BalancedStratifiedSample(y, train_ratio, label_indices, strategy);\n                    \n                case 'systematic'\n                    [train_idx, test_idx] = obj.SystematicSample(y, train_ratio, label_indices);\n                    \n                otherwise\n                    error('未知的采样策略: %s', strategy.type);\n            end\n            \n            % 应用扰动（如果启用）\n            if strategy.bootstrap_perturbation\n                train_idx = obj.ApplyBootstrapPerturbation(train_idx, y);\n            end\n            \n            % 确保所有类别都存在\n            if strategy.ensure_all_classes\n                train_idx = obj.EnsureAllClassesPresent(train_idx, y, label_indices);\n            end\n            \n            % 计算test_idx\n            total_idx = 1:length(y);\n            test_idx = setdiff(total_idx, train_idx);\n        end\n        \n        function [train_idx, test_idx] = StratifiedSample(obj, y, train_ratio, label_indices)\n            % 分层采样\n            train_idx = [];\n            \n            for i = 1:length(label_indices)\n                class_idx = label_indices{i};\n                n_class = length(class_idx);\n                n_train = round(train_ratio * n_class);\n                \n                % 保证至少有一个样本\n                n_train = max(1, n_train);\n                n_train = min(n_train, n_class);\n                \n                % 随机选择\n                selected = randsample(n_class, n_train);\n                train_idx = [train_idx; class_idx(selected)];\n            end\n            \n            % 计算test_idx\n            total_idx = 1:length(y);\n            test_idx = setdiff(total_idx, train_idx);\n        end\n        \n        function [train_idx, test_idx] = BalancedStratifiedSample(obj, y, train_ratio, label_indices, strategy)\n            % 平衡分层采样\n            \n            % 计算每个类别的目标样本数\n            n_classes = length(label_indices);\n            class_sizes = cellfun(@length, label_indices);\n            \n            if strcmp(strategy.balancing_method, 'oversampling')\n                % 上采样到最大类别的大小\n                target_size_per_class = max(class_sizes);\n            elseif strcmp(strategy.balancing_method, 'undersampling')\n                % 下采样到最小类别的大小\n                target_size_per_class = min(class_sizes);\n            else  % hybrid\n                % 平衡到中位数大小\n                target_size_per_class = median(class_sizes);\n            end\n            \n            % 调整目标大小以适应训练比例\n            target_train_size = round(target_size_per_class * train_ratio);\n            target_train_size = max(1, target_train_size);\n            \n            train_idx = [];\n            \n            for i = 1:length(label_indices)\n                class_idx = label_indices{i};\n                n_class = length(class_idx);\n                \n                if n_class >= target_train_size\n                    % 下采样\n                    selected = randsample(n_class, target_train_size, false);\n                else\n                    % 上采样（有放回抽样）\n                    selected = randsample(n_class, target_train_size, true);\n                end\n                \n                train_idx = [train_idx; class_idx(selected)];\n            end\n            \n            % 计算test_idx\n            total_idx = 1:length(y);\n            test_idx = setdiff(total_idx, train_idx);\n        end\n        \n        function [train_idx, test_idx] = SystematicSample(obj, y, train_ratio, label_indices)\n            % 系统抽样（适用于小样本）\n            \n            n_total = length(y);\n            n_train = round(train_ratio * n_total);\n            \n            % 确保合理范围\n            n_train = max(round(n_total * 0.5), min(n_train, round(n_total * 0.9)));\n            \n            % 系统抽样\n            step = round(n_total / n_train);\n            step = max(1, step);\n            \n            start_idx = randi(step);\n            train_idx = start_idx:step:n_total;\n            train_idx = train_idx(train_idx <= n_total);\n            \n            % 确保训练集大小\n            if length(train_idx) < n_train\n                % 补充随机样本\n                remaining = setdiff(1:n_total, train_idx);\n                additional = randsample(remaining, n_train - length(train_idx), false);\n                train_idx = [train_idx, additional];\n            end\n            \n            % 计算test_idx\n            total_idx = 1:n_total;\n            test_idx = setdiff(total_idx, train_idx);\n        end\n        \n        function perturbed_idx = ApplyBootstrapPerturbation(obj, train_idx, y)\n            % 应用Bootstrap扰动\n            \n            n_train = length(train_idx);\n            \n            % 计算扰动比例（通常10-20%）\n            perturbation_rate = 0.15;\n            n_perturb = round(n_train * perturbation_rate);\n            \n            % 选择要替换的索引\n            replace_idx = randsample(n_train, n_perturb, false);\n            \n            % 从原始训练集中重新采样\n            new_samples = randsample(train_idx, n_perturb, true);\n            \n            % 创建扰动后的索引\n            perturbed_idx = train_idx;\n            perturbed_idx(replace_idx) = new_samples;\n            \n            % 去重\n            perturbed_idx = unique(perturbed_idx);\n        end\n        \n        function enhanced_idx = EnsureAllClassesPresent(obj, train_idx, y, label_indices)\n            % 确保所有类别都在训练集中\n            \n            enhanced_idx = train_idx;\n            \n            % 检查每个类别\n            for i = 1:length(label_indices)\n                class_idx = label_indices{i};\n                \n                % 检查该类别是否存在于训练集中\n                if ~any(ismember(train_idx, class_idx))\n                    % 随机添加一个该类别的样本\n                    random_sample = datasample(class_idx, 1);\n                    enhanced_idx = [enhanced_idx; random_sample];\n                end\n            end\n            \n            % 去重\n            enhanced_idx = unique(enhanced_idx);\n        end\n        \n        function distribution = CalculateLabelDistribution(~, y_subset)\n            % 计算子集的标签分布\n            unique_labels = unique(y_subset);\n            distribution = struct();\n            \n            for i = 1:length(unique_labels)\n                label = unique_labels(i);\n                count = sum(y_subset == label);\n                distribution.(sprintf('label_%d', label)) = count;\n                distribution.(sprintf('prop_%d', label)) = count / length(y_subset);\n            end\n        end\n        \n        function AnalyzeSamplingQuality(obj, sample_stats)\n            % 分析采样质量\n            \n            quality_analysis = struct();\n            \n            % 训练集大小统计\n            quality_analysis.train_size = struct();\n            quality_analysis.train_size.mean = mean(sample_stats.train_sizes);\n            quality_analysis.train_size.std = std(sample_stats.train_sizes);\n            quality_analysis.train_size.min = min(sample_stats.train_sizes);\n            quality_analysis.train_size.max = max(sample_stats.train_sizes);\n            quality_analysis.train_size.cv = quality_analysis.train_size.std / quality_analysis.train_size.mean;\n            \n            % 测试集大小统计\n            quality_analysis.test_size = struct();\n            quality_analysis.test_size.mean = mean(sample_stats.test_sizes);\n            quality_analysis.test_size.std = std(sample_stats.test_sizes);\n            quality_analysis.test_size.min = min(sample_stats.test_sizes);\n            quality_analysis.test_size.max = max(sample_stats.test_sizes);\n            quality_analysis.test_size.cv = quality_analysis.test_size.std / quality_analysis.test_size.mean;\n            \n            % 标签分布一致性\n            quality_analysis.distribution_stability = obj.AnalyzeDistributionStability(sample_stats.label_distributions);\n            \n            % 样本覆盖率（每个样本被选中的次数）\n            quality_analysis.sample_coverage = obj.CalculateSampleCoverage(sample_stats);\n            \n            obj.SamplingStats.quality_analysis = quality_analysis;\n            \n            % 记录质量分析结果\n            obj.Logger.Log('info', '采样质量分析:');\n            obj.Logger.Log('info', sprintf('  训练集大小: %.1f ± %.1f (CV=%.3f)', ...\n                quality_analysis.train_size.mean, quality_analysis.train_size.std, quality_analysis.train_size.cv));\n            obj.Logger.Log('info', sprintf('  测试集大小: %.1f ± %.1f (CV=%.3f)', ...\n                quality_analysis.test_size.mean, quality_analysis.test_size.std, quality_analysis.test_size.cv));\n            obj.Logger.Log('info', sprintf('  分布稳定性: %.3f', quality_analysis.distribution_stability));\n            obj.Logger.Log('info', sprintf('  平均样本覆盖率: %.1f%%', quality_analysis.sample_coverage.mean_coverage * 100));\n        end\n        \n        function stability = AnalyzeDistributionStability(obj, distributions)\n            % 分析标签分布的稳定性\n            \n            n_samples = length(distributions);\n            if n_samples < 2\n                stability = 1;\n                return;\n            end\n            \n            % 获取所有可能的标签\n            all_labels = {};\n            for i = 1:n_samples\n                fields = fieldnames(distributions{i});\n                for j = 1:length(fields)\n                    if startswith(fields{j}, 'prop_')\n                        if ~any(strcmp(all_labels, fields{j}))\n                            all_labels{end+1} = fields{j};\n                        end\n                    end\n                end\n            end\n            \n            % 计算每个标签的分布稳定性\n            stabilities = zeros(length(all_labels), 1);\n            \n            for i = 1:length(all_labels)\n                label = all_labels{i};\n                proportions = zeros(n_samples, 1);\n                \n                for j = 1:n_samples\n                    if isfield(distributions{j}, label)\n                        proportions(j) = distributions{j}.(label);\n                    end\n                end\n                \n                % 计算变异系数\n                if mean(proportions) > 0\n                    stabilities(i) = 1 - (std(proportions) / mean(proportions));\n                else\n                    stabilities(i) = 1;\n                end\n            end\n            \n            % 总体稳定性\n            stability = mean(stabilities);\n        end\n        \n        function coverage = CalculateSampleCoverage(obj, sample_stats)\n            % 计算样本覆盖率\n            \n            % 汇总所有训练集索引\n            all_train_idx = [];\n            for i = 1:length(sample_stats.train_sizes)\n                % 这里需要访问实际的索引，但由于是并行处理，我们用估计\n                all_train_idx = [all_train_idx; ones(sample_stats.train_sizes(i), 1) * i];\n            end\n            \n            % 计算每个样本的覆盖次数（近似）\n            n_samples = obj.Config.NumBootstrapSamples;\n            estimated_total_samples = sum(sample_stats.train_sizes) + sum(sample_stats.test_sizes);\n            avg_sample_occurrence = n_samples * obj.Config.TrainRatio;\n            \n            coverage = struct();\n            coverage.mean_coverage = avg_sample_occurrence / n_samples;\n            coverage.estimated_coverage_rate = mean(sample_stats.train_sizes) / mean(sample_stats.train_sizes + sample_stats.test_sizes);\n        end\n        \n        function CreateCSVReport(obj, output_dir)\n            % 创建CSV格式的采样报告\n            \n            try\n                % 基本统计报告\n                stats = obj.SamplingStats;\n                \n                % 创建标签分布报告\n                if isfield(stats, 'label_analysis')\n                    label_table = table();\n                    label_table.Label = stats.label_analysis.unique_labels;\n                    label_table.Count = stats.label_analysis.label_counts';\n                    label_table.Proportion = stats.label_analysis.label_proportions';\n                    \n                    writetable(label_table, fullfile(output_dir, 'label_distribution.csv'));\n                end\n                \n                % 创建采样质量报告\n                if isfield(stats, 'quality_analysis')\n                    quality = stats.quality_analysis;\n                    \n                    quality_table = table();\n                    quality_table.Metric = {'Train Size Mean', 'Train Size Std', 'Train Size CV', ...\n                        'Test Size Mean', 'Test Size Std', 'Test Size CV', ...\n                        'Distribution Stability', 'Mean Coverage'};\n                    quality_table.Value = [quality.train_size.mean, quality.train_size.std, quality.train_size.cv, ...\n                        quality.test_size.mean, quality.test_size.std, quality.test_size.cv, ...\n                        quality.distribution_stability, quality.sample_coverage.mean_coverage];\n                    \n                    writetable(quality_table, fullfile(output_dir, 'sampling_quality.csv'));\n                end\n                \n                obj.Logger.Log('info', 'CSV报告已生成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'BootstrapSampler.CreateCSVReport');\n            end\n        end\n        \n        function GenerateSamplingReport(obj)\n            % 生成采样报告\n            \n            report = struct();\n            report.timestamp = datetime('now');\n            report.config = struct();\n            report.config.n_samples = obj.Config.NumBootstrapSamples;\n            report.config.train_ratio = obj.Config.TrainRatio;\n            \n            if isfield(obj.SamplingStats, 'label_analysis')\n                report.label_analysis = obj.SamplingStats.label_analysis;\n            end\n            \n            if isfield(obj.SamplingStats, 'quality_analysis')\n                report.quality_analysis = obj.SamplingStats.quality_analysis;\n            end\n            \n            % 计算关键指标\n            if isfield(obj.SampleStats, 'train_sizes')\n                report.summary = struct();\n                report.summary.avg_train_size = mean(obj.SampleStats.train_sizes);\n                report.summary.avg_test_size = mean(obj.SampleStats.test_sizes);\n                report.summary.size_stability = 1 - (std(obj.SampleStats.train_sizes) / mean(obj.SampleStats.train_sizes));\n            end\n            \n            % 保存报告\n            obj.SamplingStats.final_report = report;\n            \n            % 记录关键信息\n            obj.Logger.CreateSection('Bootstrap采样报告');\n            obj.Logger.Log('info', sprintf('总采样次数: %d', obj.Config.NumBootstrapSamples));\n            obj.Logger.Log('info', sprintf('训练集比例: %.2f', obj.Config.TrainRatio));\n            \n            if isfield(report, 'summary')\n                obj.Logger.Log('info', sprintf('平均训练集大小: %.1f', report.summary.avg_train_size));\n                obj.Logger.Log('info', sprintf('平均测试集大小: %.1f', report.summary.avg_test_size));\n                obj.Logger.Log('info', sprintf('大小稳定性: %.3f', report.summary.size_stability));\n            end\n            \n            if isfield(report, 'quality_analysis')\n                obj.Logger.Log('info', sprintf('分布稳定性: %.3f', report.quality_analysis.distribution_stability));\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "f8169031-2d22-4a5f-a415-4350dcf3b476"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "9d706ac9-e73f-49d8-b0ec-31334813834f"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T09:17:30.365270+00:00",
          "stop_timestamp": "2025-05-08T09:17:30.365270+00:00",
          "type": "text",
          "text": "",
          "citations": []
        }
      ],
      "sender": "assistant",
      "index": 3,
      "created_at": "2025-05-08T09:17:31.526603+00:00",
      "updated_at": "2025-05-08T09:17:31.526603+00:00",
      "truncated": false,
      "stop_reason": "stop_sequence",
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "ae4038cf-5785-4151-9969-477f3cb1c609"
    },
    {
      "uuid": "ad11cb22-6006-44cc-9ac4-556807347526",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T10:06:39.180095+00:00",
          "stop_timestamp": "2025-05-08T10:06:39.180095+00:00",
          "type": "text",
          "text": "Continue",
          "citations": []
        }
      ],
      "sender": "human",
      "index": 4,
      "created_at": "2025-05-08T10:06:39.183975+00:00",
      "updated_at": "2025-05-08T10:06:39.183975+00:00",
      "truncated": false,
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "0fc6b3b3-2ecf-4a51-aa80-03f0f5ea1d51"
    },
    {
      "uuid": "72ad818b-e2ef-47e3-bd5c-c8ce86ea188e",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-05-08T10:06:43.188647+00:00",
          "stop_timestamp": "2025-05-08T10:06:49.472684+00:00",
          "type": "thinking",
          "thinking": "用户想让我继续优化代码。我已经完成了前9个模块：\n\n1. 配置文件模块 (BinomialConfig)\n2. 日志管理模块 (BinomialLogger)\n3. 主分析器类 (BinomialAnalyzer)\n4. 数据管理模块 (DataManager)\n5. 并行计算管理模块 (ParallelManager)\n6. GPU管理模块 (GPUManager)\n7. 多重共线性检查模块 (CollinearityChecker)\n8. 相关性分析模块 (CorrelationAnalyzer)\n9. Bootstrap采样模块 (BootstrapSampler)\n\n接下来我需要继续创建其余的模块：\n\n10. K折交叉验证模块 (CrossValidator)\n11. 变量选择模块 (VariableSelector)\n12. 系数稳定性监控模块 (CoefficientStabilityMonitor)\n13. 参数统计分析模块 (ParameterStatisticsCalculator)\n14. 变量贡献评估模块 (VariableContributionEvaluator)\n15. 残差分析模块 (ResidualAnalyzer)\n16. 结果可视化模块 (ResultVisualizer)\n17. 结果保存模块 (ResultSaver)\n18. 报告生成模块 (ReportGenerator)\n19. 主执行函数 (Binomial)\n\n我将继续创建第10个模块：K折交叉验证模块。",
          "summaries": [
            {
              "summary": "Thinking about continuing an unspecified task or conversation"
            },
            {
              "summary": "Continuing to optimize code modules and progress"
            },
            {
              "summary": "Mapped out comprehensive AI module development strategy."
            }
          ],
          "cut_off": false
        },
        {
          "start_timestamp": "2025-05-08T10:06:49.858788+00:00",
          "stop_timestamp": "2025-05-08T10:06:50.454637+00:00",
          "type": "text",
          "text": "## 第十部分：K折交叉验证模块\n\n创建增强的K折交叉验证模块，包含多种评估指标和可视化：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T10:06:50.735697+00:00",
          "stop_timestamp": "2025-05-08T10:09:37.672202+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-cross-validator",
            "type": "application/vnd.ant.code",
            "title": "K折交叉验证模块 - CrossValidator.m",
            "command": "create",
            "content": "classdef CrossValidator < handle\n    % K折交叉验证器类：实现全面的交叉验证分析\n    % 包括多种性能指标、系数稳定性分析和可视化\n    \n    properties (Access = private)\n        Config\n        Logger\n        CVResults\n        FoldStats\n    end\n    \n    methods (Access = public)\n        function obj = CrossValidator(config, logger)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.CVResults = struct();\n            obj.FoldStats = struct();\n        end\n        \n        function cv_results = Validate(obj, X, y, var_names)\n            % 执行K折交叉验证\n            % 输入:\n            %   X - 自变量矩阵\n            %   y - 因变量\n            %   var_names - 变量名称\n            % 输出:\n            %   cv_results - 交叉验证结果\n            \n            obj.Logger.Log('info', sprintf('开始%d折交叉验证', obj.Config.KFolds));\n            \n            try\n                % 1. 准备交叉验证\n                obj.PrepareCrossValidation(X, y);\n                \n                % 2. 执行折叠\n                obj.ExecuteFolds(X, y, var_names);\n                \n                % 3. 计算总体指标\n                obj.CalculateOverallMetrics();\n                \n                % 4. 分析系数稳定性\n                obj.AnalyzeCoefficientStability();\n                \n                % 5. 进行统计检验\n                obj.PerformStatisticalTests();\n                \n                % 6. 创建可视化\n                obj.CreateCrossValidationVisualizations();\n                \n                % 7. 生成报告\n                obj.GenerateCrossValidationReport();\n                \n                cv_results = obj.CVResults;\n                \n                obj.Logger.Log('info', sprintf('%d折交叉验证完成', obj.Config.KFolds));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CrossValidator.Validate');\n                rethrow(ME);\n            end\n        end\n        \n        function results = GetResults(obj)\n            % 获取交叉验证结果\n            results = obj.CVResults;\n        end\n        \n        function ExportResults(obj, output_dir)\n            % 导出交叉验证结果\n            try\n                % 创建导出目录\n                cv_dir = fullfile(output_dir, 'cross_validation');\n                if ~exist(cv_dir, 'dir')\n                    mkdir(cv_dir);\n                end\n                \n                % 保存结果\n                results = obj.CVResults;\n                save(fullfile(cv_dir, 'cv_results.mat'), 'results', '-v7.3');\n                \n                % 导出性能指标\n                obj.ExportPerformanceMetrics(cv_dir);\n                \n                % 导出系数分析\n                obj.ExportCoefficientAnalysis(cv_dir);\n                \n                % 导出预测结果\n                obj.ExportPredictions(cv_dir);\n                \n                obj.Logger.Log('info', '交叉验证结果已导出');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CrossValidator.ExportResults');\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function PrepareCrossValidation(obj, X, y)\n            % 准备交叉验证\n            \n            n_samples = length(y);\n            k = obj.Config.KFolds;\n            \n            % 验证K值\n            if k < 2\n                error('K值必须大于等于2');\n            end\n            \n            if k > n_samples\n                obj.Logger.Log('warning', sprintf('K值(%d)大于样本数(%d)，调整为%d', k, n_samples, n_samples));\n                k = n_samples;\n                obj.Config.KFolds = k;  % 更新配置\n            end\n            \n            % 创建分层交叉验证分组\n            try\n                cv = cvpartition(y, 'KFold', k, 'Stratify', true);\n            catch\n                obj.Logger.Log('warning', '分层创建失败，使用随机分组');\n                cv = cvpartition(y, 'KFold', k);\n            end\n            \n            % 保存分组信息\n            obj.CVResults.cv_partition = cv;\n            obj.CVResults.k_folds = k;\n            obj.CVResults.n_samples = n_samples;\n            \n            % 初始化结果存储\n            obj.InitializeResultsStorage(k);\n            \n            obj.Logger.Log('info', sprintf('准备%d折交叉验证，样本数：%d', k, n_samples));\n        end\n        \n        function InitializeResultsStorage(obj, k)\n            % 初始化结果存储结构\n            \n            % 性能指标\n            metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc', ...\n                       'aic', 'bic', 'log_loss', 'brier_score'};\n            \n            for i = 1:length(metrics)\n                obj.CVResults.(metrics{i}) = zeros(k, 1);\n            end\n            \n            % 预测结果存储\n            obj.CVResults.fold_indices = cell(k, 1);\n            obj.CVResults.y_pred = cell(k, 1);\n            obj.CVResults.y_test = cell(k, 1);\n            obj.CVResults.y_pred_prob = cell(k, 1);\n            \n            % 系数存储\n            obj.CVResults.coefficients = cell(k, 1);\n            obj.CVResults.feature_importance = cell(k, 1);\n            \n            % 性能细节\n            obj.CVResults.confusion_matrices = cell(k, 1);\n            obj.CVResults.roc_curves = cell(k, 1);\n            obj.CVResults.precision_recall_curves = cell(k, 1);\n            \n            % 折叠统计\n            obj.FoldStats = struct();\n            obj.FoldStats.training_time = zeros(k, 1);\n            obj.FoldStats.prediction_time = zeros(k, 1);\n            obj.FoldStats.convergence_info = cell(k, 1);\n        end\n        \n        function ExecuteFolds(obj, X, y, var_names)\n            % 执行所有折叠\n            \n            k = obj.Config.KFolds;\n            cv = obj.CVResults.cv_partition;\n            \n            % 并行执行折叠\n            fold_results = cell(k, 1);\n            \n            parfor i = 1:k\n                fold_results{i} = obj.ExecuteSingleFold(i, X, y, var_names, cv);\n            end\n            \n            % 合并结果\n            obj.MergeFoldResults(fold_results);\n            \n            obj.Logger.Log('info', sprintf('完成%d折叠的模型训练和评估', k));\n        end\n        \n        function fold_result = ExecuteSingleFold(obj, fold_idx, X, y, var_names, cv)\n            % 执行单个折叠\n            \n            fold_result = struct();\n            fold_start_time = tic;\n            \n            try\n                % 获取训练和测试集\n                train_idx = cv.training(fold_idx);\n                test_idx = cv.test(fold_idx);\n                \n                X_train = X(train_idx, :);\n                y_train = y(train_idx);\n                X_test = X(test_idx, :);\n                y_test = y(test_idx);\n                \n                % 存储索引\n                fold_result.fold_indices = struct('train', find(train_idx), 'test', find(test_idx));\n                \n                % 训练模型\n                training_start = tic;\n                [model, model_info] = obj.TrainFoldModel(X_train, y_train);\n                training_time = toc(training_start);\n                \n                % 进行预测\n                prediction_start = tic;\n                [y_pred, y_pred_prob] = obj.PredictFold(model, X_test);\n                prediction_time = toc(prediction_start);\n                \n                % 计算性能指标\n                metrics = obj.CalculateFoldMetrics(y_test, y_pred, y_pred_prob, model, X_train, y_train);\n                \n                % 存储结果\n                fold_result.metrics = metrics;\n                fold_result.y_pred = y_pred;\n                fold_result.y_test = y_test;\n                fold_result.y_pred_prob = y_pred_prob;\n                fold_result.coefficients = obj.ExtractCoefficients(model, var_names);\n                fold_result.feature_importance = obj.ExtractFeatureImportance(model, var_names);\n                fold_result.confusion_matrix = obj.CalculateConfusionMatrix(y_test, y_pred);\n                fold_result.roc_curve = obj.CalculateROCCurve(y_test, y_pred_prob);\n                fold_result.pr_curve = obj.CalculatePRCurve(y_test, y_pred_prob);\n                \n                % 时间和收敛信息\n                fold_result.training_time = training_time;\n                fold_result.prediction_time = prediction_time;\n                fold_result.convergence_info = model_info;\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('折叠%d执行失败: %s', fold_idx, ME.message));\n                \n                % 返回空结果\n                fold_result.metrics = struct();\n                fold_result.errors = ME;\n            end\n            \n            fold_result.total_time = toc(fold_start_time);\n        end\n        \n        function [model, model_info] = TrainFoldModel(obj, X_train, y_train)\n            % 训练单个折叠的模型\n            \n            model_info = struct();\n            \n            try\n                % 使用逻辑回归模型\n                mdl = fitglm(X_train, y_train, 'Distribution', 'binomial', 'Link', 'logit');\n                \n                % 检查收敛性\n                model_info.converged = mdl.DispersionEstimated;\n                model_info.iterations = mdl.NumIterations;\n                model_info.deviance = mdl.Deviance;\n                \n                model = mdl;\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('模型训练失败: %s', ME.message));\n                model = [];\n                model_info.error = ME;\n            end\n        end\n        \n        function [y_pred, y_pred_prob] = PredictFold(obj, model, X_test)\n            % 对测试集进行预测\n            \n            try\n                if ~isempty(model)\n                    y_pred_prob = predict(model, X_test);\n                    y_pred = y_pred_prob > 0.5;\n                else\n                    % 模型为空，返回随机预测\n                    y_pred_prob = rand(size(X_test, 1), 1);\n                    y_pred = y_pred_prob > 0.5;\n                end\n            catch\n                % 预测失败，返回随机预测\n                y_pred_prob = rand(size(X_test, 1), 1);\n                y_pred = y_pred_prob > 0.5;\n            end\n        end\n        \n        function metrics = CalculateFoldMetrics(obj, y_test, y_pred, y_pred_prob, model, X_train, y_train)\n            % 计算单个折叠的性能指标\n            \n            metrics = struct();\n            \n            try\n                % 基本分类指标\n                [metrics.accuracy, metrics.precision, metrics.recall, metrics.specificity, metrics.f1_score] = ...\n                    obj.CalculateClassificationMetrics(y_test, y_pred);\n                \n                % AUC\n                if length(unique(y_test)) > 1\n                    [~, ~, ~, metrics.auc] = perfcurve(y_test, y_pred_prob, 1);\n                else\n                    metrics.auc = NaN;\n                end\n                \n                % 模型选择指标\n                if ~isempty(model)\n                    [metrics.aic, metrics.bic] = obj.CalculateModelSelectionMetrics(model, X_train, y_train);\n                else\n                    metrics.aic = NaN;\n                    metrics.bic = NaN;\n                end\n                \n                % 概率指标\n                metrics.log_loss = obj.CalculateLogLoss(y_test, y_pred_prob);\n                metrics.brier_score = obj.CalculateBrierScore(y_test, y_pred_prob);\n                \n            catch ME\n                obj.Logger.Log('warning', sprintf('指标计算失败: %s', ME.message));\n                % 返回默认值\n                metrics = obj.GetDefaultMetrics();\n            end\n        end\n        \n        function [accuracy, precision, recall, specificity, f1_score] = CalculateClassificationMetrics(obj, y_test, y_pred)\n            % 计算分类指标\n            \n            % 计算混淆矩阵元素\n            TP = sum(y_pred == 1 & y_test == 1);\n            TN = sum(y_pred == 0 & y_test == 0);\n            FP = sum(y_pred == 1 & y_test == 0);\n            FN = sum(y_pred == 0 & y_test == 1);\n            \n            % 计算指标\n            total = length(y_test);\n            accuracy = (TP + TN) / total;\n            \n            if (TP + FP) > 0\n                precision = TP / (TP + FP);\n            else\n                precision = 0;\n            end\n            \n            if (TP + FN) > 0\n                recall = TP / (TP + FN);\n            else\n                recall = 0;\n            end\n            \n            if (TN + FP) > 0\n                specificity = TN / (TN + FP);\n            else\n                specificity = 0;\n            end\n            \n            if (precision + recall) > 0\n                f1_score = 2 * precision * recall / (precision + recall);\n            else\n                f1_score = 0;\n            end\n        end\n        \n        function [aic, bic] = CalculateModelSelectionMetrics(obj, model, X_train, y_train)\n            % 计算模型选择指标\n            \n            try\n                % 提取模型信息\n                deviance = model.Deviance;\n                n_params = length(model.Coefficients.Estimate);\n                n_samples = size(X_train, 1);\n                \n                % 计算AIC和BIC\n                aic = deviance + 2 * n_params;\n                bic = deviance + log(n_samples) * n_params;\n                \n            catch\n                aic = Inf;\n                bic = Inf;\n            end\n        end\n        \n        function log_loss = CalculateLogLoss(obj, y_true, y_prob)\n            % 计算对数损失\n            \n            try\n                % 避免边界情况\n                eps = 1e-15;\n                y_prob = max(min(y_prob, 1 - eps), eps);\n                \n                % 计算对数损失\n                log_loss = -mean(y_true .* log(y_prob) + (1 - y_true) .* log(1 - y_prob));\n                \n            catch\n                log_loss = NaN;\n            end\n        end\n        \n        function brier_score = CalculateBrierScore(obj, y_true, y_prob)\n            % 计算Brier分数\n            \n            try\n                brier_score = mean((y_prob - y_true).^2);\n            catch\n                brier_score = NaN;\n            end\n        end\n        \n        function coefs = ExtractCoefficients(obj, model, var_names)\n            % 提取模型系数\n            \n            try\n                if ~isempty(model)\n                    coefs = table();\n                    coefs.Variable = model.CoefficientNames';\n                    coefs.Estimate = model.Coefficients.Estimate;\n                    coefs.SE = model.Coefficients.SE;\n                    coefs.tStat = model.Coefficients.tStat;\n                    coefs.pValue = model.Coefficients.pValue;\n                else\n                    coefs = table();\n                end\n            catch\n                coefs = table();\n            end\n        end\n        \n        function importance = ExtractFeatureImportance(obj, model, var_names)\n            % 提取特征重要性\n            \n            try\n                if ~isempty(model)\n                    % 使用标准化系数的绝对值作为重要性\n                    coefs = model.Coefficients.Estimate(2:end);  % 排除截距\n                    \n                    importance = table();\n                    importance.Variable = var_names';\n                    importance.Importance = abs(coefs);\n                    importance = sortrows(importance, 'Importance', 'descend');\n                else\n                    importance = table();\n                end\n            catch\n                importance = table();\n            end\n        end\n        \n        function cm = CalculateConfusionMatrix(obj, y_true, y_pred)\n            % 计算混淆矩阵\n            \n            try\n                cm = struct();\n                \n                % 计算元素\n                cm.TN = sum(y_pred == 0 & y_true == 0);\n                cm.FP = sum(y_pred == 1 & y_true == 0);\n                cm.FN = sum(y_pred == 0 & y_true == 1);\n                cm.TP = sum(y_pred == 1 & y_true == 1);\n                \n                % 创建矩阵\n                cm.matrix = [cm.TN, cm.FP; cm.FN, cm.TP];\n                \n                % 归一化矩阵\n                cm.normalized = cm.matrix ./ sum(cm.matrix(:));\n                \n            catch\n                cm = struct();\n            end\n        end\n        \n        function roc = CalculateROCCurve(obj, y_true, y_scores)\n            % 计算ROC曲线\n            \n            try\n                [X, Y, T, AUC] = perfcurve(y_true, y_scores, 1);\n                \n                roc = struct();\n                roc.FPR = X;\n                roc.TPR = Y;\n                roc.Thresholds = T;\n                roc.AUC = AUC;\n                \n            catch\n                roc = struct();\n            end\n        end\n        \n        function pr = CalculatePRCurve(obj, y_true, y_scores)\n            % 计算Precision-Recall曲线\n            \n            try\n                % 获取唯一阈值\n                thresholds = unique(y_scores);\n                thresholds = sort(thresholds, 'descend');\n                \n                precisions = zeros(length(thresholds), 1);\n                recalls = zeros(length(thresholds), 1);\n                \n                for i = 1:length(thresholds)\n                    y_pred = y_scores >= thresholds(i);\n                    \n                    TP = sum(y_pred == 1 & y_true == 1);\n                    FP = sum(y_pred == 1 & y_true == 0);\n                    FN = sum(y_pred == 0 & y_true == 1);\n                    \n                    if (TP + FP) > 0\n                        precisions(i) = TP / (TP + FP);\n                    else\n                        precisions(i) = 1;\n                    end\n                    \n                    if (TP + FN) > 0\n                        recalls(i) = TP / (TP + FN);\n                    else\n                        recalls(i) = 0;\n                    end\n                end\n                \n                pr = struct();\n                pr.Precision = precisions;\n                pr.Recall = recalls;\n                pr.Thresholds = thresholds;\n                pr.AUC_PR = trapz(fliplr(recalls'), fliplr(precisions'));\n                \n            catch\n                pr = struct();\n            end\n        end\n        \n        function MergeFoldResults(obj, fold_results)\n            % 合并所有折叠的结果\n            \n            k = length(fold_results);\n            \n            % 合并性能指标\n            metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc', ...\n                       'aic', 'bic', 'log_loss', 'brier_score'};\n            \n            for i = 1:k\n                for j = 1:length(metrics)\n                    metric = metrics{j};\n                    if isfield(fold_results{i}, 'metrics') && isfield(fold_results{i}.metrics, metric)\n                        obj.CVResults.(metric)(i) = fold_results{i}.metrics.(metric);\n                    else\n                        obj.CVResults.(metric)(i) = NaN;\n                    end\n                end\n                \n                % 合并其他结果\n                fields = {'fold_indices', 'y_pred', 'y_test', 'y_pred_prob', 'coefficients', ...\n                         'feature_importance', 'confusion_matrix', 'roc_curve', 'pr_curve'};\n                \n                for field = fields\n                    field_name = field{1};\n                    if isfield(fold_results{i}, field_name)\n                        obj.CVResults.(field_name){i} = fold_results{i}.(field_name);\n                    else\n                        obj.CVResults.(field_name){i} = [];\n                    end\n                end\n                \n                % 合并统计信息\n                if isfield(fold_results{i}, 'training_time')\n                    obj.FoldStats.training_time(i) = fold_results{i}.training_time;\n                end\n                if isfield(fold_results{i}, 'prediction_time')\n                    obj.FoldStats.prediction_time(i) = fold_results{i}.prediction_time;\n                end\n                if isfield(fold_results{i}, 'convergence_info')\n                    obj.FoldStats.convergence_info{i} = fold_results{i}.convergence_info;\n                end\n            end\n        end\n        \n        function CalculateOverallMetrics(obj)\n            % 计算总体性能指标\n            \n            metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc', ...\n                       'aic', 'bic', 'log_loss', 'brier_score'};\n            \n            obj.CVResults.summary = struct();\n            \n            for i = 1:length(metrics)\n                metric = metrics{i};\n                values = obj.CVResults.(metric);\n                \n                % 计算统计量\n                obj.CVResults.summary.(['avg_' metric]) = mean(values, 'omitnan');\n                obj.CVResults.summary.(['std_' metric]) = std(values, 'omitnan');\n                obj.CVResults.summary.(['cv_' metric]) = std(values, 'omitnan') / mean(values, 'omitnan');\n                obj.CVResults.summary.(['min_' metric]) = min(values);\n                obj.CVResults.summary.(['max_' metric]) = max(values);\n                obj.CVResults.summary.(['median_' metric]) = median(values, 'omitnan');\n            end\n            \n            % 计算置信区间\n            obj.CalculateConfidenceIntervals();\n            \n            % 记录总体指标\n            obj.Logger.Log('info', '总体交叉验证指标：');\n            obj.Logger.Log('info', sprintf('准确率: %.3f ± %.3f', ...\n                obj.CVResults.summary.avg_accuracy, obj.CVResults.summary.std_accuracy));\n            obj.Logger.Log('info', sprintf('F1分数: %.3f ± %.3f', ...\n                obj.CVResults.summary.avg_f1_score, obj.CVResults.summary.std_f1_score));\n            obj.Logger.Log('info', sprintf('AUC: %.3f ± %.3f', ...\n                obj.CVResults.summary.avg_auc, obj.CVResults.summary.std_auc));\n        end\n        \n        function CalculateConfidenceIntervals(obj)\n            % 计算置信区间\n            \n            metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\n            alpha = 0.05;  % 95%置信区间\n            \n            obj.CVResults.confidence_intervals = struct();\n            \n            for i = 1:length(metrics)\n                metric = metrics{i};\n                values = obj.CVResults.(metric);\n                n = sum(~isnan(values));\n                \n                if n > 1\n                    % 使用t分布计算置信区间\n                    t_stat = tinv(1 - alpha/2, n - 1);\n                    mean_val = mean(values, 'omitnan');\n                    std_val = std(values, 'omitnan');\n                    margin = t_stat * std_val / sqrt(n);\n                    \n                    obj.CVResults.confidence_intervals.(metric) = [mean_val - margin, mean_val + margin];\n                else\n                    obj.CVResults.confidence_intervals.(metric) = [NaN, NaN];\n                end\n            end\n        end\n        \n        function AnalyzeCoefficientStability(obj)\n            % 分析系数稳定性\n            \n            try\n                % 收集所有系数\n                all_coefficients = obj.CVResults.coefficients;\n                \n                % 检查是否有有效的系数数据\n                valid_coefs = cellfun(@(x) ~isempty(x) && height(x) > 0, all_coefficients);\n                \n                if sum(valid_coefs) < 2\n                    obj.Logger.Log('warning', '系数数据不足，无法进行稳定性分析');\n                    return;\n                end\n                \n                % 获取所有变量名\n                all_var_names = {};\n                for i = 1:length(all_coefficients)\n                    if valid_coefs(i)\n                        vars = all_coefficients{i}.Variable;\n                        all_var_names = union(all_var_names, vars);\n                    end\n                end\n                \n                % 创建系数矩阵\n                coef_matrix = NaN(sum(valid_coefs), length(all_var_names));\n                \n                valid_idx = 1;\n                for i = 1:length(all_coefficients)\n                    if valid_coefs(i)\n                        for j = 1:length(all_var_names)\n                            var_name = all_var_names{j};\n                            idx = strcmp(all_coefficients{i}.Variable, var_name);\n                            if any(idx)\n                                coef_matrix(valid_idx, j) = all_coefficients{i}.Estimate(idx);\n                            end\n                        end\n                        valid_idx = valid_idx + 1;\n                    end\n                end\n                \n                % 计算稳定性指标\n                stability = struct();\n                stability.variable_names = all_var_names;\n                stability.mean_coefficients = nanmean(coef_matrix, 1);\n                stability.std_coefficients = nanstd(coef_matrix, 0, 1);\n                stability.cv_coefficients = abs(stability.std_coefficients ./ stability.mean_coefficients);\n                \n                % 识别不稳定的系数\n                stability.unstable_threshold = 0.5;\n                stability.unstable_variables = all_var_names(stability.cv_coefficients > stability.unstable_threshold);\n                \n                obj.CVResults.coefficient_stability = stability;\n                \n                % 记录结果\n                obj.Logger.Log('info', '系数稳定性分析完成：');\n                obj.Logger.Log('info', sprintf('分析了 %d 个变量的系数', length(all_var_names)));\n                obj.Logger.Log('info', sprintf('发现 %d 个不稳定变量 (CV > %.2f)', ...\n                    length(stability.unstable_variables), stability.unstable_threshold));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'AnalyzeCoefficientStability');\n            end\n        end\n        \n        function PerformStatisticalTests(obj)\n            % 执行统计检验\n            \n            obj.CVResults.statistical_tests = struct();\n            \n            try\n                % 1. Friedman秩和检验（对不同指标）\n                metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                metric_data = [];\n                \n                for i = 1:length(metrics)\n                    metric_data = [metric_data, obj.CVResults.(metrics{i})];\n                end\n                \n                % 执行Friedman检验\n                [p_friedman, tbl_friedman, stats_friedman] = friedman(metric_data, 1, 'off');\n                \n                obj.CVResults.statistical_tests.friedman = struct();\n                obj.CVResults.statistical_tests.friedman.p_value = p_friedman;\n                obj.CVResults.statistical_tests.friedman.table = tbl_friedman;\n                obj.CVResults.statistical_tests.friedman.stats = stats_friedman;\n                \n                % 2. 检验方差齐性\n                obj.CVResults.statistical_tests.variance_homogeneity = struct();\n                \n                for i = 1:length(metrics)\n                    metric = metrics{i};\n                    values = obj.CVResults.(metric);\n                    \n                    % Levene's test（方差齐性）\n                    if length(values) >= 3\n                        [p_levene, stat_levene] = obj.LeveneTest(values);\n                        obj.CVResults.statistical_tests.variance_homogeneity.(metric) = struct();\n                        obj.CVResults.statistical_tests.variance_homogeneity.(metric).p_value = p_levene;\n                        obj.CVResults.statistical_tests.variance_homogeneity.(metric).statistic = stat_levene;\n                    end\n                end\n                \n                % 3. 正态性检验\n                obj.CVResults.statistical_tests.normality = struct();\n                \n                for i = 1:length(metrics)\n                    metric = metrics{i};\n                    values = obj.CVResults.(metric);\n                    \n                    % Kolmogorov-Smirnov检验\n                    if length(values) >= 3\n                        [h_ks, p_ks] = kstest(values);\n                        obj.CVResults.statistical_tests.normality.(metric) = struct();\n                        obj.CVResults.statistical_tests.normality.(metric).ks_p_value = p_ks;\n                        obj.CVResults.statistical_tests.normality.(metric).ks_reject = h_ks;\n                    end\n                end\n                \n                obj.Logger.Log('info', '统计检验完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PerformStatisticalTests');\n            end\n        end\n        \n        function [p_value, statistic] = LeveneTest(obj, data)\n            % Levene方差齐性检验\n            \n            try\n                % 这是一个简化版的Levene检验\n                n = length(data);\n                grand_mean = mean(data);\n                \n                % 计算组内偏差\n                deviations = abs(data - grand_mean);\n                \n                % 计算F统计量\n                mean_deviation = mean(deviations);\n                ss_between = n * (mean_deviation - mean(deviations))^2;\n                ss_within = sum((deviations - mean_deviation).^2);\n                \n                if ss_within > 0\n                    statistic = ss_between / (ss_within / (n - 1));\n                    % 使用F分布计算p值（简化）\n                    p_value = 1 - fcdf(statistic, 1, n - 1);\n                else\n                    statistic = 0;\n                    p_value = 1;\n                end\n                \n            catch\n                statistic = NaN;\n                p_value = NaN;\n            end\n        end\n        \n        function CreateCrossValidationVisualizations(obj)\n            % 创建交叉验证可视化\n            \n            try\n                figure_dir = fullfile(obj.Config.OutputDirectory, 'figures', 'cross_validation');\n                if ~exist(figure_dir, 'dir')\n                    mkdir(figure_dir);\n                end\n                \n                % 1. 折叠性能图\n                obj.CreateFoldPerformancePlot(figure_dir);\n                \n                % 2. 指标分布图\n                obj.CreateMetricDistributionPlot(figure_dir);\n                \n                % 3. 系数稳定性图\n                obj.CreateCoefficientStabilityPlot(figure_dir);\n                \n                % 4. ROC曲线比较\n                obj.CreateROCComparisonPlot(figure_dir);\n                \n                % 5. PR曲线比较\n                obj.CreatePRComparisonPlot(figure_dir);\n                \n                % 6. 混淆矩阵热图\n                obj.CreateConfusionMatrixHeatmap(figure_dir);\n                \n                obj.Logger.Log('info', '交叉验证可视化已创建');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateCrossValidationVisualizations');\n            end\n        end\n        \n        function CreateFoldPerformancePlot(obj, figure_dir)\n            % 创建折叠性能图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 800]);\n                \n                k = obj.Config.KFolds;\n                metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\n                metric_labels = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\n                \n                for i = 1:length(metrics)\n                    subplot(2, 3, i);\n                    \n                    metric = metrics{i};\n                    values = obj.CVResults.(metric);\n                    mean_val = obj.CVResults.summary.(['avg_' metric]);\n                    std_val = obj.CVResults.summary.(['std_' metric]);\n                    \n                    % 绘制折线图\n                    plot(1:k, values, 'o-', 'LineWidth', 2, 'MarkerSize', 8);\n                    hold on;\n                    \n                    % 绘制均值线\n                    yline(mean_val, 'r--', 'LineWidth', 2);\n                    \n                    % 绘制标准差区间\n                    fill([1:k, k:-1:1], [mean_val + std_val * ones(1, k), fliplr(mean_val - std_val * ones(1, k))], ...\n                        'r', 'FaceAlpha', 0.1, 'EdgeColor', 'none');\n                    \n                    xlabel('折数');\n                    ylabel(metric_labels{i});\n                    title(sprintf('%s （均值=%.3f, 标准差=%.3f）', metric_labels{i}, mean_val, std_val));\n                    grid on;\n                    xlim([0.5, k+0.5]);\n                    \n                    if i <= 5\n                        ylim([0, 1]);\n                    end\n                end\n                \n                sgtitle('K折交叉验证各折性能指标', 'FontSize', 16, 'FontWeight', 'bold');\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'fold_performance.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'fold_performance.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateFoldPerformancePlot');\n            end\n        end\n        \n        function CreateMetricDistributionPlot(obj, figure_dir)\n            % 创建指标分布图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1000, 600]);\n                \n                metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc'};\n                metric_labels = {'准确率', '精确率', '召回率', '特异性', 'F1分数', 'AUC'};\n                \n                data = zeros(obj.Config.KFolds, length(metrics));\n                for i = 1:length(metrics)\n                    data(:, i) = obj.CVResults.(metrics{i});\n                end\n                \n                % 创建箱线图\n                boxplot(data, 'Labels', metric_labels, 'Notch', 'on');\n                \n                ylabel('指标值');\n                title('交叉验证指标分布');\n                grid on;\n                ylim([0, 1.05]);\n                \n                % 添加均值点\n                means = mean(data);\n                hold on;\n                scatter(1:length(metrics), means, 100, 'r', 'filled', 'MarkerEdgeColor', 'k');\n                legend('箱线图', '均值', 'Location', 'southwest');\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'metric_distribution.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'metric_distribution.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateMetricDistributionPlot');\n            end\n        end\n        \n        function CreateCoefficientStabilityPlot(obj, figure_dir)\n            % 创建系数稳定性图\n            \n            try\n                if ~isfield(obj.CVResults, 'coefficient_stability')\n                    return;\n                end\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1000, 600]);\n                \n                stability = obj.CVResults.coefficient_stability;\n                \n                % 排序变量\n                [sorted_cv, idx] = sort(stability.cv_coefficients, 'descend');\n                sorted_vars = stability.variable_names(idx);\n                sorted_means = stability.mean_coefficients(idx);\n                \n                % 限制显示的变量数量\n                max_vars = min(15, length(sorted_vars));\n                sorted_cv = sorted_cv(1:max_vars);\n                sorted_vars = sorted_vars(1:max_vars);\n                sorted_means = sorted_means(1:max_vars);\n                \n                % 创建条形图\n                bar(sorted_cv);\n                hold on;\n                \n                % 添加阈值线\n                yline(stability.unstable_threshold, 'r--', '不稳定阈值', 'LineWidth', 2);\n                \n                % 设置标签\n                set(gca, 'XTick', 1:max_vars, 'XTickLabel', sorted_vars, 'XTickLabelRotation', 45);\n                ylabel('变异系数 (CV)');\n                xlabel('变量');\n                title('系数稳定性分析');\n                grid on;\n                \n                % 添加系数值标签\n                for i = 1:max_vars\n                    text(i, sorted_cv(i) + 0.01, sprintf('%.3f', sorted_means(i)), ...\n                        'HorizontalAlignment', 'center', 'VerticalAlignment', 'bottom');\n                end\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'coefficient_stability.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'coefficient_stability.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateCoefficientStabilityPlot');\n            end\n        end\n        \n        function CreateROCComparisonPlot(obj, figure_dir)\n            % 创建ROC曲线比较图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 800, 800]);\n                \n                colors = lines(obj.Config.KFolds);\n                \n                % 绘制每个折叠的ROC曲线\n                for i = 1:obj.Config.KFolds\n                    roc = obj.CVResults.roc_curves{i};\n                    if ~isempty(roc) && isfield(roc, 'FPR') && isfield(roc, 'TPR')\n                        plot(roc.FPR, roc.TPR, 'Color', colors(i, :), 'LineWidth', 1, ...\n                            'DisplayName', sprintf('折叠 %d (AUC=%.3f)', i, roc.AUC));\n                        hold on;\n                    end\n                end\n                \n                % 绘制平均ROC曲线\n                avg_auc = obj.CVResults.summary.avg_auc;\n                plot([0, 1], [0, 1], 'k--', 'LineWidth', 1.5, 'DisplayName', '随机分类器');\n                \n                xlabel('假阳性率');\n                ylabel('真阳性率');\n                title(sprintf('K折交叉验证ROC曲线比较 (平均AUC=%.3f±%.3f)', ...\n                    avg_auc, obj.CVResults.summary.std_auc));\n                legend('Location', 'southeast');\n                grid on;\n                axis equal;\n                xlim([0, 1]);\n                ylim([0, 1]);\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'roc_comparison.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'roc_comparison.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateROCComparisonPlot');\n            end\n        end\n        \n        function CreatePRComparisonPlot(obj, figure_dir)\n            % 创建PR曲线比较图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 800, 800]);\n                \n                colors = lines(obj.Config.KFolds);\n                \n                % 绘制每个折叠的PR曲线\n                for i = 1:obj.Config.KFolds\n                    pr = obj.CVResults.precision_recall_curves{i};\n                    if ~isempty(pr) && isfield(pr, 'Recall') && isfield(pr, 'Precision')\n                        plot(pr.Recall, pr.Precision, 'Color', colors(i, :), 'LineWidth', 1, ...\n                            'DisplayName', sprintf('折叠 %d (AUC=%.3f)', i, pr.AUC_PR));\n                        hold on;\n                    end\n                end\n                \n                xlabel('召回率');\n                ylabel('精确率');\n                title('K折交叉验证Precision-Recall曲线比较');\n                legend('Location', 'southwest');\n                grid on;\n                xlim([0, 1]);\n                ylim([0, 1.05]);\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'pr_comparison.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'pr_comparison.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreatePRComparisonPlot');\n            end\n        end\n        \n        function CreateConfusionMatrixHeatmap(obj, figure_dir)\n            % 创建混淆矩阵热图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 400]);\n                \n                % 计算平均混淆矩阵\n                avg_cm = zeros(2, 2);\n                count = 0;\n                \n                for i = 1:obj.Config.KFolds\n                    cm = obj.CVResults.confusion_matrices{i};\n                    if ~isempty(cm) && isfield(cm, 'matrix')\n                        avg_cm = avg_cm + cm.matrix;\n                        count = count + 1;\n                    end\n                end\n                \n                if count > 0\n                    avg_cm = avg_cm / count;\n                end\n                \n                % 创建三个子图：原始值、行归一化、列归一化\n                subplot(1, 3, 1);\n                heatmap(avg_cm, 'XDisplayLabels', {'预测0', '预测1'}, ...\n                    'YDisplayLabels', {'实际0', '实际1'}, 'Title', '平均混淆矩阵（原始计数）');\n                \n                subplot(1, 3, 2);\n                row_normalized = avg_cm ./ sum(avg_cm, 2);\n                heatmap(row_normalized, 'XDisplayLabels', {'预测0', '预测1'}, ...\n                    'YDisplayLabels', {'实际0', '实际1'}, 'Title', '行归一化混淆矩阵');\n                \n                subplot(1, 3, 3);\n                col_normalized = avg_cm ./ sum(avg_cm, 1);\n                heatmap(col_normalized, 'XDisplayLabels', {'预测0', '预测1'}, ...\n                    'YDisplayLabels', {'实际0', '实际1'}, 'Title', '列归一化混淆矩阵');\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'confusion_matrix_heatmap.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'confusion_matrix_heatmap.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateConfusionMatrixHeatmap');\n            end\n        end\n        \n        function GenerateCrossValidationReport(obj)\n            % 生成交叉验证报告\n            \n            try\n                report = struct();\n                report.timestamp = datetime('now');\n                report.k_folds = obj.Config.KFolds;\n                report.summary = obj.CVResults.summary;\n                \n                % 添加置信区间\n                report.confidence_intervals = obj.CVResults.confidence_intervals;\n                \n                % 添加系数稳定性摘要\n                if isfield(obj.CVResults, 'coefficient_stability')\n                    report.coefficient_stability = struct();\n                    report.coefficient_stability.n_variables = length(obj.CVResults.coefficient_stability.variable_names);\n                    report.coefficient_stability.n_unstable = length(obj.CVResults.coefficient_stability.unstable_variables);\n                    report.coefficient_stability.unstable_variables = obj.CVResults.coefficient_stability.unstable_variables;\n                end\n                \n                % 添加统计检验结果\n                if isfield(obj.CVResults, 'statistical_tests')\n                    report.statistical_tests = obj.CVResults.statistical_tests;\n                end\n                \n                % 保存报告\n                obj.CVResults.final_report = report;\n                \n                % 记录关键发现\n                obj.Logger.CreateSection('交叉验证报告摘要');\n                obj.Logger.Log('info', sprintf('K值: %d', report.k_folds));\n                \n                % 记录主要指标\n                metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                metric_labels = {'准确率', '精确率', '召回率', 'F1分数', 'AUC'};\n                \n                for i = 1:length(metrics)\n                    metric = metrics{i};\n                    avg = report.summary.(['avg_' metric]);\n                    std = report.summary.(['std_' metric]);\n                    ci = report.confidence_intervals.(metric);\n                    \n                    obj.Logger.Log('info', sprintf('%s: %.3f ± %.3f (95%% CI: [%.3f, %.3f])', ...\n                        metric_labels{i}, avg, std, ci(1), ci(2)));\n                end\n                \n                % 记录系数稳定性\n                if isfield(report, 'coefficient_stability')\n                    obj.Logger.Log('info', sprintf('系数稳定性: %d/%d 变量不稳定', ...\n                        report.coefficient_stability.n_unstable, report.coefficient_stability.n_variables));\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GenerateCrossValidationReport');\n            end\n        end\n        \n        function ExportPerformanceMetrics(obj, output_dir)\n            % 导出性能指标\n            \n            try\n                % 创建性能指标表\n                metrics = {'accuracy', 'precision', 'recall', 'specificity', 'f1_score', 'auc', 'aic', 'bic'};\n                k = obj.Config.KFolds;\n                \n                performance_table = table();\n                performance_table.Fold = (1:k)';\n                \n                for i = 1:length(metrics)\n                    metric = metrics{i};\n                    performance_table.(metric) = obj.CVResults.(metric);\n                end\n                \n                % 添加汇总行\n                summary_row = table();\n                summary_row.Fold = 0;  % 使用0表示汇总行\n                \n                for i = 1:length(metrics)\n                    metric = metrics{i};\n                    summary_row.(metric) = obj.CVResults.summary.(['avg_' metric]);\n                end\n                \n                performance_table = [performance_table; summary_row];\n                \n                % 保存表格\n                writetable(performance_table, fullfile(output_dir, 'performance_metrics.csv'));\n                \n                % 创建置信区间表\n                ci_table = table();\n                ci_fields = fieldnames(obj.CVResults.confidence_intervals);\n                \n                for i = 1:length(ci_fields)\n                    field = ci_fields{i};\n                    ci = obj.CVResults.confidence_intervals.(field);\n                    ci_table.Metric{i} = field;\n                    ci_table.Lower_95CI(i) = ci(1);\n                    ci_table.Upper_95CI(i) = ci(2);\n                end\n                \n                writetable(ci_table, fullfile(output_dir, 'confidence_intervals.csv'));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ExportPerformanceMetrics');\n            end\n        end\n        \n        function ExportCoefficientAnalysis(obj, output_dir)\n            % 导出系数分析结果\n            \n            try\n                if ~isfield(obj.CVResults, 'coefficient_stability')\n                    return;\n                end\n                \n                stability = obj.CVResults.coefficient_stability;\n                \n                % 创建系数稳定性表\n                coef_table = table();\n                coef_table.Variable = stability.variable_names';\n                coef_table.Mean_Coefficient = stability.mean_coefficients';\n                coef_table.Std_Coefficient = stability.std_coefficients';\n                coef_table.CV = stability.cv_coefficients';\n                coef_table.Unstable = stability.cv_coefficients' > stability.unstable_threshold;\n                \n                % 按变异系数排序\n                coef_table = sortrows(coef_table, 'CV', 'descend');\n                \n                writetable(coef_table, fullfile(output_dir, 'coefficient_stability.csv'));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ExportCoefficientAnalysis');\n            end\n        end\n        \n        function ExportPredictions(obj, output_dir)\n            % 导出预测结果\n            \n            try\n                % 创建预测结果目录\n                pred_dir = fullfile(output_dir, 'predictions');\n                if ~exist(pred_dir, 'dir')\n                    mkdir(pred_dir);\n                end\n                \n                % 导出每个折叠的预测\n                for i = 1:obj.Config.KFolds\n                    if ~isempty(obj.CVResults.y_test{i}) && ~isempty(obj.CVResults.y_pred{i})\n                        pred_table = table();\n                        pred_table.True_Label = obj.CVResults.y_test{i};\n                        pred_table.Predicted_Label = obj.CVResults.y_pred{i};\n                        pred_table.Predicted_Probability = obj.CVResults.y_pred_prob{i};\n                        \n                        filename = sprintf('fold_%d_predictions.csv', i);\n                        writetable(pred_table, fullfile(pred_dir, filename));\n                    end\n                end\n                \n                % 合并所有预测\n                all_pred_table = table();\n                all_true = [];\n                all_pred = [];\n                all_prob = [];\n                all_fold = [];\n                \n                for i = 1:obj.Config.KFolds\n                    if ~isempty(obj.CVResults.y_test{i})\n                        all_true = [all_true; obj.CVResults.y_test{i}];\n                        all_pred = [all_pred; obj.CVResults.y_pred{i}];\n                        all_prob = [all_prob; obj.CVResults.y_pred_prob{i}];\n                        all_fold = [all_fold; ones(length(obj.CVResults.y_test{i}), 1) * i];\n                    end\n                end\n                \n                all_pred_table.Fold = all_fold;\n                all_pred_table.True_Label = all_true;\n                all_pred_table.Predicted_Label = all_pred;\n                all_pred_table.Predicted_Probability = all_prob;\n                \n                writetable(all_pred_table, fullfile(output_dir, 'all_predictions.csv'));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ExportPredictions');\n            end\n        end\n        \n        function metrics = GetDefaultMetrics(obj)\n            % 获取默认指标值\n            metrics = struct();\n            metrics.accuracy = 0;\n            metrics.precision = 0;\n            metrics.recall = 0;\n            metrics.specificity = 0;\n            metrics.f1_score = 0;\n            metrics.auc = 0.5;\n            metrics.aic = Inf;\n            metrics.bic = Inf;\n            metrics.log_loss = Inf;\n            metrics.brier_score = 1;\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "80528a50-5f38-4c0f-9081-efc500e5b033"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "4e8d7bee-ee4c-4eac-9bd6-d3b09036d55a"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T10:09:47.524484+00:00",
          "stop_timestamp": "2025-05-08T10:09:48.203592+00:00",
          "type": "text",
          "text": "\n\n## 第十一部分：变量选择模块\n\n创建综合的变量选择模块，支持多种算法：",
          "citations": []
        },
        {
          "start_timestamp": "2025-05-08T10:09:48.873826+00:00",
          "stop_timestamp": "2025-05-08T10:13:19.889290+00:00",
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "binomial-variable-selector",
            "type": "application/vnd.ant.code",
            "title": "变量选择模块 - VariableSelector.m",
            "command": "create",
            "content": "classdef VariableSelector < handle\n    % 变量选择器类：实现多种变量选择算法\n    % 包括逐步回归、LASSO、Ridge、ElasticNet和随机森林\n    \n    properties (Access = private)\n        Config\n        Logger\n        ParallelManager\n        SelectionResults\n    end\n    \n    properties (Access = public)\n        Methods\n        Results\n    end\n    \n    methods (Access = public)\n        function obj = VariableSelector(config, logger, parallel_manager)\n            % 构造函数\n            obj.Config = config;\n            obj.Logger = logger;\n            obj.ParallelManager = parallel_manager;\n            obj.Methods = config.VariableSelectionMethods;\n            obj.SelectionResults = struct();\n            obj.Results = struct();\n        end\n        \n        function results = SelectVariables(obj, X, y, train_indices, test_indices, var_names)\n            % 执行变量选择\n            % 输入:\n            %   X - 自变量矩阵\n            %   y - 因变量\n            %   train_indices - 训练集索引（cell数组）\n            %   test_indices - 测试集索引（cell数组）\n            %   var_names - 变量名称\n            % 输出:\n            %   results - 选择结果结构体\n            \n            obj.Logger.Log('info', '开始变量选择分析');\n            \n            try\n                % 1. 准备并行任务\n                tasks = obj.PrepareSelectionTasks(X, y, train_indices, test_indices, var_names);\n                \n                % 2. 并行执行各种方法\n                obj.Logger.Log('info', '并行执行各种变量选择方法');\n                method_futures = obj.ParallelManager.RunAsyncTask(@obj.ProcessMethod, tasks, 'VariableSelection');\n                \n                % 3. 收集结果\n                method_results = obj.ParallelManager.WaitForAsyncResults(method_futures, 'VariableSelection');\n                \n                % 4. 处理和整合结果\n                obj.IntegrateResults(method_results);\n                \n                % 5. 执行元分析\n                obj.PerformMetaAnalysis();\n                \n                % 6. 创建可视化\n                obj.CreateSelectionVisualizations();\n                \n                % 7. 生成报告\n                obj.GenerateSelectionReport();\n                \n                results = obj.Results;\n                \n                obj.Logger.Log('info', '变量选择分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'VariableSelector.SelectVariables');\n                rethrow(ME);\n            end\n        end\n        \n        function SaveResults(obj, output_dir)\n            % 保存变量选择结果\n            try\n                % 创建保存目录\n                var_sel_dir = fullfile(output_dir, 'variable_selection');\n                if ~exist(var_sel_dir, 'dir')\n                    mkdir(var_sel_dir);\n                end\n                \n                % 保存主结果\n                results = obj.Results;\n                save(fullfile(var_sel_dir, 'variable_selection_results.mat'), 'results', '-v7.3');\n                \n                % 保存各方法的详细结果\n                for i = 1:length(obj.Methods)\n                    method = obj.Methods{i};\n                    if isfield(obj.Results, method)\n                        method_results = obj.Results.(method);\n                        save(fullfile(var_sel_dir, sprintf('%s_results.mat', method)), 'method_results', '-v7.3');\n                    end\n                end\n                \n                % 导出CSV表格\n                obj.ExportVariableSelectionTables(var_sel_dir);\n                \n                obj.Logger.Log('info', '变量选择结果已保存');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'VariableSelector.SaveResults');\n            end\n        end\n    end\n    \n    methods (Access = private)\n        function tasks = PrepareSelectionTasks(obj, X, y, train_indices, test_indices, var_names)\n            % 准备变量选择任务\n            \n            tasks = cell(length(obj.Methods), 1);\n            \n            for i = 1:length(obj.Methods)\n                task = struct();\n                task.method = obj.Methods{i};\n                task.X = X;\n                task.y = y;\n                task.train_indices = train_indices;\n                task.test_indices = test_indices;\n                task.var_names = var_names;\n                task.config = obj.Config;\n                \n                tasks{i} = task;\n            end\n        end\n        \n        function result = ProcessMethod(obj, task)\n            % 处理单个变量选择方法\n            \n            method = task.method;\n            result = struct();\n            result.method = method;\n            \n            try\n                obj.Logger.Log('info', sprintf('开始处理%s方法', method));\n                \n                % 1. 执行变量选择\n                [selected_vars, var_freq, var_combinations] = obj.SelectVariablesByMethod(task);\n                \n                % 2. 训练和评估模型\n                [models, performance, group_performance] = obj.TrainAndEvaluateModels(task, var_combinations);\n                \n                % 3. 提取模型参数\n                params = obj.ExtractModelParameters(models, task.var_names);\n                \n                % 4. 组织结果\n                result.selected_vars = selected_vars;\n                result.var_freq = var_freq;\n                result.var_combinations = var_combinations;\n                result.models = models;\n                result.performance = performance;\n                result.group_performance = group_performance;\n                result.params = params;\n                result.success = true;\n                \n                obj.Logger.Log('info', sprintf('%s方法处理完成', method));\n                \n            catch ME\n                obj.Logger.LogException(ME, sprintf('ProcessMethod: %s', method));\n                result.success = false;\n                result.error = ME;\n            end\n        end\n        \n        function [selected_vars, var_freq, var_combinations] = SelectVariablesByMethod(obj, task)\n            % 根据方法选择变量\n            \n            method = task.method;\n            X = task.X;\n            y = task.y;\n            train_indices = task.train_indices;\n            \n            n_samples = length(train_indices);\n            n_vars = size(X, 2);\n            \n            % 预分配\n            var_combinations = cell(n_samples, 1);\n            \n            % 设置并行选项\n            opts = obj.ParallelManager.GetParallelOptions();\n            \n            switch lower(method)\n                case 'stepwise'\n                    var_combinations = obj.SelectStepwise(X, y, train_indices, task.config, opts);\n                    \n                case 'lasso'\n                    var_combinations = obj.SelectLASSO(X, y, train_indices, task.config, opts);\n                    \n                case 'ridge'\n                    var_combinations = obj.SelectRidge(X, y, train_indices, task.config, opts);\n                    \n                case 'elasticnet'\n                    var_combinations = obj.SelectElasticNet(X, y, train_indices, task.config, opts);\n                    \n                case 'randomforest'\n                    var_combinations = obj.SelectRandomForest(X, y, train_indices, task.config, opts);\n                    \n                otherwise\n                    error('不支持的变量选择方法: %s', method);\n            end\n            \n            % 计算变量选择频率\n            var_freq = obj.CalculateVariableFrequency(var_combinations, n_vars);\n            \n            % 确定最终选择的变量\n            selected_vars = obj.DetermineSelectedVariables(var_combinations, var_freq, n_vars);\n        end\n        \n        function var_combinations = SelectStepwise(obj, X, y, train_indices, config, opts)\n            % 逐步回归变量选择\n            \n            n_samples = length(train_indices);\n            var_combinations = cell(n_samples, 1);\n            \n            parfor i = 1:n_samples\n                try\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    \n                    % 执行逐步回归\n                    [~, ~, ~, inmodel] = stepwisefit(X_train, y_train, ...\n                        'PEnter', config.StepwisePEnter, ...\n                        'PRemove', config.StepwisePRemove, ...\n                        'Display', 'off');\n                    \n                    var_combinations{i} = find(inmodel);\n                    \n                catch\n                    % 如果失败，使用相关性选择\n                    [~, pval] = corr(X_train, y_train);\n                    var_combinations{i} = find(pval < 0.05);\n                end\n            end\n        end\n        \n        function var_combinations = SelectLASSO(obj, X, y, train_indices, config, opts)\n            % LASSO变量选择\n            \n            n_samples = length(train_indices);\n            var_combinations = cell(n_samples, 1);\n            \n            % 设置lambda范围\n            lambda_range = logspace(-5, 1, 50);\n            \n            parfor i = 1:n_samples\n                try\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    \n                    % 标准化数据\n                    [X_train_norm, mu, sigma] = zscore(X_train);\n                    \n                    % 执行LASSO\n                    [B, FitInfo] = lasso(X_train_norm, y_train, ...\n                        'CV', config.LassoCrossValidationFolds, ...\n                        'Alpha', config.LassoAlpha, ...\n                        'Lambda', lambda_range, ...\n                        'Options', opts);\n                    \n                    % 选择最优lambda\n                    lambda_min = FitInfo.LambdaMinMSE;\n                    idx_min = FitInfo.Lambda == lambda_min;\n                    coef = B(:, idx_min);\n                    \n                    var_combinations{i} = find(abs(coef) > 0);\n                    \n                catch\n                    % 失败时的备选方法\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, pval] = corr(X_train, y_train);\n                    var_combinations{i} = find(pval < 0.05);\n                end\n                \n                % 确保至少有一个变量\n                if isempty(var_combinations{i})\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, idx] = sort(abs(corr(X_train, y_train)), 'descend');\n                    var_combinations{i} = idx(1:min(3, length(idx)));\n                end\n            end\n        end\n        \n        function var_combinations = SelectRidge(obj, X, y, train_indices, config, opts)\n            % Ridge回归变量选择\n            \n            n_samples = length(train_indices);\n            var_combinations = cell(n_samples, 1);\n            \n            lambda_range = logspace(-5, 1, 50);\n            \n            parfor i = 1:n_samples\n                try\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    \n                    % 执行Ridge回归\n                    [~, FitInfo] = lasso(X_train, y_train, ...\n                        'CV', config.LassoCrossValidationFolds, ...\n                        'Alpha', config.RidgeAlpha, ...\n                        'Lambda', lambda_range, ...\n                        'Options', opts);\n                    \n                    lambda_min = FitInfo.LambdaMinMSE;\n                    \n                    % 使用ridge函数获取系数\n                    B = ridge(y_train, X_train, lambda_min, 0);\n                    \n                    % 选择重要变量（排除截距）\n                    coef = B(2:end);\n                    threshold = max(0.05, std(coef) * 0.1);\n                    var_combinations{i} = find(abs(coef) > threshold);\n                    \n                catch\n                    % 失败时的备选方法\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    mdl = fitglm(X_train, y_train, 'Distribution', 'binomial');\n                    pvals = mdl.Coefficients.pValue(2:end);\n                    var_combinations{i} = find(pvals < 0.05);\n                end\n                \n                % 确保至少有一个变量\n                if isempty(var_combinations{i})\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, idx] = sort(abs(corr(X_train, y_train)), 'descend');\n                    var_combinations{i} = idx(1:min(3, length(idx)));\n                end\n            end\n        end\n        \n        function var_combinations = SelectElasticNet(obj, X, y, train_indices, config, opts)\n            % ElasticNet变量选择\n            \n            n_samples = length(train_indices);\n            var_combinations = cell(n_samples, 1);\n            \n            lambda_range = logspace(-5, 1, 50);\n            \n            parfor i = 1:n_samples\n                try\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    \n                    % 执行ElasticNet\n                    [B, FitInfo] = lasso(X_train, y_train, ...\n                        'CV', config.LassoCrossValidationFolds, ...\n                        'Alpha', config.ElasticNetAlpha, ...\n                        'Lambda', lambda_range, ...\n                        'Options', opts);\n                    \n                    lambda_min = FitInfo.LambdaMinMSE;\n                    idx_min = FitInfo.Lambda == lambda_min;\n                    coef = B(:, idx_min);\n                    \n                    var_combinations{i} = find(abs(coef) > 0);\n                    \n                catch\n                    % 失败时的备选方法\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, pval] = corr(X_train, y_train);\n                    var_combinations{i} = find(pval < 0.05);\n                end\n                \n                % 确保至少有一个变量\n                if isempty(var_combinations{i})\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, idx] = sort(abs(corr(X_train, y_train)), 'descend');\n                    var_combinations{i} = idx(1:min(3, length(idx)));\n                end\n            end\n        end\n        \n        function var_combinations = SelectRandomForest(obj, X, y, train_indices, config, opts)\n            % 随机森林变量选择\n            \n            n_samples = length(train_indices);\n            var_combinations = cell(n_samples, 1);\n            \n            parfor i = 1:n_samples\n                try\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    \n                    if exist('TreeBagger', 'file')\n                        % 创建随机森林\n                        rf = TreeBagger(config.RandomForestNumTrees, X_train, y_train, ...\n                            'Method', 'classification', ...\n                            'OOBPrediction', 'on', ...\n                            'OOBPredictorImportance', 'on', ...\n                            'MinLeafSize', max(1, floor(size(X_train, 1) / 50)), ...\n                            'NumPredictorsToSample', max(1, floor(sqrt(size(X_train, 2)))), ...\n                            'Options', opts, ...\n                            'PredictorSelection', 'curvature', ...\n                            'MaxNumSplits', 1e4, ...\n                            'Surrogate', 'off');\n                        \n                        % 获取特征重要性\n                        importance = rf.OOBPermutedPredictorDeltaError;\n                        \n                        % 选择重要变量\n                        var_combinations{i} = find(importance > mean(importance));\n                        \n                        % 清理对象\n                        clear rf;\n                    else\n                        % 备选方法：相关性选择\n                        [~, pval] = corr(X_train, y_train);\n                        var_combinations{i} = find(pval < 0.05);\n                    end\n                    \n                catch\n                    % 失败时的备选方法\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, pval] = corr(X_train, y_train);\n                    var_combinations{i} = find(pval < 0.05);\n                end\n                \n                % 确保至少有一个变量\n                if isempty(var_combinations{i})\n                    X_train = X(train_indices{i}, :);\n                    y_train = y(train_indices{i});\n                    [~, idx] = sort(abs(corr(X_train, y_train)), 'descend');\n                    var_combinations{i} = idx(1:min(3, length(idx)));\n                end\n            end\n        end\n        \n        function var_freq = CalculateVariableFrequency(obj, var_combinations, n_vars)\n            % 计算变量选择频率\n            \n            n_samples = length(var_combinations);\n            var_freq = zeros(n_vars, 1);\n            \n            for i = 1:n_samples\n                if ~isempty(var_combinations{i})\n                    selected = false(n_vars, 1);\n                    selected(var_combinations{i}) = true;\n                    var_freq = var_freq + selected;\n                end\n            end\n            \n            var_freq = var_freq / n_samples;\n        end\n        \n        function selected_vars = DetermineSelectedVariables(obj, var_combinations, var_freq, n_vars)\n            % 确定最终选择的变量\n            \n            % 找出最常见的变量组合\n            combo_strings = cellfun(@(x) sprintf('%d,', sort(x)), var_combinations, 'UniformOutput', false);\n            [unique_combos, ~, ic] = unique(combo_strings);\n            combo_counts = accumarray(ic, 1);\n            \n            % 使用最频繁的组合\n            [~, max_idx] = max(combo_counts);\n            most_frequent_combo = unique_combos{max_idx};\n            \n            % 从字符串中提取变量索引\n            combo_indices = str2num(['[' most_frequent_combo(1:end-1) ']']);\n            \n            % 创建选择向量\n            selected_vars = false(n_vars, 1);\n            if ~isempty(combo_indices)\n                selected_vars(combo_indices) = true;\n            end\n            \n            obj.Logger.Log('info', sprintf('最常见的变量组合出现%d次，占比%.2f%%', ...\n                combo_counts(max_idx), 100*combo_counts(max_idx)/length(var_combinations)));\n        end\n        \n        function [models, performance, group_performance] = TrainAndEvaluateModels(obj, task, var_combinations)\n            % 训练和评估模型\n            \n            X = task.X;\n            y = task.y;\n            train_indices = task.train_indices;\n            test_indices = task.test_indices;\n            var_names = task.var_names;\n            method = task.method;\n            \n            n_samples = length(train_indices);\n            \n            % 预分配\n            models = cell(n_samples, 1);\n            metrics_names = {'accuracy', 'sensitivity', 'specificity', 'precision', 'f1_score', 'auc', 'aic', 'bic'};\n            \n            % 初始化性能结构\n            performance = struct();\n            for metric = metrics_names\n                performance.(metric{1}) = zeros(n_samples, 1);\n            end\n            \n            % 预测结果存储\n            y_pred_all = cell(n_samples, 1);\n            y_test_all = cell(n_samples, 1);\n            y_pred_prob_all = cell(n_samples, 1);\n            all_coefs = cell(n_samples, 1);\n            \n            % 组合性能初始化\n            perf_template = struct(...\n                'accuracy', 0, 'sensitivity', 0, 'specificity', 0, ...\n                'precision', 0, 'f1_score', 0, 'auc', 0, ...\n                'aic', 0, 'bic', 0, 'count', 0, 'variables', {{}});\n            \n            combo_keys = cell(n_samples, 1);\n            perf_structs = cell(n_samples, 1);\n            \n            % 并行训练和评估\n            parfor i = 1:n_samples\n                try\n                    % 获取训练和测试集\n                    train_idx = train_indices{i};\n                    test_idx = test_indices{i};\n                    selected_vars = var_combinations{i};\n                    \n                    if isempty(selected_vars)\n                        models{i} = [];\n                        continue;\n                    end\n                    \n                    X_selected = X(:, selected_vars);\n                    \n                    % 训练模型\n                    local_mdl = obj.TrainModel(X_selected(train_idx, :), y(train_idx), method);\n                    models{i} = local_mdl;\n                    \n                    if ~isempty(local_mdl)\n                        % 预测\n                        [y_pred, y_pred_prob] = obj.PredictModel(local_mdl, X_selected(test_idx, :), method);\n                        \n                        % 计算性能指标\n                        [metrics, coefs] = obj.EvaluateModel(y(test_idx), y_pred, y_pred_prob, local_mdl, method, ...\n                            X_selected(train_idx, :), y(train_idx));\n                        \n                        % 存储结果\n                        for metric = metrics_names\n                            performance.(metric{1})(i) = metrics.(metric{1});\n                        end\n                        \n                        y_pred_all{i} = y_pred;\n                        y_test_all{i} = y(test_idx);\n                        y_pred_prob_all{i} = y_pred_prob;\n                        all_coefs{i} = coefs;\n                        \n                        % 组合性能\n                        combo_key = sprintf('%s', mat2str(sort(selected_vars)));\n                        combo_keys{i} = combo_key;\n                        \n                        perf = perf_template;\n                        for field = fieldnames(metrics)'\n                            if isfield(perf, field{1})\n                                perf.(field{1}) = metrics.(field{1});\n                            end\n                        end\n                        perf.count = 1;\n                        perf.variables = var_names(selected_vars);\n                        perf_structs{i} = perf;\n                    end\n                    \n                catch ME\n                    obj.Logger.Log('warning', sprintf('模型 %d 失败: %s', i, ME.message));\n                    models{i} = [];\n                end\n            end\n            \n            % 处理组合性能\n            group_performance = obj.ProcessGroupPerformance(combo_keys, perf_structs);\n            \n            % 处理总体性能\n            performance = obj.ProcessOverallPerformance(performance, y_pred_all, y_test_all, y_pred_prob_all, all_coefs);\n        end\n        \n        function model = TrainModel(obj, X_train, y_train, method)\n            % 训练单个模型\n            \n            try\n                switch lower(method)\n                    case 'randomforest'\n                        if exist('TreeBagger', 'file')\n                            model = TreeBagger(100, X_train, y_train, ...\n                                'Method', 'classification', ...\n                                'OOBPrediction', 'off', ...\n                                'Options', obj.ParallelManager.GetParallelOptions());\n                        else\n                            model = fitglm(X_train, y_train, 'Distribution', 'binomial', 'Link', 'logit');\n                        end\n                        \n                    otherwise\n                        model = fitglm(X_train, y_train, 'Distribution', 'binomial', 'Link', 'logit');\n                end\n            catch\n                model = [];\n            end\n        end\n        \n        function [y_pred, y_pred_prob] = PredictModel(obj, model, X_test, method)\n            % 使用模型进行预测\n            \n            try\n                switch lower(method)\n                    case 'randomforest'\n                        if isa(model, 'TreeBagger')\n                            [y_pred_class, y_pred_scores] = predict(model, X_test);\n                            y_pred = str2double(y_pred_class) > 0.5;\n                            y_pred_prob = y_pred_scores(:, 2);\n                        else\n                            y_pred_prob = predict(model, X_test);\n                            y_pred = y_pred_prob > 0.5;\n                        end\n                        \n                    otherwise\n                        y_pred_prob = predict(model, X_test);\n                        y_pred = y_pred_prob > 0.5;\n                end\n            catch\n                y_pred = rand(size(X_test, 1), 1) > 0.5;\n                y_pred_prob = rand(size(X_test, 1), 1);\n            end\n        end\n        \n        function [metrics, coefs] = EvaluateModel(obj, y_test, y_pred, y_pred_prob, model, method, X_train, y_train)\n            % 评估模型性能\n            \n            metrics = struct();\n            coefs = [];\n            \n            try\n                % 基本分类指标\n                [metrics.accuracy, metrics.precision, metrics.recall, metrics.specificity, metrics.f1_score] = ...\n                    obj.CalculateClassificationMetrics(y_test, y_pred);\n                \n                % AUC\n                if length(unique(y_test)) > 1\n                    [~, ~, ~, metrics.auc] = perfcurve(y_test, y_pred_prob, 1);\n                else\n                    metrics.auc = NaN;\n                end\n                \n                % 模型选择指标\n                if ~isempty(model)\n                    [metrics.aic, metrics.bic] = obj.CalculateModelSelectionMetrics(model, method, X_train, y_train);\n                else\n                    metrics.aic = NaN;\n                    metrics.bic = NaN;\n                end\n                \n                % 提取系数\n                coefs = obj.ExtractCoefficients(model, method);\n                \n            catch\n                % 设置默认值\n                metrics.accuracy = 0;\n                metrics.precision = 0;\n                metrics.recall = 0;\n                metrics.specificity = 0;\n                metrics.f1_score = 0;\n                metrics.auc = 0.5;\n                metrics.aic = Inf;\n                metrics.bic = Inf;\n            end\n        end\n        \n        function [accuracy, precision, recall, specificity, f1_score] = CalculateClassificationMetrics(obj, y_test, y_pred)\n            % 计算分类指标\n            \n            TP = sum(y_pred == 1 & y_test == 1);\n            TN = sum(y_pred == 0 & y_test == 0);\n            FP = sum(y_pred == 1 & y_test == 0);\n            FN = sum(y_pred == 0 & y_test == 1);\n            \n            accuracy = (TP + TN) / length(y_test);\n            sensitivity = TP / max(1, (TP + FN));\n            specificity = TN / max(1, (TN + FP));\n            precision = TP / max(1, (TP + FP));\n            f1_score = 2 * (precision * sensitivity) / max(1, (precision + sensitivity));\n            \n            recall = sensitivity;  % 召回率就是敏感性\n        end\n        \n        function [aic, bic] = CalculateModelSelectionMetrics(obj, model, method, X_train, y_train)\n            % 计算模型选择指标\n            \n            try\n                switch lower(method)\n                    case 'randomforest'\n                        if isa(model, 'TreeBagger')\n                            % 使用OOB误差计算\n                            oob_err_vec = oobError(model);\n                            oob_error = oob_err_vec(end);\n                            n_trees = model.NumTrees;\n                            n_predictors = size(X_train, 2);\n                            \n                            aic = oob_error * length(y_train) + 2 * (n_trees + n_predictors);\n                            bic = oob_error * length(y_train) + log(length(y_train)) * (n_trees + n_predictors);\n                        else\n                            aic = model.ModelCriterion.AIC;\n                            bic = model.ModelCriterion.BIC;\n                        end\n                        \n                    otherwise\n                        aic = model.ModelCriterion.AIC;\n                        bic = model.ModelCriterion.BIC;\n                end\n            catch\n                aic = Inf;\n                bic = Inf;\n            end\n        end\n        \n        function coefs = ExtractCoefficients(obj, model, method)\n            % 提取模型系数\n            \n            try\n                switch lower(method)\n                    case 'randomforest'\n                        if isa(model, 'TreeBagger')\n                            coefs = model.OOBPermutedPredictorDeltaError;\n                        else\n                            coefs = model.Coefficients.Estimate;\n                        end\n                        \n                    otherwise\n                        coefs = model.Coefficients.Estimate;\n                end\n            catch\n                coefs = [];\n            end\n        end\n        \n        function group_performance = ProcessGroupPerformance(obj, combo_keys, perf_structs)\n            % 处理组合性能\n            \n            [unique_keys, ~, ic] = unique(combo_keys);\n            n_unique_combos = length(unique_keys);\n            \n            perf_template = struct(...\n                'accuracy', 0, 'sensitivity', 0, 'specificity', 0, ...\n                'precision', 0, 'f1_score', 0, 'auc', 0, ...\n                'aic', 0, 'bic', 0, 'count', 0, 'variables', {{}});\n            \n            group_performance = repmat(perf_template, n_unique_combos, 1);\n            \n            for i = 1:n_unique_combos\n                combo_indices = find(ic == i);\n                first_idx = combo_indices(1);\n                \n                if ~isempty(perf_structs{first_idx})\n                    group_performance(i).variables = perf_structs{first_idx}.variables;\n                    group_performance(i).count = length(combo_indices);\n                    \n                    % 计算平均性能\n                    metrics = {'accuracy', 'sensitivity', 'specificity', 'precision', 'f1_score', 'auc', 'aic', 'bic'};\n                    for metric = metrics\n                        sum_val = 0;\n                        valid_count = 0;\n                        for j = 1:length(combo_indices)\n                            idx = combo_indices(j);\n                            if ~isempty(perf_structs{idx}) && isfield(perf_structs{idx}, metric{1})\n                                sum_val = sum_val + perf_structs{idx}.(metric{1});\n                                valid_count = valid_count + 1;\n                            end\n                        end\n                        if valid_count > 0\n                            group_performance(i).(metric{1}) = sum_val / valid_count;\n                        end\n                    end\n                end\n            end\n            \n            % 按出现次数排序\n            [~, idx] = sort([group_performance.count], 'descend');\n            group_performance = group_performance(idx);\n        end\n        \n        function performance = ProcessOverallPerformance(obj, performance, y_pred_all, y_test_all, y_pred_prob_all, all_coefs)\n            % 处理总体性能\n            \n            % 计算平均值和标准差\n            metrics = {'accuracy', 'sensitivity', 'specificity', 'precision', 'f1_score', 'auc', 'aic', 'bic'};\n            \n            for metric = metrics\n                values = performance.(metric{1});\n                performance.(['avg_' metric{1}]) = mean(values, 'omitnan');\n                performance.(['std_' metric{1}]) = std(values, 'omitnan');\n            end\n            \n            % 添加预测结果\n            performance.y_pred = y_pred_all;\n            performance.y_test = y_test_all;\n            performance.y_pred_prob = y_pred_prob_all;\n            performance.all_coefs = all_coefs;\n        end\n        \n        function params = ExtractModelParameters(obj, models, var_names)\n            % 提取模型参数\n            \n            n_models = length(models);\n            coef_cell = cell(n_models, 1);\n            pval_cell = cell(n_models, 1);\n            var_cell = cell(n_models, 1);\n            \n            parfor i = 1:n_models\n                mdl = models{i};\n                \n                if ~isempty(mdl)\n                    if isa(mdl, 'TreeBagger')\n                        % 随机森林特征重要性\n                        local_imp = mdl.OOBPermutedPredictorDeltaError;\n                        local_coef = local_imp;\n                        local_pval = nan(size(local_imp));\n                        local_vars = cellstr(mdl.PredictorNames);\n                    else\n                        % 逻辑回归模型\n                        try\n                            coef_table = mdl.Coefficients;\n                            local_coef = coef_table.Estimate';\n                            local_pval = coef_table.pValue';\n                            local_vars = coef_table.Row';\n                        catch\n                            local_coef = [];\n                            local_pval = [];\n                            local_vars = {};\n                        end\n                    end\n                else\n                    local_coef = [];\n                    local_pval = [];\n                    local_vars = {};\n                end\n                \n                coef_cell{i} = local_coef;\n                pval_cell{i} = local_pval;\n                var_cell{i} = local_vars;\n            end\n            \n            params = struct();\n            params.coef_cell = coef_cell;\n            params.pval_cell = pval_cell;\n            params.var_cell = var_cell;\n        end\n        \n        function IntegrateResults(obj, method_results)\n            % 整合所有方法的结果\n            \n            obj.Results = struct();\n            \n            for i = 1:length(method_results)\n                result = method_results{i};\n                if result.success\n                    method = result.method;\n                    obj.Results.(method) = rmfield(result, {'method', 'success'});\n                else\n                    obj.Logger.Log('warning', sprintf('%s方法失败，跳过', result.method));\n                end\n            end\n        end\n        \n        function PerformMetaAnalysis(obj)\n            % 执行元分析\n            \n            obj.Logger.Log('info', '开始元分析');\n            \n            try\n                % 1. 跨方法变量选择一致性分析\n                obj.AnalyzeCrossMethodConsistency();\n                \n                % 2. 性能比较分析\n                obj.AnalyzePerformanceComparison();\n                \n                % 3. 最佳变量组合推荐\n                obj.RecommendBestVariableSet();\n                \n                % 4. 稳定性分析\n                obj.AnalyzeSelectionStability();\n                \n                obj.Logger.Log('info', '元分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'PerformMetaAnalysis');\n            end\n        end\n        \n        function AnalyzeCrossMethodConsistency(obj)\n            % 跨方法变量选择一致性分析\n            \n            try\n                methods = fieldnames(obj.Results);\n                n_methods = length(methods);\n                \n                if n_methods < 2\n                    return;\n                end\n                \n                % 收集所有方法的变量选择\n                all_frequencies = [];\n                method_names = {};\n                \n                for i = 1:n_methods\n                    method = methods{i};\n                    if isfield(obj.Results.(method), 'var_freq')\n                        all_frequencies = [all_frequencies, obj.Results.(method).var_freq];\n                        method_names{end+1} = method;\n                    end\n                end\n                \n                if isempty(all_frequencies)\n                    return;\n                end\n                \n                % 计算一致性指标\n                consistency = struct();\n                consistency.method_agreement_matrix = corr(all_frequencies);\n                consistency.average_frequency = mean(all_frequencies, 2);\n                consistency.frequency_variance = var(all_frequencies, 0, 2);\n                consistency.consistency_score = mean(consistency.method_agreement_matrix(:));\n                \n                % 识别一致选择的变量\n                threshold = 0.5;\n                consistency.consistently_selected = find(consistency.average_frequency > threshold);\n                consistency.variable_consensus = consistency.average_frequency(consistency.consistently_selected);\n                \n                obj.Results.meta_analysis.cross_method_consistency = consistency;\n                \n                obj.Logger.Log('info', sprintf('方法间一致性分析完成，一致性得分: %.3f', consistency.consistency_score));\n                \n            catch ME\n                obj.Logger.LogException(ME, 'AnalyzeCrossMethodConsistency');\n            end\n        end\n        \n        function AnalyzePerformanceComparison(obj)\n            % 性能比较分析\n            \n            try\n                methods = fieldnames(obj.Results);\n                performance_comparison = struct();\n                \n                % 收集性能指标\n                metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                \n                for metric = metrics\n                    comparison_data = table();\n                    \n                    for i = 1:length(methods)\n                        method = methods{i};\n                        if isfield(obj.Results.(method), 'performance') && ...\n                           isfield(obj.Results.(method).performance, ['avg_' metric{1}])\n                            \n                            row = table();\n                            row.Method = {method};\n                            row.Mean = obj.Results.(method).performance.(['avg_' metric{1}]);\n                            row.Std = obj.Results.(method).performance.(['std_' metric{1}]);\n                            row.Metric = {metric{1}};\n                            \n                            comparison_data = [comparison_data; row];\n                        end\n                    end\n                    \n                    if height(comparison_data) > 0\n                        % 排序\n                        comparison_data = sortrows(comparison_data, 'Mean', 'descend');\n                        performance_comparison.(metric{1}) = comparison_data;\n                        \n                        % 统计检验\n                        if height(comparison_data) >= 2\n                            values = comparison_data.Mean;\n                            [~, p_value] = ttest(values);\n                            performance_comparison.([metric{1} '_test']) = struct('p_value', p_value);\n                        end\n                    end\n                end\n                \n                obj.Results.meta_analysis.performance_comparison = performance_comparison;\n                \n                obj.Logger.Log('info', '性能比较分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'AnalyzePerformanceComparison');\n            end\n        end\n        \n        function RecommendBestVariableSet(obj)\n            % 推荐最佳变量组合\n            \n            try\n                methods = fieldnames(obj.Results);\n                recommendations = struct();\n                \n                % 基于性能推荐\n                best_performance = struct();\n                for metric = {'f1_score', 'auc', 'accuracy'}\n                    best_method = '';\n                    best_value = -Inf;\n                    \n                    for i = 1:length(methods)\n                        method = methods{i};\n                        if isfield(obj.Results.(method), 'performance') && ...\n                           isfield(obj.Results.(method).performance, ['avg_' metric{1}])\n                            value = obj.Results.(method).performance.(['avg_' metric{1}]);\n                            if value > best_value\n                                best_value = value;\n                                best_method = method;\n                            end\n                        end\n                    end\n                    \n                    if ~isempty(best_method)\n                        best_performance.(metric{1}) = struct('method', best_method, 'value', best_value);\n                        \n                        % 获取变量组合\n                        if isfield(obj.Results.(best_method), 'group_performance') && ...\n                           ~isempty(obj.Results.(best_method).group_performance)\n                            top_combo = obj.Results.(best_method).group_performance(1);\n                            best_performance.(metric{1}).variables = top_combo.variables;\n                        end\n                    end\n                end\n                \n                recommendations.by_performance = best_performance;\n                \n                % 基于一致性推荐\n                if isfield(obj.Results, 'meta_analysis') && ...\n                   isfield(obj.Results.meta_analysis, 'cross_method_consistency')\n                    consistency = obj.Results.meta_analysis.cross_method_consistency;\n                    \n                    if ~isempty(consistency.consistently_selected)\n                        % 获取变量名\n                        all_var_names = obj.GetVariableNames();\n                        if ~isempty(all_var_names)\n                            recommended_vars = all_var_names(consistency.consistently_selected);\n                            recommendations.by_consensus = struct();\n                            recommendations.by_consensus.variables = recommended_vars;\n                            recommendations.by_consensus.frequencies = consistency.variable_consensus;\n                        end\n                    end\n                end\n                \n                obj.Results.meta_analysis.recommendations = recommendations;\n                \n                obj.Logger.Log('info', '变量组合推荐完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'RecommendBestVariableSet');\n            end\n        end\n        \n        function AnalyzeSelectionStability(obj)\n            % 分析变量选择的稳定性\n            \n            try\n                methods = fieldnames(obj.Results);\n                stability_analysis = struct();\n                \n                for i = 1:length(methods)\n                    method = methods{i};\n                    \n                    if isfield(obj.Results.(method), 'var_combinations')\n                        var_combinations = obj.Results.(method).var_combinations;\n                        \n                        % 计算选择稳定性\n                        stability = struct();\n                        \n                        % 1. Shannon熵\n                        var_freq = obj.Results.(method).var_freq;\n                        stability.shannon_entropy = obj.CalculateShannonEntropy(var_freq);\n                        \n                        % 2. Jaccard相似度\n                        stability.jaccard_similarity = obj.CalculateJaccardSimilarity(var_combinations);\n                        \n                        % 3. 变异系数\n                        combo_sizes = cellfun(@length, var_combinations);\n                        stability.size_cv = std(combo_sizes) / mean(combo_sizes);\n                        \n                        stability_analysis.(method) = stability;\n                    end\n                end\n                \n                obj.Results.meta_analysis.stability_analysis = stability_analysis;\n                \n                obj.Logger.Log('info', '稳定性分析完成');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'AnalyzeSelectionStability');\n            end\n        end\n        \n        function entropy = CalculateShannonEntropy(obj, var_freq)\n            % 计算Shannon熵\n            \n            % 避免log(0)\n            non_zero_freq = var_freq(var_freq > 0);\n            \n            if isempty(non_zero_freq)\n                entropy = 0;\n            else\n                entropy = -sum(non_zero_freq .* log2(non_zero_freq));\n            end\n        end\n        \n        function similarity = CalculateJaccardSimilarity(obj, var_combinations)\n            % 计算Jaccard相似度\n            \n            n_combinations = length(var_combinations);\n            similarities = [];\n            \n            for i = 1:n_combinations-1\n                for j = i+1:n_combinations\n                    set_i = var_combinations{i};\n                    set_j = var_combinations{j};\n                    \n                    if isempty(set_i) && isempty(set_j)\n                        sim = 1;\n                    elseif isempty(set_i) || isempty(set_j)\n                        sim = 0;\n                    else\n                        intersection = length(intersect(set_i, set_j));\n                        union = length(union(set_i, set_j));\n                        sim = intersection / union;\n                    end\n                    \n                    similarities = [similarities; sim];\n                end\n            end\n            \n            if isempty(similarities)\n                similarity = 1;\n            else\n                similarity = mean(similarities);\n            end\n        end\n        \n        function var_names = GetVariableNames(obj)\n            % 获取变量名称\n            \n            var_names = [];\n            methods = fieldnames(obj.Results);\n            \n            for i = 1:length(methods)\n                method = methods{i};\n                if isfield(obj.Results.(method), 'group_performance') && ...\n                   ~isempty(obj.Results.(method).group_performance)\n                    \n                    for j = 1:length(obj.Results.(method).group_performance)\n                        if isfield(obj.Results.(method).group_performance(j), 'variables')\n                            vars = obj.Results.(method).group_performance(j).variables;\n                            if ~isempty(vars)\n                                var_names = vars;\n                                return;\n                            end\n                        end\n                    end\n                end\n            end\n        end\n        \n        function CreateSelectionVisualizations(obj)\n            % 创建变量选择可视化\n            \n            try\n                figure_dir = fullfile(obj.Config.OutputDirectory, 'figures', 'variable_selection');\n                if ~exist(figure_dir, 'dir')\n                    mkdir(figure_dir);\n                end\n                \n                % 1. 变量选择频率图\n                obj.CreateVariableFrequencyPlot(figure_dir);\n                \n                % 2. 方法性能比较图\n                obj.CreateMethodPerformanceComparison(figure_dir);\n                \n                % 3. 变量组合性能图\n                obj.CreateCombinationPerformancePlot(figure_dir);\n                \n                % 4. 一致性分析图\n                obj.CreateConsistencyAnalysisPlot(figure_dir);\n                \n                % 5. 稳定性分析图\n                obj.CreateStabilityAnalysisPlot(figure_dir);\n                \n                obj.Logger.Log('info', '变量选择可视化已创建');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateSelectionVisualizations');\n            end\n        end\n        \n        function CreateVariableFrequencyPlot(obj, figure_dir)\n            % 创建变量选择频率图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 800]);\n                \n                methods = fieldnames(obj.Results);\n                n_methods = length(methods);\n                \n                % 收集数据\n                all_frequencies = [];\n                var_names = obj.GetVariableNames();\n                \n                for i = 1:n_methods\n                    method = methods{i};\n                    if isfield(obj.Results.(method), 'var_freq')\n                        all_frequencies = [all_frequencies, obj.Results.(method).var_freq];\n                    end\n                end\n                \n                if isempty(all_frequencies)\n                    close(fig);\n                    return;\n                end\n                \n                % 创建分组条形图\n                bar(all_frequencies, 'grouped');\n                \n                % 设置标签\n                xlabel('变量');\n                ylabel('选择频率');\n                title('不同方法的变量选择频率比较');\n                legend(methods, 'Location', 'best');\n                grid on;\n                \n                % 设置X轴标签\n                if ~isempty(var_names) && length(var_names) == size(all_frequencies, 1)\n                    set(gca, 'XTick', 1:length(var_names), 'XTickLabel', var_names, 'XTickLabelRotation', 45);\n                end\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'variable_frequency_comparison.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'variable_frequency_comparison.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateVariableFrequencyPlot');\n            end\n        end\n        \n        function CreateMethodPerformanceComparison(obj, figure_dir)\n            % 创建方法性能比较图\n            \n            try\n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 800]);\n                \n                methods = fieldnames(obj.Results);\n                metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                metric_labels = {'准确率', '精确率', '召回率', 'F1分数', 'AUC'};\n                \n                n_metrics = length(metrics);\n                \n                for i = 1:n_metrics\n                    subplot(2, 3, i);\n                    \n                    metric = metrics{i};\n                    means = [];\n                    stds = [];\n                    method_names = {};\n                    \n                    for j = 1:length(methods)\n                        method = methods{j};\n                        if isfield(obj.Results.(method), 'performance') && ...\n                           isfield(obj.Results.(method).performance, ['avg_' metric])\n                            \n                            means = [means; obj.Results.(method).performance.(['avg_' metric])];\n                            stds = [stds; obj.Results.(method).performance.(['std_' metric])];\n                            method_names{end+1} = method;\n                        end\n                    end\n                    \n                    if ~isempty(means)\n                        % 创建条形图\n                        bar_h = bar(means);\n                        hold on;\n                        errorbar(1:length(means), means, stds, '.k');\n                        \n                        % 设置标签\n                        set(gca, 'XTick', 1:length(method_names), 'XTickLabel', method_names, 'XTickLabelRotation', 45);\n                        ylabel(metric_labels{i});\n                        title(sprintf('%s比较', metric_labels{i}));\n                        grid on;\n                        \n                        if i <= 5\n                            ylim([0, 1.05]);\n                        end\n                    end\n                end\n                \n                sgtitle('不同变量选择方法的性能比较', 'FontSize', 16, 'FontWeight', 'bold');\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'method_performance_comparison.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'method_performance_comparison.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateMethodPerformanceComparison');\n            end\n        end\n        \n        function CreateCombinationPerformancePlot(obj, figure_dir)\n            % 创建变量组合性能图\n            \n            try\n                methods = fieldnames(obj.Results);\n                \n                for i = 1:length(methods)\n                    method = methods{i};\n                    \n                    if isfield(obj.Results.(method), 'group_performance')\n                        group_perf = obj.Results.(method).group_performance;\n                        \n                        if length(group_perf) >= 3\n                            fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 800]);\n                            \n                            % 取前8个组合\n                            top_n = min(8, length(group_perf));\n                            \n                            % 提取数据\n                            combo_labels = cell(top_n, 1);\n                            f1_scores = zeros(top_n, 1);\n                            aucs = zeros(top_n, 1);\n                            counts = zeros(top_n, 1);\n                            \n                            for j = 1:top_n\n                                combo_labels{j} = sprintf('组合 %d', j);\n                                f1_scores(j) = group_perf(j).f1_score;\n                                aucs(j) = group_perf(j).auc;\n                                counts(j) = group_perf(j).count;\n                            end\n                            \n                            % 创建两个子图\n                            subplot(2, 1, 1);\n                            bar([f1_scores, aucs], 'grouped');\n                            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45);\n                            ylabel('性能指标');\n                            legend({'F1分数', 'AUC'});\n                            title(sprintf('%s方法：变量组合性能', method));\n                            grid on;\n                            ylim([0, 1.05]);\n                            \n                            subplot(2, 1, 2);\n                            bar(counts);\n                            set(gca, 'XTick', 1:top_n, 'XTickLabel', combo_labels, 'XTickLabelRotation', 45);\n                            ylabel('出现次数');\n                            title(sprintf('%s方法：变量组合频率', method));\n                            grid on;\n                            \n                            % 保存图形\n                            filename = sprintf('%s_combination_performance', method);\n                            saveas(fig, fullfile(figure_dir, [filename '.svg']), 'svg');\n                            saveas(fig, fullfile(figure_dir, [filename '.png']), 'png');\n                            close(fig);\n                        end\n                    end\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateCombinationPerformancePlot');\n            end\n        end\n        \n        function CreateConsistencyAnalysisPlot(obj, figure_dir)\n            % 创建一致性分析图\n            \n            try\n                if ~isfield(obj.Results, 'meta_analysis') || ...\n                   ~isfield(obj.Results.meta_analysis, 'cross_method_consistency')\n                    return;\n                end\n                \n                consistency = obj.Results.meta_analysis.cross_method_consistency;\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1000, 800]);\n                \n                % 绘制方法间相关性矩阵\n                imagesc(consistency.method_agreement_matrix);\n                colorbar;\n                colormap('RdBu_r');\n                \n                % 设置标签\n                methods = fieldnames(obj.Results);\n                set(gca, 'XTick', 1:length(methods), 'XTickLabel', methods, 'XTickLabelRotation', 45);\n                set(gca, 'YTick', 1:length(methods), 'YTickLabel', methods);\n                \n                title('方法间变量选择一致性');\n                xlabel('方法');\n                ylabel('方法');\n                \n                % 添加数值标签\n                for i = 1:size(consistency.method_agreement_matrix, 1)\n                    for j = 1:size(consistency.method_agreement_matrix, 2)\n                        text(j, i, sprintf('%.3f', consistency.method_agreement_matrix(i, j)), ...\n                            'HorizontalAlignment', 'center', 'VerticalAlignment', 'middle');\n                    end\n                end\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'consistency_analysis.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'consistency_analysis.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateConsistencyAnalysisPlot');\n            end\n        end\n        \n        function CreateStabilityAnalysisPlot(obj, figure_dir)\n            % 创建稳定性分析图\n            \n            try\n                if ~isfield(obj.Results, 'meta_analysis') || ...\n                   ~isfield(obj.Results.meta_analysis, 'stability_analysis')\n                    return;\n                end\n                \n                stability = obj.Results.meta_analysis.stability_analysis;\n                methods = fieldnames(stability);\n                \n                fig = figure('Visible', 'off', 'Position', [100, 100, 1200, 600]);\n                \n                % 提取数据\n                shannon_entropies = zeros(length(methods), 1);\n                jaccard_similarities = zeros(length(methods), 1);\n                size_cvs = zeros(length(methods), 1);\n                \n                for i = 1:length(methods)\n                    method = methods{i};\n                    shannon_entropies(i) = stability.(method).shannon_entropy;\n                    jaccard_similarities(i) = stability.(method).jaccard_similarity;\n                    size_cvs(i) = stability.(method).size_cv;\n                end\n                \n                % 创建三个子图\n                subplot(1, 3, 1);\n                bar(shannon_entropies);\n                set(gca, 'XTick', 1:length(methods), 'XTickLabel', methods, 'XTickLabelRotation', 45);\n                ylabel('Shannon熵');\n                title('变量选择熵');\n                grid on;\n                \n                subplot(1, 3, 2);\n                bar(jaccard_similarities);\n                set(gca, 'XTick', 1:length(methods), 'XTickLabel', methods, 'XTickLabelRotation', 45);\n                ylabel('Jaccard相似度');\n                title('选择一致性');\n                grid on;\n                ylim([0, 1]);\n                \n                subplot(1, 3, 3);\n                bar(size_cvs);\n                set(gca, 'XTick', 1:length(methods), 'XTickLabel', methods, 'XTickLabelRotation', 45);\n                ylabel('变异系数');\n                title('选择大小稳定性');\n                grid on;\n                \n                sgtitle('变量选择稳定性分析', 'FontSize', 16, 'FontWeight', 'bold');\n                \n                % 保存图形\n                saveas(fig, fullfile(figure_dir, 'stability_analysis.svg'), 'svg');\n                saveas(fig, fullfile(figure_dir, 'stability_analysis.png'), 'png');\n                close(fig);\n                \n            catch ME\n                obj.Logger.LogException(ME, 'CreateStabilityAnalysisPlot');\n            end\n        end\n        \n        function GenerateSelectionReport(obj)\n            % 生成变量选择报告\n            \n            try\n                report = struct();\n                report.timestamp = datetime('now');\n                report.methods_analyzed = length(fieldnames(obj.Results));\n                \n                % 性能总结\n                report.performance_summary = struct();\n                \n                methods = fieldnames(obj.Results);\n                for method = methods'\n                    if isfield(obj.Results.(method{1}), 'performance')\n                        perf = obj.Results.(method{1}).performance;\n                        summary = struct();\n                        \n                        metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                        for metric = metrics\n                            if isfield(perf, ['avg_' metric{1}])\n                                summary.(metric{1}) = struct();\n                                summary.(metric{1}).mean = perf.(['avg_' metric{1}]);\n                                summary.(metric{1}).std = perf.(['std_' metric{1}]);\n                            end\n                        end\n                        \n                        report.performance_summary.(method{1}) = summary;\n                    end\n                end\n                \n                % 推荐总结\n                if isfield(obj.Results, 'meta_analysis') && ...\n                   isfield(obj.Results.meta_analysis, 'recommendations')\n                    report.recommendations = obj.Results.meta_analysis.recommendations;\n                end\n                \n                % 稳定性总结\n                if isfield(obj.Results, 'meta_analysis') && ...\n                   isfield(obj.Results.meta_analysis, 'stability_analysis')\n                    report.stability_summary = struct();\n                    \n                    for method = methods'\n                        if isfield(obj.Results.meta_analysis.stability_analysis, method{1})\n                            stability = obj.Results.meta_analysis.stability_analysis.(method{1});\n                            report.stability_summary.(method{1}) = stability;\n                        end\n                    end\n                end\n                \n                % 保存报告\n                obj.Results.final_report = report;\n                \n                % 记录关键发现\n                obj.Logger.CreateSection('变量选择报告总结');\n                obj.Logger.Log('info', sprintf('分析方法数: %d', report.methods_analyzed));\n                \n                % 记录最佳性能\n                best_f1 = -Inf;\n                best_method = '';\n                \n                for method = methods'\n                    if isfield(report.performance_summary, method{1}) && ...\n                       isfield(report.performance_summary.(method{1}), 'f1_score')\n                        f1 = report.performance_summary.(method{1}).f1_score.mean;\n                        if f1 > best_f1\n                            best_f1 = f1;\n                            best_method = method{1};\n                        end\n                    end\n                end\n                \n                if ~isempty(best_method)\n                    obj.Logger.Log('info', sprintf('最佳性能方法: %s (F1=%.3f)', best_method, best_f1));\n                end\n                \n                % 记录推荐\n                if isfield(report, 'recommendations') && isfield(report.recommendations, 'by_consensus')\n                    consensus_vars = report.recommendations.by_consensus.variables;\n                    obj.Logger.Log('info', sprintf('一致推荐的变量: %s', strjoin(consensus_vars, ', ')));\n                end\n                \n            catch ME\n                obj.Logger.LogException(ME, 'GenerateSelectionReport');\n            end\n        end\n        \n        function ExportVariableSelectionTables(obj, output_dir)\n            % 导出变量选择表格\n            \n            try\n                % 1. 导出变量选择频率表\n                methods = fieldnames(obj.Results);\n                var_names = obj.GetVariableNames();\n                \n                if ~isempty(var_names)\n                    freq_table = table();\n                    freq_table.Variable = var_names';\n                    \n                    for i = 1:length(methods)\n                        method = methods{i};\n                        if isfield(obj.Results.(method), 'var_freq')\n                            freq_table.(method) = obj.Results.(method).var_freq;\n                        end\n                    end\n                    \n                    % 添加平均频率\n                    freq_data = table2array(freq_table(:, 2:end));\n                    freq_table.Average = mean(freq_data, 2);\n                    \n                    % 按平均频率排序\n                    freq_table = sortrows(freq_table, 'Average', 'descend');\n                    \n                    writetable(freq_table, fullfile(output_dir, 'variable_selection_frequencies.csv'));\n                end\n                \n                % 2. 导出性能比较表\n                perf_table = table();\n                \n                metrics = {'accuracy', 'precision', 'recall', 'f1_score', 'auc'};\n                for metric = metrics\n                    method_names = {};\n                    means = [];\n                    stds = [];\n                    \n                    for i = 1:length(methods)\n                        method = methods{i};\n                        if isfield(obj.Results.(method), 'performance') && ...\n                           isfield(obj.Results.(method).performance, ['avg_' metric{1}])\n                            \n                            method_names{end+1} = method;\n                            means = [means; obj.Results.(method).performance.(['avg_' metric{1}])];\n                            stds = [stds; obj.Results.(method).performance.(['std_' metric{1}])];\n                        end\n                    end\n                    \n                    if ~isempty(method_names)\n                        metric_table = table();\n                        metric_table.Method = method_names';\n                        metric_table.Mean = means;\n                        metric_table.Std = stds;\n                        metric_table.Metric = repmat({metric{1}}, length(method_names), 1);\n                        \n                        perf_table = [perf_table; metric_table];\n                    end\n                end\n                \n                writetable(perf_table, fullfile(output_dir, 'method_performance_comparison.csv'));\n                \n                % 3. 导出变量组合表\n                for i = 1:length(methods)\n                    method = methods{i};\n                    if isfield(obj.Results.(method), 'group_performance')\n                        group_perf = obj.Results.(method).group_performance;\n                        \n                        combo_table = table();\n                        \n                        for j = 1:length(group_perf)\n                            row = table();\n                            row.Combination = j;\n                            row.Count = group_perf(j).count;\n                            row.Accuracy = group_perf(j).accuracy;\n                            row.F1_Score = group_perf(j).f1_score;\n                            row.AUC = group_perf(j).auc;\n                            row.Variables = {strjoin(group_perf(j).variables, ', ')};\n                            \n                            combo_table = [combo_table; row];\n                        end\n                        \n                        filename = sprintf('%s_variable_combinations.csv', method);\n                        writetable(combo_table, fullfile(output_dir, filename));\n                    end\n                end\n                \n                obj.Logger.Log('info', '变量选择表格已导出');\n                \n            catch ME\n                obj.Logger.LogException(ME, 'ExportVariableSelectionTables');\n            end\n        end\n    end\nend\n",
            "language": "matlab",
            "version_uuid": "58f0b89a-000a-43a0-970d-836853225756"
          },
          "message": "artifacts"
        },
        {
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "6916b2be-fbb1-4b01-bfb1-7e69795bfab5"
            }
          ],
          "is_error": false
        },
        {
          "start_timestamp": "2025-05-08T10:13:20.184508+00:00",
          "stop_timestamp": "2025-05-08T10:13:20.184508+00:00",
          "type": "text",
          "text": "",
          "citations": []
        }
      ],
      "sender": "assistant",
      "index": 5,
      "created_at": "2025-05-08T10:13:20.215759+00:00",
      "updated_at": "2025-05-08T10:13:20.215759+00:00",
      "truncated": true,
      "stop_reason": "max_tokens",
      "attachments": [],
      "files": [],
      "files_v2": [],
      "sync_sources": [],
      "parent_message_uuid": "ad11cb22-6006-44cc-9ac4-556807347526"
    }
  ]
}